#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å€å¡Šéˆèˆ¹é•·â€”å‚‘å…‹ï¼šè‡ªå‹•åŒ–æ¨æ’­ç³»çµ±
æ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡å¡Š
"""

import requests
import json
import time
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any
import os
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# å°ç£å°åŒ—æ™‚å€ï¼ˆUTC+8ï¼‰
TAIPEI_TZ = timezone(timedelta(hours=8))

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== é…ç½®è¨­å®š ====================
# ä¸€å¾‹å¾ç’°å¢ƒè®Šé‡è®€å–ï¼Œé¿å…åœ¨ç¨‹å¼ç¢¼ä¸­ç¡¬ç·¨ API é‡‘é‘°ç­‰æ•æ„Ÿè³‡è¨Š

# CoinGecko API
CG_GECKO_API_KEY = os.getenv('CG_GECKO_API_KEY')

# CoinGlass API
CG_API_KEY = os.getenv('CG_API_KEY')
CG_API_BASE = "https://open-api-v4.coinglass.com"

# Tree of Alpha API
TREE_API_KEY = os.getenv('TREE_API_KEY')

# Telegram é…ç½®
TG_TOKEN = os.getenv('TG_TOKEN')
CHAT_ID = os.getenv('CHAT_ID')

# Telegram Thread IDs (å¾ç’°å¢ƒè®Šé‡è®€å– JSONï¼Œæˆ–ä½¿ç”¨é è¨­å€¼)
thread_ids_str = os.environ.get('TG_THREAD_IDS', '')
if thread_ids_str:
    try:
        TG_THREAD_IDS = json.loads(thread_ids_str)
    except:
        TG_THREAD_IDS = {
            'sector_ranking': 5,
            'buying_power_monitor': 246,  # åŸ whale_positionï¼Œå·²æ›¿æ›ç‚ºè³¼è²·åŠ›ç›£æ§
            'position_change': 250,
            'economic_data': 13,
            'news': 7,
            'funding_rate': 244,
            'long_term_index': 248,
            'liquidity_radar': 3,
            'altseason_radar': 254,
            'hyperliquid': 252,
        }
else:
    TG_THREAD_IDS = {
        'sector_ranking': int(os.environ.get('TG_THREAD_SECTOR_RANKING', 5)),
        'buying_power_monitor': int(os.environ.get('TG_THREAD_WHALE_POSITION', 246)),  # ä½¿ç”¨åŸ whale_position çš„ thread ID
        'position_change': int(os.environ.get('TG_THREAD_POSITION_CHANGE', 250)),
        'economic_data': int(os.environ.get('TG_THREAD_ECONOMIC_DATA', 13)),
        'news': int(os.environ.get('TG_THREAD_NEWS', 7)),
        'funding_rate': int(os.environ.get('TG_THREAD_FUNDING_RATE', 244)),
        'long_term_index': int(os.environ.get('TG_THREAD_LONG_TERM_INDEX', 248)),
        'liquidity_radar': int(os.environ.get('TG_THREAD_LIQUIDITY_RADAR', 3)),
        'altseason_radar': int(os.environ.get('TG_THREAD_ALTSEASON_RADAR', 254)),
        'hyperliquid': int(os.environ.get('TG_THREAD_HYPERLIQUID', 252)),
    }

# å…¶ä»–é…ç½®
EXCHANGE = "Binance"
TIME_TYPE = "h1"
SYMBOLS = ["BTCUSDT", "ETHUSDT", "SOLUSDT"]
# æŒå€‰è®ŠåŒ–ç¯©é¸ï¼šæ”¹ç‚ºåªåµæ¸¬åˆç´„å¹£ç¨®ï¼ˆä½¿ç”¨ API ç²å–ï¼‰
MAX_SYMBOLS = 904  # å°‡ç”± API è¿”å›çš„åˆç´„å¹£ç¨®æ•¸é‡æ±ºå®š

# æ•¸æ“šå­˜å„²ç›®éŒ„
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

# ==================== å·¥å…·å‡½æ•¸ ====================

def send_telegram_message(text: str, thread_id: int, parse_mode: str = "Markdown") -> bool:
    """ç™¼é€è¨Šæ¯åˆ° Telegram"""
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "message_thread_id": thread_id,
        "text": text,
        "parse_mode": parse_mode,
        "disable_web_page_preview": True
    }
    
    try:
        response = requests.post(url, json=payload, timeout=10)
        if response.status_code == 200:
            result = response.json()
            if result.get("ok"):
                logger.info("Telegram è¨Šæ¯ç™¼é€æˆåŠŸ")
                return True
            else:
                logger.error(f"Telegram API éŒ¯èª¤: {result}")
                return False
        else:
            logger.error(f"Telegram HTTP éŒ¯èª¤: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        logger.error(f"ç™¼é€ Telegram è¨Šæ¯å¤±æ•—: {str(e)}")
        return False


def load_json_file(filepath: Path, default: Any = None) -> Any:
    """å¾æ–‡ä»¶åŠ è¼‰ JSON æ•¸æ“š"""
    if filepath.exists():
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è®€å–æ–‡ä»¶å¤±æ•— {filepath}: {str(e)}")
    return default if default is not None else []


def save_json_file(filepath: Path, data: Any) -> bool:
    """ä¿å­˜æ•¸æ“šåˆ° JSON æ–‡ä»¶"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶å¤±æ•— {filepath}: {str(e)}")
        return False


def translate_text(text: str, target_lang: str = 'zh-tw') -> str:
    """ç¿»è­¯æ–‡æœ¬ï¼ˆä½¿ç”¨ googletransï¼Œå¦‚æœå¯ç”¨ï¼‰"""
    try:
        from googletrans import Translator
        translator = Translator()
        result = translator.translate(text, dest=target_lang)
        return result.text
    except ImportError:
        logger.warning("googletrans æœªå®‰è£ï¼Œè·³éç¿»è­¯")
        return text
    except Exception as e:
        logger.warning(f"ç¿»è­¯å¤±æ•—: {str(e)}ï¼Œä½¿ç”¨åŸæ–‡")
        return text


def get_taipei_time(dt: Optional[datetime] = None) -> datetime:
    """ç²å–å°ç£å°åŒ—æ™‚é–“ï¼ˆUTC+8ï¼‰"""
    if dt is None:
        dt = datetime.now(timezone.utc)
    elif dt.tzinfo is None:
        # å¦‚æœæ²’æœ‰æ™‚å€è³‡è¨Šï¼Œå‡è¨­æ˜¯ UTC
        dt = dt.replace(tzinfo=timezone.utc)
    # è½‰æ›ç‚ºå°ç£æ™‚é–“
    return dt.astimezone(TAIPEI_TZ)


def format_datetime(dt: datetime) -> str:
    """æ ¼å¼åŒ–æ—¥æœŸæ™‚é–“ï¼ˆè‡ªå‹•è½‰æ›ç‚ºå°ç£æ™‚é–“ï¼‰"""
    # è½‰æ›ç‚ºå°ç£æ™‚é–“
    dt_taipei = get_taipei_time(dt)
    weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
    weekday = weekdays[dt_taipei.weekday()]
    return dt_taipei.strftime(f"%Y-%m-%d (é€±{weekday}) %H:%M")


# ==================== 1. ä¸»æµæ¿å¡Šæ’è¡Œæ¦œæ¨æ’­ ====================

MAIN_SECTORS = {
    "Meme": "Meme è¿·å› æ¿å¡Š",
    "Artificial Intelligence (AI)": "AI äººå·¥æ™ºæ…§",
    "Real World Assets (RWA)": "RWA ç¾å¯¦è³‡ç”¢",
    "Decentralized Finance (DeFi)": "DeFi å»ä¸­å¿ƒåŒ–é‡‘è",
    "Layer 2": "ç¬¬äºŒå±¤ç¶²è·¯ (L2)",
    "Gaming (GameFi)": "GameFi é›»ç«¶éŠæˆ²",
    "Smart Contract Platform": "æ™ºæ…§åˆç´„å…¬éˆ",
    "Exchange-based Tokens": "äº¤æ˜“æ‰€ä»£å¹£",
    "Stablecoins": "ç©©å®šå¹£"
}


def fetch_sector_ranking():
    """æŠ“å–ä¸»æµæ¿å¡Šæ’è¡Œæ¦œ"""
    url = f"https://api.coingecko.com/api/v3/coins/categories?x_cg_demo_api_key={CG_GECKO_API_KEY}"
    
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            logger.error(f"CoinGecko API éŒ¯èª¤: {response.status_code}")
            return
        
        categories = response.json()
        
        # éæ¿¾ä¸¦ä¸­æ–‡åŒ–
        filtered_sectors = []
        for category in categories:
            if category.get('name') in MAIN_SECTORS:
                filtered_sectors.append({
                    'displayName': MAIN_SECTORS[category['name']],
                    'change': category.get('market_cap_change_24h', 0)
                })
        
        # æ’åº
        filtered_sectors.sort(key=lambda x: x['change'], reverse=True)
        
        send_ranking_to_tg(filtered_sectors)
        
    except Exception as e:
        logger.error(f"æ•¸æ“šæŠ“å–å¤±æ•—: {str(e)}")


def send_ranking_to_tg(ranking: List[Dict]):
    """ç™¼é€æ’è¡Œæ¦œåˆ° Telegram"""
    message = "ğŸ“Š *ã€å…¨çƒä¸»æµåŠ å¯†æ¿å¡Šæ’è¡Œæ¦œã€‘(1H)* \n\n"
    message += "ğŸ”¥ *ä¸»æµæ¿å¡Šå¼·å¼±ä¸€è¦½ï¼š*\n"
    
    for index, sector in enumerate(ranking):
        medal = "ğŸ¥‡" if index == 0 else "ğŸ¥ˆ" if index == 1 else "ğŸ¥‰" if index == 2 else "ğŸ”¹"
        change_str = f"{sector['change']:.2f}"
        emoji = "ğŸ“ˆ" if sector['change'] > 0 else "ğŸ“‰"
        sign = "+" if sector['change'] > 0 else ""
        message += f"{medal} *{sector['displayName']}* `{sign}{change_str}%` {emoji}\n"
    
    message += "\nğŸ”— [æŸ¥çœ‹å®Œæ•´å³æ™‚æ•¸æ“š](https://www.coingecko.com/zh-tw/categories#key-stats) \n"
    message += "\nğŸ’¡ _æ•¸æ“šæºï¼šCoinGecko API_ \n"
    message += "_ç”±å‚‘å…‹ AI æ¯å°æ™‚è‡ªå‹•ç›£æ§è³‡é‡‘æµå‘_"
    
    send_telegram_message(message, TG_THREAD_IDS['sector_ranking'])


# ==================== 2. å·¨é¯¨èˆ‡å¤§æˆ¶æŒå€‰å‹•å‘ ====================

def fetch_global_account_ratio(symbol: str, time_type: str) -> Optional[Dict]:
    """ç²å–å…¨å±€å¸³æˆ¶æ¯”ï¼ˆæ•£æˆ¶æƒ…ç·’ï¼‰"""
    url = f"{CG_API_BASE}/api/futures/global-long-short-account-ratio/history"
    params = {
        "exchange": EXCHANGE,
        "symbol": symbol,
        "interval": time_type
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "Accept": "application/json"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.error(f"å…¨å±€å¸³æˆ¶æ¯” API è«‹æ±‚å¤±æ•— - {symbol}: {response.status_code}")
            return None
        
        data = response.json()
        if data.get('code') not in ['0', 0, 200, '200']:
            logger.error(f"å…¨å±€å¸³æˆ¶æ¯” API è¿”å›éŒ¯èª¤ - {symbol}: {data.get('code')}")
            return None
        
        return data
    except Exception as e:
        logger.error(f"ç²å–å…¨å±€å¸³æˆ¶æ¯”æ™‚ç™¼ç”ŸéŒ¯èª¤ - {symbol}: {str(e)}")
        return None


def fetch_top_account_ratio(symbol: str, time_type: str) -> Optional[Dict]:
    """ç²å–å¤§æˆ¶å¸³æˆ¶æ¯”ï¼ˆå¤§æˆ¶å¸³æˆ¶æ•¸ï¼‰"""
    url = f"{CG_API_BASE}/api/futures/top-long-short-account-ratio/history"
    params = {
        "exchange": EXCHANGE,
        "symbol": symbol,
        "interval": time_type
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "Accept": "application/json"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code != 200:
            return None
        
        data = response.json()
        if data.get('code') not in ['0', 0, 200, '200']:
            return None
        
        return data
    except Exception as e:
        logger.error(f"ç²å–å¤§æˆ¶å¸³æˆ¶æ¯”æ™‚ç™¼ç”ŸéŒ¯èª¤ - {symbol}: {str(e)}")
        return None


def fetch_top_position_ratio(symbol: str, time_type: str) -> Optional[Dict]:
    """ç²å–å¤§æˆ¶æŒå€‰æ¯”ï¼ˆå·¨é¯¨éƒ¨ä½ï¼‰"""
    url = f"{CG_API_BASE}/api/futures/top-long-short-position-ratio/history"
    params = {
        "exchange": EXCHANGE,
        "symbol": symbol,
        "interval": time_type
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "Accept": "application/json"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code != 200:
            return None
        
        data = response.json()
        if data.get('code') not in ['0', 0, 200, '200']:
            return None
        
        return data
    except Exception as e:
        logger.error(f"ç²å–å¤§æˆ¶æŒå€‰æ¯”æ™‚ç™¼ç”ŸéŒ¯èª¤ - {symbol}: {str(e)}")
        return None


def get_latest_data_point(data: Dict) -> Optional[Dict]:
    """å¾ API éŸ¿æ‡‰ä¸­æå–æœ€æ–°çš„æ•¸æ“šé»"""
    if not data or 'data' not in data:
        return None
    
    data_list = data['data']
    if isinstance(data_list, list) and len(data_list) > 0:
        return data_list[-1]
    
    return data_list if isinstance(data_list, dict) else None


def analyze_data(all_data: Dict) -> Optional[Dict]:
    """åˆ†ææ•¸æ“šä¸¦åˆ¤æ–·å¸‚å ´ç‹€æ³ï¼ˆæ”¹é€²ç‰ˆï¼šæ›´åˆç†çš„é–¾å€¼å’Œç™½è©±æè¿°ï¼‰"""
    global_point = get_latest_data_point(all_data.get('global'))
    global_ratio = global_point.get('global_account_long_short_ratio') if global_point else None
    
    top_account_point = get_latest_data_point(all_data.get('topAccount'))
    top_account_ratio = top_account_point.get('top_account_long_short_ratio') if top_account_point else None
    
    top_position_point = get_latest_data_point(all_data.get('topPosition'))
    top_position_ratio = top_position_point.get('top_position_long_short_ratio') if top_position_point else None
    
    if global_ratio is None and top_position_ratio is None:
        logger.warning("ç„¡æ³•æå–å¿…è¦çš„æ•¸æ“šæŒ‡æ¨™")
        return None
    
    # æ”¹é€²çš„è¨ºæ–·é‚è¼¯ï¼šä½¿ç”¨æ›´åˆç†çš„é–¾å€¼ï¼Œä¸¦æä¾›æ›´ç™½è©±çš„æè¿°
    diagnosis = ""
    diagnosis_detail = ""
    risk_level = "ä¸­ç­‰"
    
    # è¨ˆç®—æ•£æˆ¶å’Œå·¨é¯¨çš„å‚¾å‘
    retail_bullish = global_ratio > 1.2 if global_ratio else False
    retail_bearish = global_ratio < 0.9 if global_ratio else False
    whale_bullish = top_position_ratio > 1.15 if top_position_ratio else False
    whale_bearish = top_position_ratio < 0.9 if top_position_ratio else False
    
    # åˆ¤æ–·å¸‚å ´ç‹€æ³
    if global_ratio is not None and top_position_ratio is not None:
        # æƒ…æ³1ï¼šæ•£æˆ¶æ¥µåº¦çœ‹å¤šï¼Œå·¨é¯¨çœ‹ç©ºï¼ˆå±éšªä¿¡è™Ÿï¼‰
        if global_ratio > 1.5 and top_position_ratio < 0.95:
            diagnosis = "âš ï¸ æ•£æˆ¶ç‹‚ç†±ï¼Œå·¨é¯¨æ’¤é€€"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºæ¥µåº¦çœ‹å¤šï¼Œä½†å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºçœ‹ç©ºã€‚é€™æ˜¯å…¸å‹çš„ã€Œæ•£æˆ¶æ¥ç›¤ï¼Œå·¨é¯¨å‡ºè²¨ã€ä¿¡è™Ÿï¼Œåƒ¹æ ¼å¯èƒ½é¢è‡¨å¤§å¹…å›èª¿ã€‚"
            risk_level = "é«˜"
        # æƒ…æ³2ï¼šæ•£æˆ¶ææ…Œï¼Œå·¨é¯¨æŠ„åº•ï¼ˆæ©Ÿæœƒä¿¡è™Ÿï¼‰
        elif global_ratio < 0.85 and top_position_ratio > 1.2:
            diagnosis = "âœ… æ•£æˆ¶ææ…Œï¼Œå·¨é¯¨æŠ„åº•"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºæ¥µåº¦çœ‹ç©ºï¼Œä½†å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºå¼·å‹¢çœ‹å¤šã€‚é€™æ˜¯ã€Œæ•£æˆ¶å‰²è‚‰ï¼Œå·¨é¯¨æƒè²¨ã€çš„åº•éƒ¨ä¿¡è™Ÿï¼Œå¯èƒ½æ˜¯æŠ„åº•æ©Ÿæœƒã€‚"
            risk_level = "ä½"
        # æƒ…æ³3ï¼šæ•£æˆ¶çœ‹å¤šï¼Œå·¨é¯¨ä¹Ÿçœ‹å¤šï¼ˆå¥åº·ä¸Šæ¼²ï¼‰
        elif global_ratio > 1.1 and top_position_ratio > 1.1:
            diagnosis = "ğŸ“ˆ æ•£æˆ¶èˆ‡å·¨é¯¨åŒæ­¥çœ‹å¤š"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} å’Œå·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} éƒ½é¡¯ç¤ºçœ‹å¤šã€‚å¸‚å ´æƒ…ç·’ä¸€è‡´ï¼Œä¸Šæ¼²å‹•èƒ½è¼ƒå¼·ï¼Œä½†éœ€æ³¨æ„éç†±é¢¨éšªã€‚"
            risk_level = "ä¸­ä½"
        # æƒ…æ³4ï¼šæ•£æˆ¶çœ‹ç©ºï¼Œå·¨é¯¨ä¹Ÿçœ‹ç©ºï¼ˆä¸‹è·Œè¶¨å‹¢ï¼‰
        elif global_ratio < 0.95 and top_position_ratio < 0.95:
            diagnosis = "ğŸ“‰ æ•£æˆ¶èˆ‡å·¨é¯¨åŒæ­¥çœ‹ç©º"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} å’Œå·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} éƒ½é¡¯ç¤ºçœ‹ç©ºã€‚å¸‚å ´æƒ…ç·’ä¸€è‡´çœ‹è·Œï¼Œä¸‹è·Œå£“åŠ›è¼ƒå¤§ï¼Œå»ºè­°è¬¹æ…æ“ä½œã€‚"
            risk_level = "é«˜"
        # æƒ…æ³5ï¼šæ•£æˆ¶çœ‹å¤šï¼Œå·¨é¯¨ä¸­æ€§ï¼ˆéœ€è§€å¯Ÿï¼‰
        elif global_ratio > 1.15 and 0.95 <= top_position_ratio <= 1.15:
            diagnosis = "ğŸ” æ•£æˆ¶çœ‹å¤šï¼Œå·¨é¯¨è§€æœ›"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºçœ‹å¤šï¼Œä½†å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} ä¿æŒä¸­æ€§ã€‚å·¨é¯¨å¯èƒ½åœ¨ç­‰å¾…æ›´å¥½çš„é€²å ´æ™‚æ©Ÿï¼Œéœ€å¯†åˆ‡è§€å¯Ÿã€‚"
            risk_level = "ä¸­"
        # æƒ…æ³6ï¼šæ•£æˆ¶çœ‹ç©ºï¼Œå·¨é¯¨ä¸­æ€§ï¼ˆéœ€è§€å¯Ÿï¼‰
        elif global_ratio < 0.9 and 0.95 <= top_position_ratio <= 1.15:
            diagnosis = "ğŸ” æ•£æˆ¶çœ‹ç©ºï¼Œå·¨é¯¨è§€æœ›"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºçœ‹ç©ºï¼Œä½†å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} ä¿æŒä¸­æ€§ã€‚å·¨é¯¨å¯èƒ½åœ¨ç­‰å¾…æ›´å¥½çš„é€²å ´æ™‚æ©Ÿï¼Œéœ€å¯†åˆ‡è§€å¯Ÿã€‚"
            risk_level = "ä¸­"
        # æƒ…æ³7ï¼šæ•£æˆ¶ä¸­æ€§ï¼Œå·¨é¯¨çœ‹å¤šï¼ˆæ©Ÿæœƒä¿¡è™Ÿï¼‰
        elif 0.95 <= global_ratio <= 1.15 and top_position_ratio > 1.15:
            diagnosis = "ğŸ’ æ•£æˆ¶ä¸­æ€§ï¼Œå·¨é¯¨çœ‹å¤š"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} ä¿æŒä¸­æ€§ï¼Œä½†å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºå¼·å‹¢çœ‹å¤šã€‚å·¨é¯¨å¯èƒ½æå‰å¸ƒå±€ï¼Œé€™æ˜¯è¼ƒå¥½çš„è·Ÿéš¨ä¿¡è™Ÿã€‚"
            risk_level = "ä¸­ä½"
        # æƒ…æ³8ï¼šæ•£æˆ¶ä¸­æ€§ï¼Œå·¨é¯¨çœ‹ç©ºï¼ˆè­¦å‘Šä¿¡è™Ÿï¼‰
        elif 0.95 <= global_ratio <= 1.15 and top_position_ratio < 0.9:
            diagnosis = "âš ï¸ æ•£æˆ¶ä¸­æ€§ï¼Œå·¨é¯¨çœ‹ç©º"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} ä¿æŒä¸­æ€§ï¼Œä½†å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºçœ‹ç©ºã€‚å·¨é¯¨å¯èƒ½æå‰æ¸›å€‰ï¼Œéœ€è­¦æƒ•ä¸‹è·Œé¢¨éšªã€‚"
            risk_level = "ä¸­é«˜"
        # æƒ…æ³9ï¼šé›™æ–¹éƒ½æ¥è¿‘ä¸­æ€§ï¼ˆå¹³è¡¡ç‹€æ…‹ï¼‰
        else:
            diagnosis = "âš–ï¸ å¸‚å ´å¹³è¡¡"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} å’Œå·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} éƒ½æ¥è¿‘ä¸­æ€§ã€‚å¸‚å ´è™•æ–¼å¹³è¡¡ç‹€æ…‹ï¼Œç­‰å¾…æ˜ç¢ºæ–¹å‘ã€‚"
            risk_level = "ä¸­ç­‰"
    elif global_ratio is not None:
        # åªæœ‰æ•£æˆ¶æ•¸æ“š
        if global_ratio > 1.3:
            diagnosis = "ğŸ‘¤ æ•£æˆ¶æ¥µåº¦çœ‹å¤š"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºæ¥µåº¦çœ‹å¤šï¼Œå¸‚å ´æƒ…ç·’éç†±ï¼Œéœ€è­¦æƒ•å›èª¿é¢¨éšªã€‚"
            risk_level = "ä¸­é«˜"
        elif global_ratio > 1.1:
            diagnosis = "ğŸ‘¤ æ•£æˆ¶çœ‹å¤š"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºçœ‹å¤šï¼Œå¸‚å ´æƒ…ç·’åæ¨‚è§€ã€‚"
            risk_level = "ä¸­"
        elif global_ratio < 0.8:
            diagnosis = "ğŸ‘¤ æ•£æˆ¶æ¥µåº¦çœ‹ç©º"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºæ¥µåº¦çœ‹ç©ºï¼Œå¸‚å ´æƒ…ç·’ææ…Œï¼Œå¯èƒ½æ˜¯åº•éƒ¨ä¿¡è™Ÿã€‚"
            risk_level = "ä¸­"
        elif global_ratio < 0.95:
            diagnosis = "ğŸ‘¤ æ•£æˆ¶çœ‹ç©º"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} é¡¯ç¤ºçœ‹ç©ºï¼Œå¸‚å ´æƒ…ç·’åæ‚²è§€ã€‚"
            risk_level = "ä¸­"
        else:
            diagnosis = "ğŸ‘¤ æ•£æˆ¶ä¸­æ€§"
            diagnosis_detail = f"æ•£æˆ¶å¤šç©ºæ¯” {global_ratio:.2f} æ¥è¿‘ä¸­æ€§ï¼Œå¸‚å ´æƒ…ç·’å¹³è¡¡ã€‚"
            risk_level = "ä¸­ç­‰"
    elif top_position_ratio is not None:
        # åªæœ‰å·¨é¯¨æ•¸æ“š
        if top_position_ratio > 1.3:
            diagnosis = "ğŸ³ å·¨é¯¨å¼·å‹¢çœ‹å¤š"
            diagnosis_detail = f"å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºå¼·å‹¢çœ‹å¤šï¼Œå¤§æˆ¶ç©æ¥µå»ºå€‰ï¼Œå¯èƒ½æ˜¯ä¸Šæ¼²ä¿¡è™Ÿã€‚"
            risk_level = "ä½"
        elif top_position_ratio > 1.1:
            diagnosis = "ğŸ³ å·¨é¯¨çœ‹å¤š"
            diagnosis_detail = f"å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºçœ‹å¤šï¼Œå¤§æˆ¶å‚¾å‘åšå¤šã€‚"
            risk_level = "ä¸­ä½"
        elif top_position_ratio < 0.8:
            diagnosis = "ğŸ³ å·¨é¯¨å¼·å‹¢çœ‹ç©º"
            diagnosis_detail = f"å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºå¼·å‹¢çœ‹ç©ºï¼Œå¤§æˆ¶ç©æ¥µæ¸›å€‰ï¼Œéœ€è­¦æƒ•ä¸‹è·Œé¢¨éšªã€‚"
            risk_level = "é«˜"
        elif top_position_ratio < 0.95:
            diagnosis = "ğŸ³ å·¨é¯¨çœ‹ç©º"
            diagnosis_detail = f"å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} é¡¯ç¤ºçœ‹ç©ºï¼Œå¤§æˆ¶å‚¾å‘åšç©ºã€‚"
            risk_level = "ä¸­é«˜"
        else:
            diagnosis = "ğŸ³ å·¨é¯¨ä¸­æ€§"
            diagnosis_detail = f"å·¨é¯¨æŒå€‰æ¯” {top_position_ratio:.2f} æ¥è¿‘ä¸­æ€§ï¼Œå¤§æˆ¶ä¿æŒè§€æœ›ã€‚"
            risk_level = "ä¸­ç­‰"
    else:
        diagnosis = "â“ æ•¸æ“šä¸è¶³"
        diagnosis_detail = "ç„¡æ³•ç²å–è¶³å¤ çš„æ•¸æ“šé€²è¡Œåˆ†æã€‚"
        risk_level = "æœªçŸ¥"
    
    return {
        'globalRatio': global_ratio,
        'topAccountRatio': top_account_ratio,
        'topPositionRatio': top_position_ratio,
        'diagnosis': diagnosis,
        'diagnosisDetail': diagnosis_detail,
        'riskLevel': risk_level
    }


def format_symbol_message(symbol: str, analysis: Dict) -> str:
    """æ ¼å¼åŒ–å–®å€‹å¹£ç¨®çš„è¨Šæ¯ç‰‡æ®µï¼ˆæ”¹é€²ç‰ˆï¼šæ›´ç™½è©±ã€æ›´ç›´è§€ï¼‰"""
    coin_symbol = symbol.replace("USDT", "")
    message = f"\nğŸ‹ ã€{coin_symbol}ã€‘\n"
    message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    
    # é¡¯ç¤ºæ•¸æ“šæŒ‡æ¨™ï¼ˆç°¡åŒ–é¡¯ç¤ºï¼‰
    if analysis.get('globalRatio') is not None:
        gr = analysis['globalRatio']
        # ç”¨æ›´ç›´è§€çš„æ–¹å¼é¡¯ç¤º
        if gr > 1.2:
            emoji = "ğŸ”¥"
            status = "æ¥µåº¦çœ‹å¤š"
        elif gr > 1.05:
            emoji = "ğŸ“ˆ"
            status = "çœ‹å¤š"
        elif gr < 0.85:
            emoji = "â„ï¸"
            status = "æ¥µåº¦çœ‹ç©º"
        elif gr < 0.95:
            emoji = "ğŸ“‰"
            status = "çœ‹ç©º"
        else:
            emoji = "â¡ï¸"
            status = "ä¸­æ€§"
        message += f"ğŸ‘¤ æ•£æˆ¶æƒ…ç·’ï¼š{emoji} {status} (å¤šç©ºæ¯” {gr:.2f})\n"
    
    if analysis.get('topAccountRatio') is not None:
        tar = analysis['topAccountRatio']
        message += f"ğŸ“Š å¤§æˆ¶å¸³æˆ¶æ¯”ï¼š{tar:.2f}\n"
    
    if analysis.get('topPositionRatio') is not None:
        tpr = analysis['topPositionRatio']
        # ç”¨æ›´ç›´è§€çš„æ–¹å¼é¡¯ç¤º
        if tpr > 1.2:
            emoji = "ğŸŸ¢"
            status = "å¼·å‹¢çœ‹å¤š"
        elif tpr > 1.05:
            emoji = "ğŸŸ¡"
            status = "çœ‹å¤š"
        elif tpr < 0.85:
            emoji = "ğŸ”´"
            status = "å¼·å‹¢çœ‹ç©º"
        elif tpr < 0.95:
            emoji = "ğŸŸ "
            status = "çœ‹ç©º"
        else:
            emoji = "âšª"
            status = "ä¸­æ€§"
        message += f"ğŸ³ å·¨é¯¨éƒ¨ä½ï¼š{emoji} {status} (æŒå€‰æ¯” {tpr:.2f})\n"
    
    # é¡¯ç¤ºè¨ºæ–·çµæœï¼ˆæ›´çªå‡ºï¼‰
    message += f"\nğŸš© å¸‚å ´è¨ºæ–·ï¼š\n"
    message += f"   {analysis.get('diagnosis', 'ç„¡æ³•åˆ¤æ–·')}\n"
    
    if analysis.get('diagnosisDetail'):
        message += f"\nğŸ’¡ è§£è®€ï¼š\n"
        message += f"   {analysis['diagnosisDetail']}\n"
    
    # é¡¯ç¤ºé¢¨éšªç­‰ç´š
    risk_level = analysis.get('riskLevel', 'æœªçŸ¥')
    risk_emoji = {
        'ä½': 'ğŸŸ¢',
        'ä¸­ä½': 'ğŸŸ¡',
        'ä¸­ç­‰': 'ğŸŸ ',
        'ä¸­é«˜': 'ğŸŸ ',
        'é«˜': 'ğŸ”´',
        'æœªçŸ¥': 'âšª'
    }
    message += f"\nâš ï¸ é¢¨éšªç­‰ç´šï¼š{risk_emoji.get(risk_level, 'âšª')} {risk_level}\n"
    
    return message


def fetch_stablecoin_marketcap_history() -> Optional[List[Dict]]:
    """ç²å–ç©©å®šå¹£å¸‚å€¼æ­·å²æ•¸æ“š"""
    url = "https://open-api-v4.coinglass.com/api/index/stableCoin-marketCap-history"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        logger.info(f"æ­£åœ¨èª¿ç”¨ç©©å®šå¹£å¸‚å€¼ API: {url}")
        response = requests.get(url, headers=headers, timeout=10)
        logger.info(f"ç©©å®šå¹£å¸‚å€¼ API éŸ¿æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
        
        if response.status_code != 200:
            logger.error(f"ç©©å®šå¹£å¸‚å€¼ API è¿”å›ç‹€æ…‹ç¢¼: {response.status_code}")
            logger.error(f"éŸ¿æ‡‰å…§å®¹: {response.text[:500]}")
            return None
        
        data = response.json()
        logger.info(f"ç©©å®šå¹£å¸‚å€¼ API è¿”å›æ•¸æ“šçµæ§‹: code={data.get('code')}, msg={data.get('msg')}")
        # è¼¸å‡ºå®Œæ•´çš„æ•¸æ“šçµæ§‹ä»¥ä¾¿èª¿è©¦
        logger.info(f"å®Œæ•´éŸ¿æ‡‰çµæ§‹ï¼ˆå‰2000å­—ç¬¦ï¼‰: {json.dumps(data, ensure_ascii=False, indent=2)[:2000]}")
        
        # æª¢æŸ¥è¿”å›ç¢¼
        if data.get('code') not in ['0', 0, 200, '200', None]:
            error_msg = data.get('msg') or data.get('message') or 'æœªçŸ¥éŒ¯èª¤'
            logger.error(f"ç©©å®šå¹£å¸‚å€¼ API è¿”å›éŒ¯èª¤: {error_msg} (code: {data.get('code')})")
            return None
        
        # è¿”å›æ•¸æ“šåˆ—è¡¨ï¼ˆæ ¹æ“šå¯¦éš› API éŸ¿æ‡‰çµæ§‹ï¼‰
        # API è¿”å›çµæ§‹: { "code": "0", "data": { "data_list": [...] } }
        data_content = data.get('data')
        
        if isinstance(data_content, dict):
            # æª¢æŸ¥ data_list å­—æ®µ
            data_list = data_content.get('data_list')
            if isinstance(data_list, list) and len(data_list) > 0:
                logger.info(f"æˆåŠŸç²å–ç©©å®šå¹£å¸‚å€¼æ•¸æ“š: {len(data_list)} æ¢è¨˜éŒ„")
                # è½‰æ›æ•¸æ“šæ ¼å¼ï¼šå°‡æ¯å€‹ { "USDT": value } è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
                formatted_list = []
                for idx, item in enumerate(data_list):
                    if isinstance(item, dict):
                        # è¨ˆç®—ç¸½å¸‚å€¼ï¼ˆåŠ ç¸½æ‰€æœ‰ç©©å®šå¹£ï¼‰
                        total_mcap = sum(float(v) for v in item.values() if isinstance(v, (int, float)))
                        # æˆ–è€…åªå– USDTï¼ˆæ ¹æ“šéœ€æ±‚ï¼‰
                        usdt_mcap = item.get('USDT') or item.get('usdt') or 0
                        
                        # ä½¿ç”¨ç¸½å¸‚å€¼æˆ– USDT å¸‚å€¼ï¼ˆå„ªå…ˆä½¿ç”¨ç¸½å¸‚å€¼ï¼‰
                        mcap_value = total_mcap if total_mcap > 0 else float(usdt_mcap)
                        
                        # æ§‹å»ºæ¨™æº–æ ¼å¼çš„æ•¸æ“šé»
                        # æ³¨æ„ï¼šAPI å¯èƒ½æ²’æœ‰æ™‚é–“æˆ³ï¼Œä½¿ç”¨ç´¢å¼•ä½œç‚ºæ™‚é–“é †åºï¼ˆæœ€æ–°çš„åœ¨æœ€å¾Œï¼‰
                        formatted_item = {
                            'marketCap': mcap_value,
                            'market_cap': mcap_value,
                            'value': mcap_value,
                            'time': None,  # å¦‚æœ API æ²’æœ‰æä¾›æ™‚é–“æˆ³
                            'timestamp': None,
                            'index': idx  # ç”¨æ–¼æ’åº
                        }
                        formatted_list.append(formatted_item)
                
                logger.info(f"æ ¼å¼åŒ–å¾Œçš„æ•¸æ“š: {len(formatted_list)} æ¢è¨˜éŒ„")
                return formatted_list
        
        # å¦‚æœ data æ˜¯åˆ—è¡¨ï¼Œç›´æ¥è¿”å›ï¼ˆä½†éœ€è¦æ ¼å¼åŒ–ï¼‰
        if isinstance(data_content, list) and len(data_content) > 0:
            logger.info(f"data æ˜¯åˆ—è¡¨ï¼Œç›´æ¥è¿”å›: {len(data_content)} æ¢è¨˜éŒ„")
            return data_content
        
        # å˜—è©¦å…¶ä»–å¯èƒ½çš„å­—æ®µ
        for key in ['data_list', 'list', 'items', 'history', 'marketCap', 'market_cap', 'values', 'records']:
            if key in data:
                value = data[key]
                if isinstance(value, list) and len(value) > 0:
                    logger.info(f"å¾ {key} å­—æ®µç²å–æ•¸æ“š: {len(value)} æ¢è¨˜éŒ„")
                    return value
        
        # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œè¨˜éŒ„å®Œæ•´çš„æ•¸æ“šçµæ§‹ä»¥ä¾¿èª¿è©¦
        logger.warning(f"ç©©å®šå¹£å¸‚å€¼ API è¿”å›çš„æ•¸æ“šæ ¼å¼ä¸ç¬¦åˆé æœŸ")
        logger.info(f"æ•¸æ“šé¡å‹: {type(data_content)}")
        if isinstance(data_content, dict):
            logger.info(f"data å­—å…¸çš„éµ: {list(data_content.keys())}")
        logger.info(f"æ•¸æ“šçµæ§‹ï¼ˆå‰1000å­—ç¬¦ï¼‰: {json.dumps(data, ensure_ascii=False, indent=2)[:1000]}")
        return None
    except requests.exceptions.RequestException as e:
        logger.error(f"ç©©å®šå¹£å¸‚å€¼ API è«‹æ±‚å¤±æ•—: {str(e)}")
        return None
    except json.JSONDecodeError as e:
        logger.error(f"ç©©å®šå¹£å¸‚å€¼ API éŸ¿æ‡‰ JSON è§£æå¤±æ•—: {str(e)}")
        logger.error(f"éŸ¿æ‡‰å…§å®¹: {response.text[:500] if 'response' in locals() else 'N/A'}")
        return None
    except Exception as e:
        logger.error(f"ç²å–ç©©å®šå¹£å¸‚å€¼æ­·å²å¤±æ•—: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def fetch_aggregated_stablecoin_oi_history(symbol: str = "BTC", interval: str = "1h") -> Optional[List[Dict]]:
    """ç²å–èšåˆç©©å®šå¹£ä¿è­‰é‡‘æŒå€‰æ­·å²æ•¸æ“š"""
    url = "https://open-api-v4.coinglass.com/api/futures/open-interest/aggregated-stablecoin-history"
    params = {
        "exchange_list": "Binance",
        "symbol": symbol,
        "interval": interval
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.error(f"ç©©å®šå¹£ OI API è¿”å›ç‹€æ…‹ç¢¼: {response.status_code}")
            return None
        
        data = response.json()
        if data.get('code') not in ['0', 0, 200, '200']:
            logger.error(f"ç©©å®šå¹£ OI API è¿”å›éŒ¯èª¤: {data.get('msg')}")
            return None
        
        # è¿”å›æ•¸æ“šåˆ—è¡¨
        data_list = data.get('data', [])
        if isinstance(data_list, list):
            return data_list
        return None
    except Exception as e:
        logger.error(f"ç²å–ç©©å®šå¹£ OI æ­·å²å¤±æ•—: {str(e)}")
        return None


def calculate_marketcap_change(data_list: List[Dict]) -> Optional[Dict]:
    """è¨ˆç®—ç©©å®šå¹£å¸‚å€¼è®ŠåŒ–ç‡ï¼ˆ1å°æ™‚å’Œ24å°æ™‚ï¼‰"""
    if not data_list or len(data_list) < 2:
        return None
    
    # æŒ‰æ™‚é–“æˆ³æˆ–ç´¢å¼•æ’åºï¼ˆæœ€æ–°çš„åœ¨æœ€å¾Œï¼‰
    def get_sort_key(item):
        time_val = item.get('time') or item.get('timestamp')
        if time_val is not None:
            return time_val
        # å¦‚æœæ²’æœ‰æ™‚é–“æˆ³ï¼Œä½¿ç”¨ç´¢å¼•
        index_val = item.get('index')
        if index_val is not None:
            return index_val
        # å¦‚æœéƒ½æ²’æœ‰ï¼Œè¿”å› 0ï¼ˆä¿æŒåŸé †åºï¼‰
        return 0
    
    sorted_data = sorted(data_list, key=get_sort_key)
    
    # ç²å–æœ€æ–°å€¼
    latest = sorted_data[-1]
    latest_mcap = latest.get('marketCap') or latest.get('market_cap') or latest.get('value')
    
    if latest_mcap is None:
        return None
    
    # è¨ˆç®—1å°æ™‚å’Œ24å°æ™‚è®ŠåŒ–
    # å¦‚æœæ•¸æ“šæ²’æœ‰æ™‚é–“æˆ³ï¼Œä½¿ç”¨æ•¸æ“šé»ç´¢å¼•ä¾†ä¼°ç®—
    # å‡è¨­æ•¸æ“šæ˜¯æ¯å°æ™‚ä¸€å€‹é»ï¼ˆæˆ–æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´ï¼‰
    one_hour_data = None
    twenty_four_hours_data = None
    
    if len(sorted_data) >= 2:
        # å¦‚æœæ•¸æ“šæœ‰æ™‚é–“æˆ³ï¼Œä½¿ç”¨æ™‚é–“æˆ³
        if sorted_data[0].get('time') or sorted_data[0].get('timestamp'):
            now = get_taipei_time()
            one_hour_ago = now - timedelta(hours=1)
            one_hour_ago_ts = int(one_hour_ago.timestamp() * 1000)
            
            twenty_four_hours_ago = now - timedelta(hours=24)
            twenty_four_hours_ago_ts = int(twenty_four_hours_ago.timestamp() * 1000)
            
            for item in sorted_data:
                item_time = item.get('time') or item.get('timestamp', 0)
                if item_time <= one_hour_ago_ts:
                    one_hour_data = item
                if item_time <= twenty_four_hours_ago_ts:
                    twenty_four_hours_data = item
                else:
                    break
        else:
            # å¦‚æœæ²’æœ‰æ™‚é–“æˆ³ï¼Œä½¿ç”¨ç´¢å¼•ä¾†ä¼°ç®—ï¼ˆå‡è¨­æ•¸æ“šæ˜¯æ¯å°æ™‚ä¸€å€‹é»ï¼‰
            # 1å°æ™‚å‰ = å€’æ•¸ç¬¬2å€‹é»ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            if len(sorted_data) >= 2:
                one_hour_data = sorted_data[-2]
            # 24å°æ™‚å‰ = å€’æ•¸ç¬¬25å€‹é»ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            if len(sorted_data) >= 25:
                twenty_four_hours_data = sorted_data[-25]
            elif len(sorted_data) >= 2:
                # å¦‚æœæ•¸æ“šé»ä¸è¶³24å€‹ï¼Œä½¿ç”¨æœ€æ—©çš„æ•¸æ“šé»
                twenty_four_hours_data = sorted_data[0]
    
    result = {
        'latest_mcap': float(latest_mcap),
        'change_1h': None,
        'change_24h': None
    }
    
    # è¨ˆç®—1å°æ™‚è®ŠåŒ–ç‡
    if one_hour_data:
        one_hour_mcap = one_hour_data.get('marketCap') or one_hour_data.get('market_cap') or one_hour_data.get('value')
        if one_hour_mcap and one_hour_mcap > 0:
            result['change_1h'] = ((latest_mcap - one_hour_mcap) / one_hour_mcap) * 100
    
    # è¨ˆç®—24å°æ™‚è®ŠåŒ–ç‡
    if twenty_four_hours_data:
        twenty_four_hours_mcap = twenty_four_hours_data.get('marketCap') or twenty_four_hours_data.get('market_cap') or twenty_four_hours_data.get('value')
        if twenty_four_hours_mcap and twenty_four_hours_mcap > 0:
            result['change_24h'] = ((latest_mcap - twenty_four_hours_mcap) / twenty_four_hours_mcap) * 100
    
    return result


def calculate_oi_change(data_list: List[Dict]) -> Optional[Dict]:
    """è¨ˆç®—ç©©å®šå¹£ OI è®ŠåŒ–ç‡ï¼ˆ1å°æ™‚å’Œ24å°æ™‚ï¼‰"""
    if not data_list or len(data_list) < 2:
        return None
    
    # æŒ‰æ™‚é–“æˆ³æ’åº
    sorted_data = sorted(data_list, key=lambda x: x.get('time', 0) or x.get('timestamp', 0))
    
    # ç²å–æœ€æ–°å€¼ï¼ˆä½¿ç”¨ close æˆ– valueï¼‰
    latest = sorted_data[-1]
    latest_oi = latest.get('close') or latest.get('value') or latest.get('openInterest')
    
    if latest_oi is None:
        return None
    
    # è¨ˆç®—1å°æ™‚è®ŠåŒ–
    now = get_taipei_time()
    one_hour_ago = now - timedelta(hours=1)
    one_hour_ago_ts = int(one_hour_ago.timestamp() * 1000)
    
    one_hour_data = None
    for item in sorted_data:
        item_time = item.get('time') or item.get('timestamp', 0)
        if item_time <= one_hour_ago_ts:
            one_hour_data = item
        else:
            break
    
    # è¨ˆç®—24å°æ™‚è®ŠåŒ–
    twenty_four_hours_ago = now - timedelta(hours=24)
    twenty_four_hours_ago_ts = int(twenty_four_hours_ago.timestamp() * 1000)
    
    twenty_four_hours_data = None
    for item in sorted_data:
        item_time = item.get('time') or item.get('timestamp', 0)
        if item_time <= twenty_four_hours_ago_ts:
            twenty_four_hours_data = item
        else:
            break
    
    result = {
        'latest_oi': float(latest_oi),
        'change_1h': None,
        'change_24h': None
    }
    
    # è¨ˆç®—1å°æ™‚è®ŠåŒ–ç‡
    if one_hour_data:
        one_hour_oi = one_hour_data.get('close') or one_hour_data.get('value') or one_hour_data.get('openInterest')
        if one_hour_oi and one_hour_oi > 0:
            result['change_1h'] = ((latest_oi - one_hour_oi) / one_hour_oi) * 100
    
    # è¨ˆç®—24å°æ™‚è®ŠåŒ–ç‡
    if twenty_four_hours_data:
        twenty_four_hours_oi = twenty_four_hours_data.get('close') or twenty_four_hours_data.get('value') or twenty_four_hours_data.get('openInterest')
        if twenty_four_hours_oi and twenty_four_hours_oi > 0:
            result['change_24h'] = ((latest_oi - twenty_four_hours_oi) / twenty_four_hours_oi) * 100
    
    return result


def buying_power_monitor():
    """è³¼è²·åŠ›ç›£æ§ï¼šç›£æ§ç©©å®šå¹£å¸‚å€¼å’Œèšåˆç©©å®šå¹£ä¿è­‰é‡‘æŒå€‰"""
    logger.info("é–‹å§‹åŸ·è¡Œè³¼è²·åŠ›ç›£æ§...")
    
    # 1. ç²å–ç©©å®šå¹£å¸‚å€¼æ­·å²
    marketcap_data = fetch_stablecoin_marketcap_history()
    if not marketcap_data:
        logger.warning("ç„¡æ³•ç²å–ç©©å®šå¹£å¸‚å€¼æ•¸æ“š")
        return
    
    # 2. è¨ˆç®—å¸‚å€¼è®ŠåŒ–ç‡
    mcap_change = calculate_marketcap_change(marketcap_data)
    if not mcap_change:
        logger.warning("ç„¡æ³•è¨ˆç®—ç©©å®šå¹£å¸‚å€¼è®ŠåŒ–ç‡")
        return
    
    # 3. ç²å–ç©©å®šå¹£ OI æ­·å²
    oi_data = fetch_aggregated_stablecoin_oi_history("BTC", "1h")
    if not oi_data:
        logger.warning("ç„¡æ³•ç²å–ç©©å®šå¹£ OI æ•¸æ“š")
        return
    
    # 4. è¨ˆç®— OI è®ŠåŒ–ç‡
    oi_change = calculate_oi_change(oi_data)
    if not oi_change:
        logger.warning("ç„¡æ³•è¨ˆç®—ç©©å®šå¹£ OI è®ŠåŒ–ç‡")
        return
    
    # 5. åˆ¤æ–·æ˜¯å¦éœ€è¦æ¨æ’­ï¼ˆæ”¾å¯¬æ¢ä»¶ï¼‰
    should_alert = False
    alert_type = []
    
    # å¸‚å€¼å¢åŠ  > 0.05%ï¼ˆæ”¾å¯¬å¾ 0.1% åˆ° 0.05%ï¼‰
    if mcap_change.get('change_1h') is not None and mcap_change['change_1h'] > 0.05:
        should_alert = True
        alert_type.append("è³‡é‡‘é€²å ´")
    elif mcap_change.get('change_24h') is not None and mcap_change['change_24h'] > 0.05:
        should_alert = True
        alert_type.append("è³‡é‡‘é€²å ´")
    
    # OI æš´å¢ > 1%ï¼ˆæ”¾å¯¬å¾ 2% åˆ° 1%ï¼‰
    if oi_change.get('change_1h') is not None and oi_change['change_1h'] > 1.0:
        should_alert = True
        alert_type.append("æ§“æ¡¿å †ç©")
    elif oi_change.get('change_24h') is not None and oi_change['change_24h'] > 1.0:
        should_alert = True
        alert_type.append("æ§“æ¡¿å †ç©")
    
    # å¦‚æœæ²’æœ‰è§¸ç™¼è­¦å ±æ¢ä»¶ï¼Œä»ç„¶æ¨æ’­æ•¸æ“šï¼ˆä½†æ¨™è¨»ç‚ºæ­£å¸¸ç‹€æ…‹ï¼‰
    # é€™æ¨£ç”¨æˆ¶å¯ä»¥æŒçºŒç›£æ§è³¼è²·åŠ›è®ŠåŒ–
    if not should_alert:
        logger.info(f"æœªè§¸ç™¼è­¦å ±æ¢ä»¶ï¼Œä½†ä»æ¨æ’­ç•¶å‰æ•¸æ“šä¾›ç›£æ§")
        logger.info(f"å¸‚å€¼è®ŠåŒ–: 1h={mcap_change.get('change_1h')}, 24h={mcap_change.get('change_24h')}")
        logger.info(f"OI è®ŠåŒ–: 1h={oi_change.get('change_1h')}, 24h={oi_change.get('change_24h')}")
        # ä¸ returnï¼Œç¹¼çºŒæ§‹å»ºæ¨æ’­è¨Šæ¯
    
    # 6. æ§‹å»ºæ¨æ’­è¨Šæ¯
    now = get_taipei_time()
    time_str = format_datetime(now)
    
    lines = []
    lines.append("ğŸ’° *ã€è³¼è²·åŠ›ç›£æ§ã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    
    # ç©©å®šå¹£å¸‚å€¼
    lines.append("ğŸ“Š *ç©©å®šå¹£å¸‚å€¼*ï¼š")
    if mcap_change.get('latest_mcap'):
        mcap_b = mcap_change['latest_mcap'] / 1_000_000_000  # è½‰æ›ç‚ºåå„„
        lines.append(f"ç•¶å‰å¸‚å€¼ï¼š*{mcap_b:.2f}B USD*")
    
    if mcap_change.get('change_1h') is not None:
        change_1h = mcap_change['change_1h']
        emoji = "ğŸ“ˆ" if change_1h > 0 else "ğŸ“‰"
        lines.append(f"{emoji} 1å°æ™‚è®ŠåŒ–ï¼š*{change_1h:+.2f}%*")
    
    if mcap_change.get('change_24h') is not None:
        change_24h = mcap_change['change_24h']
        emoji = "ğŸ“ˆ" if change_24h > 0 else "ğŸ“‰"
        lines.append(f"{emoji} 24å°æ™‚è®ŠåŒ–ï¼š*{change_24h:+.2f}%*")
    
    lines.append("")
    
    # ç©©å®šå¹£ OI
    lines.append("âš¡ *èšåˆç©©å®šå¹£ä¿è­‰é‡‘æŒå€‰*ï¼š")
    if oi_change.get('latest_oi'):
        oi_b = oi_change['latest_oi'] / 1_000_000_000  # è½‰æ›ç‚ºåå„„
        lines.append(f"ç•¶å‰æŒå€‰ï¼š*{oi_b:.2f}B USD*")
    
    if oi_change.get('change_1h') is not None:
        change_1h = oi_change['change_1h']
        emoji = "ğŸ“ˆ" if change_1h > 0 else "ğŸ“‰"
        lines.append(f"{emoji} 1å°æ™‚è®ŠåŒ–ï¼š*{change_1h:+.2f}%*")
    
    if oi_change.get('change_24h') is not None:
        change_24h = oi_change['change_24h']
        emoji = "ğŸ“ˆ" if change_24h > 0 else "ğŸ“‰"
        lines.append(f"{emoji} 24å°æ™‚è®ŠåŒ–ï¼š*{change_24h:+.2f}%*")
    
    lines.append("")
    
    # è­¦å ±æç¤ºï¼ˆå¦‚æœæœ‰è§¸ç™¼ï¼‰
    if alert_type:
        lines.append("ğŸš¨ *è­¦å ±é¡å‹*ï¼š")
        for alert in alert_type:
            if alert == "è³‡é‡‘é€²å ´":
                lines.append("âœ… è³‡é‡‘é€²å ´ï¼šå ´å¤–è³‡é‡‘ï¼ˆFiatï¼‰å…Œæ›æˆç©©å®šå¹£æº–å‚™è²·å…¥")
            elif alert == "æ§“æ¡¿å †ç©":
                lines.append("âš ï¸ æ§“æ¡¿å †ç©ï¼šå ´å…§è³‡é‡‘æ­£åœ¨ä½¿ç”¨ç©©å®šå¹£ä½œç‚ºä¿è­‰é‡‘é–‹å¤šå–®")
        lines.append("")
    
    # èˆ¹é•·è§£è®€
    lines.append("ğŸ’¡ *èˆ¹é•·è§£è®€*ï¼š")
    if alert_type:
        if "è³‡é‡‘é€²å ´" in alert_type and "æ§“æ¡¿å †ç©" in alert_type:
            lines.append("å¸‚å€¼ä¸Šå‡ + OI ä¸Šå‡ = é›™é‡åˆ©å¥½ï¼Œå¸‚å ´è³‡é‡‘å……è£•ä¸”æ§“æ¡¿æ´»èºï¼Œä¸Šæ¼²å‹•èƒ½å¼·å‹ã€‚")
        elif "è³‡é‡‘é€²å ´" in alert_type:
            lines.append("å¸‚å€¼ä¸Šå‡ä»£è¡¨å ´å¤–è³‡é‡‘æµå…¥ï¼Œé€™æ˜¯é•·ç·šåˆ©å¥½ä¿¡è™Ÿï¼Œé ç¤ºå¾ŒçºŒè²·ç›¤æ”¯æ’ã€‚")
        elif "æ§“æ¡¿å †ç©" in alert_type:
            lines.append("OI æš´å¢é ç¤ºæ³¢å‹•å°‡è‡³ï¼Œéœ€æ³¨æ„æ§“æ¡¿é¢¨éšªï¼Œå¯èƒ½å‡ºç¾åŠ‡çƒˆæ³¢å‹•ã€‚")
    else:
        # æ²’æœ‰è§¸ç™¼è­¦å ±æ™‚çš„æç¤º
        lines.append("ç›®å‰è³¼è²·åŠ›è®ŠåŒ–åœ¨æ­£å¸¸ç¯„åœå…§ï¼ˆå¸‚å€¼è®ŠåŒ– <= 0.05%ï¼ŒOI è®ŠåŒ– <= 1%ï¼‰ã€‚")
        lines.append("æŒçºŒç›£æ§ä¸­ï¼Œå¦‚æœ‰ç•°å¸¸è®ŠåŒ–å°‡åŠæ™‚é€šçŸ¥ã€‚")
    
    lines.append("")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"â° æ›´æ–°æ™‚é–“ï¼š{time_str}")
    
    message = "\n".join(lines)
    send_telegram_message(message, TG_THREAD_IDS.get('buying_power_monitor', 246), parse_mode="Markdown")
    logger.info("è³¼è²·åŠ›ç›£æ§æ¨æ’­å®Œæˆ")


# ä¿ç•™èˆŠå‡½æ•¸åç¨±ä»¥å‘å¾Œå…¼å®¹
def fetch_whale_position():
    """å·²å»¢æ£„ï¼šè«‹ä½¿ç”¨ buying_power_monitor()"""
    logger.warning("fetch_whale_position() å·²å»¢æ£„ï¼Œè«‹ä½¿ç”¨ buying_power_monitor()")
    buying_power_monitor()


def fetch_whale_position_old():
    """ä¸»åŸ·è¡Œå‡½æ•¸ï¼šå·¨é¯¨æŒå€‰ç›£æ§ï¼ˆèˆŠç‰ˆæœ¬ï¼Œä¿ç•™ä½œç‚ºå‚™ä»½ï¼‰"""
    logger.info("é–‹å§‹åŸ·è¡Œå·¨é¯¨æŒå€‰ç›£æ§...")
    
    all_analyses = []
    
    for symbol in SYMBOLS:
        try:
            logger.info(f"æ­£åœ¨è™•ç† {symbol}...")
            
            global_data = fetch_global_account_ratio(symbol, TIME_TYPE)
            top_account_data = fetch_top_account_ratio(symbol, TIME_TYPE)
            top_position_data = fetch_top_position_ratio(symbol, TIME_TYPE)
            
            all_data = {
                'global': global_data,
                'topAccount': top_account_data,
                'topPosition': top_position_data
            }
            
            analysis = analyze_data(all_data)
            all_analyses.append(analysis)
            
            time.sleep(2)  # é¿å…è«‹æ±‚éæ–¼é »ç¹
            
        except Exception as e:
            logger.error(f"è™•ç† {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            all_analyses.append(None)
    
    # éæ¿¾æ‰å¤±æ•—çš„åˆ†æçµæœ
    valid_analyses = []
    valid_symbols = []
    
    for i, analysis in enumerate(all_analyses):
        if analysis is not None:
            valid_analyses.append(analysis)
            valid_symbols.append(SYMBOLS[i])
    
    if len(valid_analyses) == 0:
        logger.error("æ‰€æœ‰å¹£ç¨®æ•¸æ“šç²å–å¤±æ•—ï¼Œç„¡æ³•ç™¼é€è¨Šæ¯")
        return
    
    # æ ¼å¼åŒ–åˆä½µè¨Šæ¯ï¼ˆæ”¹é€²ç‰ˆï¼šæ›´ç™½è©±ã€æ›´å¯¦ç”¨ï¼‰
    now = get_taipei_time()
    time_str = format_datetime(now)
    
    message = "ğŸ‹ *ã€å·¨é¯¨æŒå€‰å‹•å‘ã€‘*\n"
    message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    message += "\n"
    
    for i, symbol in enumerate(SYMBOLS):
        if all_analyses[i] is not None:
            analysis = all_analyses[i]
            coin_symbol = symbol.replace("USDT", "")
            
            # ç°¡åŒ–é¡¯ç¤ºï¼ˆç™½è©±ç°¡çŸ­ï¼‰
            message += f"*ã€{coin_symbol}ã€‘*\n"
            
            # æ•£æˆ¶æƒ…ç·’ï¼ˆç°¡åŒ–ï¼‰
            if analysis.get('globalRatio') is not None:
                gr = analysis['globalRatio']
                if gr > 1.2:
                    retail_status = "ğŸ”¥ æ¥µåº¦çœ‹å¤š"
                elif gr > 1.05:
                    retail_status = "ğŸ“ˆ çœ‹å¤š"
                elif gr < 0.85:
                    retail_status = "â„ï¸ æ¥µåº¦çœ‹ç©º"
                elif gr < 0.95:
                    retail_status = "ğŸ“‰ çœ‹ç©º"
                else:
                    retail_status = "â¡ï¸ ä¸­æ€§"
                message += f"æ•£æˆ¶ï¼š{retail_status}\n"
            
            # å·¨é¯¨éƒ¨ä½ï¼ˆç°¡åŒ–ï¼‰
            if analysis.get('topPositionRatio') is not None:
                tpr = analysis['topPositionRatio']
                if tpr > 1.2:
                    whale_status = "ğŸŸ¢ å¼·å‹¢çœ‹å¤š"
                elif tpr > 1.05:
                    whale_status = "ğŸŸ¡ çœ‹å¤š"
                elif tpr < 0.85:
                    whale_status = "ğŸ”´ å¼·å‹¢çœ‹ç©º"
                elif tpr < 0.95:
                    whale_status = "ğŸŸ  çœ‹ç©º"
                else:
                    whale_status = "âšª ä¸­æ€§"
                message += f"å·¨é¯¨ï¼š{whale_status}\n"
            
            # å¸‚å ´è¨ºæ–·ï¼ˆç°¡åŒ–ï¼‰
            diagnosis = analysis.get('diagnosis', 'ç„¡æ³•åˆ¤æ–·')
            message += f"è¨ºæ–·ï¼š{diagnosis}\n"
            message += "\n"
    
    # ç°¡åŒ–çš„æ“ä½œå»ºè­°ï¼ˆç™½è©±ï¼‰
    message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    message += "ğŸ’¡ *æ“ä½œå»ºè­°*ï¼š\n"
    message += "â€¢ æ•£æˆ¶ç‹‚ç†±+å·¨é¯¨æ’¤é€€ = å±éšªâš ï¸\n"
    message += "â€¢ æ•£æˆ¶ææ…Œ+å·¨é¯¨æŠ„åº• = æ©Ÿæœƒâœ…\n"
    message += "â€¢ æ•£æˆ¶èˆ‡å·¨é¯¨åŒæ­¥ = è¶¨å‹¢å»¶çºŒğŸ“ˆ\n"
    message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    message += f"â° æ›´æ–°æ™‚é–“ï¼š{time_str}"
    
    send_telegram_message(message, TG_THREAD_IDS['whale_position'], parse_mode="Markdown")


# ==================== 3. æŒå€‰è®ŠåŒ–ç¯©é¸å™¨ ====================

def fetch_supported_futures_coins() -> List[str]:
    """ç²å– BingX äº¤æ˜“æ‰€æ”¯æ´çš„åˆç´„å¹£ç¨®åˆ—è¡¨ï¼ˆæ‡‰è©²æœ‰ 600+ å€‹ï¼‰"""
    url = "https://open-api-v4.coinglass.com/api/futures/supported-exchange-pairs"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.error(f"supported-exchange-pairs API error: {response.status_code}")
            return []
        
        result = response.json()
        data = result.get('data', result)
        
        # API è¿”å›çš„æ˜¯å­—å…¸çµæ§‹ï¼š{"BingX": [{"instrument_id": "BTCUSDT", "base_asset": "BTC", ...}, ...]}
        if not isinstance(data, dict):
            logger.error(f"API è¿”å›æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼Œé æœŸå­—å…¸ä½†å¾—åˆ°: {type(data)}")
            return []
        
        # èª¿è©¦ï¼šè¨˜éŒ„å¯ç”¨çš„äº¤æ˜“æ‰€
        exchanges = list(data.keys())
        logger.info(f"API è¿”å›çš„äº¤æ˜“æ‰€: {exchanges[:10]}... (å…± {len(exchanges)} å€‹)")
        
        # æŸ¥æ‰¾ BingXï¼ˆå˜—è©¦å¤šç¨®å¯èƒ½çš„éµåï¼‰
        bingx_data = None
        for key in data.keys():
            if 'bingx' in str(key).lower() or 'bing' in str(key).lower():
                bingx_data = data[key]
                logger.info(f"æ‰¾åˆ° BingX æ•¸æ“šï¼Œéµå: {key}")
                break
        
        if not bingx_data:
            logger.error(f"æœªæ‰¾åˆ° BingX æ•¸æ“šï¼Œå¯ç”¨äº¤æ˜“æ‰€: {exchanges}")
            return []
        
        if not isinstance(bingx_data, list):
            logger.error(f"BingX æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼Œé æœŸåˆ—è¡¨ä½†å¾—åˆ°: {type(bingx_data)}")
            return []
        
        # æå–å¹£ç¨®ç¬¦è™Ÿ
        symbols = []
        for item in bingx_data:
            if not isinstance(item, dict):
                continue
            
            # å„ªå…ˆä½¿ç”¨ base_assetï¼ˆä¾‹å¦‚ "BTC"ï¼‰
            symbol = item.get('base_asset') or item.get('baseAsset') or item.get('base')
            
            # å¦‚æœæ²’æœ‰ base_assetï¼Œå¾ instrument_id æå–ï¼ˆä¾‹å¦‚ "BTCUSDT" æˆ– "BTC-USDT" -> "BTC"ï¼‰
            if not symbol:
                instrument_id = item.get('instrument_id') or item.get('instrumentId') or item.get('symbol') or item.get('pair') or ''
                if instrument_id:
                    # è™•ç†å¤šç¨®æ ¼å¼ï¼šBTCUSDT, BTC-USDT, BTC_USDT ç­‰
                    symbol = instrument_id.replace('USDT', '').replace('USDT-PERP', '').replace('-PERP', '').replace('_USDT', '').replace('-USDT', '').replace('_', '').upper()
            
            if symbol and symbol not in symbols:
                symbols.append(symbol)
        
        logger.info(f"å¾ BingX API ç²å–åˆ° {len(symbols)} å€‹åˆç´„å¹£ç¨®")
        return symbols
    except Exception as e:
        logger.error(f"ç²å– BingX åˆç´„å¹£ç¨®åˆ—è¡¨å¤±æ•—: {str(e)}")
        import traceback
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return []


def fetch_coins_price_change() -> List[Dict]:
    """ç²å–å¹£ç¨®æ¼²è·Œå¹…åˆ—è¡¨ï¼ˆæ”¹ç‚ºåªè¿”å›åˆç´„å¹£ç¨®ï¼‰"""
    # å…ˆç²å–åˆç´„å¹£ç¨®åˆ—è¡¨
    supported_coins = fetch_supported_futures_coins()
    if not supported_coins:
        logger.warning("ç„¡æ³•ç²å–åˆç´„å¹£ç¨®åˆ—è¡¨ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ³•")
        # å‚™ç”¨ï¼šä½¿ç”¨åŸAPIï¼Œä½†æœƒåŒ…å«ç¾è²¨
        url = f"{CG_API_BASE}/api/futures/coins-price-change"
        headers = {
            "CG-API-KEY": CG_API_KEY,
            "accept": "application/json"
        }
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code != 200:
                return []
            result = response.json()
            return result.get('data', result if isinstance(result, list) else [])
        except:
            return []
    
    # ç²å–åƒ¹æ ¼è®ŠåŒ–æ•¸æ“š
    url = f"{CG_API_BASE}/api/futures/coins-price-change"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.error(f"coins-price-change error: {response.status_code}")
            return []
        
        result = response.json()
        all_data = result.get('data', result if isinstance(result, list) else [])
        
        # éæ¿¾ï¼šåªä¿ç•™åˆç´„å¹£ç¨®
        filtered_data = []
        for item in all_data:
            symbol = item.get('symbol') or item.get('coin') or ''
            # ç§»é™¤USDTå¾Œç¶´é€²è¡Œæ¯”å°
            symbol_clean = symbol.replace('USDT', '').replace('USDT-PERP', '').upper()
            if symbol_clean in supported_coins:
                filtered_data.append(item)
        
        logger.info(f"éæ¿¾å¾Œå‰©é¤˜ {len(filtered_data)} å€‹åˆç´„å¹£ç¨®ï¼ˆåŸå§‹ {len(all_data)} å€‹ï¼‰")
        return filtered_data
    except Exception as e:
        logger.error(f"ç²å–å¹£ç¨®åƒ¹æ ¼è®ŠåŒ–å¤±æ•—: {str(e)}")
        return []


def fetch_oi_change_15m(symbol: str) -> Optional[float]:
    """è¨ˆç®—å–®ä¸€ symbol 15 åˆ†é˜ OI è®ŠåŒ–%ï¼ˆæ•¸æ“šæºï¼šCoinGlass Binanceï¼Œèˆ‡ Google Apps Script ç‰ˆæœ¬ä¸€è‡´ï¼‰"""
    # ç›´æ¥ä½¿ç”¨ symbol+USDT æ ¼å¼ï¼Œä½¿ç”¨ m15 å€é–“
    # ä½¿ç”¨ exchange åƒæ•¸æŒ‡å®š Binanceï¼ˆç¢ºä¿æ•¸æ“šæºèˆ‡ Google Apps Script ç‰ˆæœ¬ä¸€è‡´ï¼‰
    sym = symbol + "USDT"
    url = f"{CG_API_BASE}/api/futures/open-interest/history"
    params = {
        "exchange": EXCHANGE,  # ä½¿ç”¨ Binanceï¼ˆç¢ºä¿æ•¸æ“šæºèˆ‡ Google Apps Script ç‰ˆæœ¬ä¸€è‡´ï¼‰
        "symbol": sym,
        "interval": "m15"  # ä½¿ç”¨ 15 åˆ†é˜å€é–“
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code != 200:
            return None
        
        result = response.json()
        data_list = result.get('data', result.get('list', []))
        
        if not isinstance(data_list, list) or len(data_list) < 2:
            return None
        
        last = data_list[-1]
        prev = data_list[-2]
        
        # å¯¦éš›æ¬„ä½åç¨±ï¼štime, open, high, low, closeï¼ˆç”¨ close ä»£è¡¨ OI æ•¸å€¼ï¼‰
        last_oi = last.get('close') or last.get('open')
        prev_oi = prev.get('close') or prev.get('open')
        
        # ç¢ºä¿è½‰æ›ç‚ºæ•¸å­—ï¼ˆè™•ç†å­—ç¬¦ä¸²æƒ…æ³ï¼‰
        try:
            last_oi = float(last_oi) if last_oi is not None else None
            prev_oi = float(prev_oi) if prev_oi is not None else None
        except (ValueError, TypeError):
            return None
        
        if not last_oi or not prev_oi or prev_oi == 0:
            return None
        
        change = ((last_oi - prev_oi) / prev_oi) * 100
        return change
    except Exception as e:
        return None


def normalize_symbol(coin: Dict) -> Optional[str]:
    """å¾å¹£ç¨®æ•¸æ“šä¸­æå– symbol"""
    return coin.get('symbol') or coin.get('pair') or coin.get('name') or coin.get('coin') or coin.get('symbolName')


def extract_price_change_15m(coin: Dict) -> float:
    """æå– 15 åˆ†é˜åƒ¹æ ¼è®ŠåŒ–%"""
    # å„ªå…ˆä½¿ç”¨ 15 åˆ†é˜åƒ¹æ ¼è®ŠåŒ–
    change = coin.get('price_change_percent_15m')
    if isinstance(change, (int, float)):
        return float(change)
    if isinstance(change, str) and change:
        try:
            parsed = float(change)
            if not (parsed != parsed):  # æª¢æŸ¥ NaN
                return parsed
        except ValueError:
            pass
    
    # å‚™ç”¨ï¼šå…¶ä»–æ™‚é–“å€é–“
    change = coin.get('price_change_percent_1h')
    if isinstance(change, (int, float)):
        return float(change)
    
    change = coin.get('price_change_percent_24h')
    if isinstance(change, (int, float)):
        return float(change)
    
    return 0.0


def build_report_message(top_long_open: List, top_long_close: List, top_short_open: List, top_short_close: List, processed_count: int = 0, oi_success_count: int = 0) -> str:
    """çµ„åˆæ¨æ’­æ–‡å­—ï¼ˆå„ªåŒ–ç‰ˆï¼šç°¡æ½”æ¨™é¡Œï¼ŒåŠ å…¥ä¸»åŠ›æ€ç¶­æ•™å­¸ï¼‰"""
    lines = []
    lines.append("ğŸ’° *ã€å‚‘å…‹çŸ­ç·šæŒå€‰ç•°å‹•æ’è¡Œæ¦œã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    
    def fmt(num):
        if num is None or (isinstance(num, float) and (num != num)):  # NaN check
            return "0.00%"
        return f"{'+' if num >= 0 else ''}{num:.2f}%"
    
    # é–‹å€‰ï¼ˆåŒ…å«å¤šæ–¹é–‹å€‰å’Œç©ºæ–¹é–‹å€‰ï¼‰
    lines.append("ğŸ“ˆ *é–‹å€‰*")
    lines.append("")
    
    # å¤šæ–¹é–‹å€‰ TOP 3
    lines.append("  *å¤šæ–¹é–‹å€‰ TOP 3*")
    if not top_long_open:
        lines.append("    ç„¡æ˜é¡¯å¤šæ–¹é–‹å€‰æ¨™çš„")
    else:
        for idx, item in enumerate(top_long_open):
            price_change = fmt(item.get('priceChange15m', 0))
            oi_change = fmt(item['oiChange15m'])
            lines.append(
                f"    {idx + 1}) *{item['symbol']}*ï½œåƒ¹æ ¼ {price_change}ï½œæŒå€‰ {oi_change}"
            )
    lines.append("")
    
    # ç©ºæ–¹é–‹å€‰ TOP 3
    lines.append("  *ç©ºæ–¹é–‹å€‰ TOP 3*")
    if not top_short_open:
        lines.append("    ç„¡æ˜é¡¯ç©ºæ–¹é–‹å€‰æ¨™çš„")
    else:
        for idx, item in enumerate(top_short_open):
            price_change = fmt(item.get('priceChange15m', 0))
            oi_change = fmt(item['oiChange15m'])
            lines.append(
                f"    {idx + 1}) *{item['symbol']}*ï½œåƒ¹æ ¼ {price_change}ï½œæŒå€‰ {oi_change}"
            )
    lines.append("")
    
    # å¹³å€‰ï¼ˆåŒ…å«å¤šæ–¹å¹³å€‰å’Œç©ºæ–¹å¹³å€‰ï¼‰
    lines.append("ğŸ“‰ *å¹³å€‰*")
    lines.append("")
    
    # å¤šæ–¹å¹³å€‰ TOP 3
    lines.append("  *å¤šæ–¹å¹³å€‰ TOP 3*")
    if not top_long_close:
        lines.append("    ç„¡æ˜é¡¯å¤šæ–¹å¹³å€‰æ¨™çš„")
    else:
        for idx, item in enumerate(top_long_close):
            price_change = fmt(item.get('priceChange15m', 0))
            oi_change = fmt(item['oiChange15m'])
            lines.append(
                f"    {idx + 1}) *{item['symbol']}*ï½œåƒ¹æ ¼ {price_change}ï½œæŒå€‰ {oi_change}"
            )
    lines.append("")
    
    # ç©ºæ–¹å¹³å€‰ TOP 3
    lines.append("  *ç©ºæ–¹å¹³å€‰ TOP 3*")
    if not top_short_close:
        lines.append("    ç„¡æ˜é¡¯ç©ºæ–¹å¹³å€‰æ¨™çš„")
    else:
        for idx, item in enumerate(top_short_close):
            price_change = fmt(item.get('priceChange15m', 0))
            oi_change = fmt(item['oiChange15m'])
            lines.append(
                f"    {idx + 1}) *{item['symbol']}*ï½œåƒ¹æ ¼ {price_change}ï½œæŒå€‰ {oi_change}"
            )
    lines.append("")
    
    # ä¸»åŠ›æ€ç¶­æ•™å­¸ï¼ˆæ›ä½æ€è€ƒï¼‰
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("ğŸ’¡ *ã€æ›ä½æ€è€ƒä¸»åŠ›å‹•æ©Ÿã€‘*")
    lines.append("")
    lines.append("è«‹å…ˆåˆ¤æ–· *15åˆ†Kåƒ¹æ ¼èµ°å‹¢è¶¨å‹¢* å»æ›ä½æ€è€ƒä¸»åŠ›å‹•æ©Ÿ")
    lines.append("")
    lines.append("ğŸ“ˆ *é–‹å€‰å‹•æ©Ÿ*ï¼šç‚ºä»€éº¼åœ¨é€™å€‹ä½ç½®é–‹å€‰ï¼Ÿ")
    lines.append("")
    lines.append("ğŸ“‰ *å¹³å€‰å‹•æ©Ÿ*ï¼šåœåˆ©é‚„æ˜¯åœæï¼Ÿ")
    
    return "\n".join(lines)


def process_single_symbol(coin: Dict) -> Optional[Dict]:
    """è™•ç†å–®å€‹å¹£ç¨®ï¼ˆç”¨æ–¼ä¸¦è¡Œè™•ç†ï¼Œä½¿ç”¨åŸæœ¬çš„é‚è¼¯ï¼‰"""
    symbol = normalize_symbol(coin)
    if not symbol:
        return None
    
    try:
        # ä½¿ç”¨åŸæœ¬çš„é‚è¼¯ï¼šå¾ coin å­—å…¸æå–åƒ¹æ ¼è®ŠåŒ–
        price_change_15m = extract_price_change_15m(coin)
        # æŸ¥è©¢ CoinGlass çš„ OI æ•¸æ“šï¼ˆå…¨å¸‚å ´æ•´åˆæ•¸æ“šï¼ŒåŸæœ¬çš„é‚è¼¯ï¼‰
        oi_change_15m = fetch_oi_change_15m(symbol)
        
        if oi_change_15m is None:
            return {'status': 'oi_failed', 'symbol': symbol}
        
        # 4 é¡åˆ†é¡é‚è¼¯ï¼ˆæ¢å¾©åŸæœ¬é‚è¼¯ï¼Œä¸éæ¿¾æŒå€‰è®ŠåŒ–ç‡ï¼‰
        category = None
        if price_change_15m > 0:
            if oi_change_15m > 0:
                category = 'long_open'
            elif oi_change_15m < 0:
                category = 'long_close'
        elif price_change_15m < 0:
            if oi_change_15m > 0:
                category = 'short_open'
            elif oi_change_15m < 0:
                category = 'short_close'
        
        if category:
            return {
                'status': 'success',
                'category': category,
                'symbol': symbol,
                'priceChange15m': price_change_15m,
                'oiChange15m': oi_change_15m
            }
        else:
            return {'status': 'no_category', 'symbol': symbol}
            
    except Exception as e:
        logger.error(f"è™•ç† {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return {'status': 'error', 'symbol': symbol, 'error': str(e)}


def fetch_position_change():
    """ä¸»æµç¨‹ï¼šæŒå€‰è®ŠåŒ–ç¯©é¸ï¼ˆåŸæœ¬çš„é‚è¼¯ï¼Œåªæ˜¯æ”¹æˆåªåµæ¸¬ BingX çš„ 554 å€‹äº¤æ˜“å°ï¼‰"""
    logger.info("é–‹å§‹åŸ·è¡ŒæŒå€‰è®ŠåŒ–ç¯©é¸ï¼Œåªåµæ¸¬ BingX åˆç´„å¹£ç¨®...")
    
    # æ­¥é©Ÿ1ï¼šå…ˆç²å– BingX äº¤æ˜“å°åå–®ï¼ˆæå–å¹£ç¨®åç¨±ï¼‰
    bingx_symbols = fetch_supported_futures_coins()
    if not bingx_symbols:
        send_telegram_message("âš ï¸ ç„¡æ³•å¾ API å–å¾— BingX åˆç´„å¹£ç¨®åå–®ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", TG_THREAD_IDS['position_change'])
        return
    
    logger.info(f"ç²å–åˆ° {len(bingx_symbols)} å€‹ BingX åˆç´„å¹£ç¨®")
    
    # æ­¥é©Ÿ2ï¼šç²å– CoinGlass æ‰€æœ‰å¹£ç¨®çš„åƒ¹æ ¼è®ŠåŒ–æ•¸æ“šï¼ˆåŸæœ¬çš„é‚è¼¯ï¼‰
    all_symbols_data = fetch_coins_price_change()
    if not all_symbols_data:
        send_telegram_message("âš ï¸ ç„¡æ³•å¾ Coinglass å–å¾—å¹£ç¨®æ¼²è·Œè³‡æ–™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", TG_THREAD_IDS['position_change'])
        return
    
    logger.info(f"å¾ Coinglass API å–å¾— {len(all_symbols_data)} å€‹å¹£ç¨®çš„åƒ¹æ ¼æ•¸æ“š")
    
    # æ­¥é©Ÿ3ï¼šåªä¿ç•™ BingX åå–®ä¸­çš„å¹£ç¨®ï¼ˆåŸæœ¬çš„é‚è¼¯ï¼Œåªæ˜¯éæ¿¾ç¯„åœæ”¹ç‚º BingXï¼‰
    bingx_symbols_upper = {s.upper() for s in bingx_symbols}
    target_symbols_data = []
    for coin in all_symbols_data:
        symbol = normalize_symbol(coin)
        if symbol and symbol.upper() in bingx_symbols_upper:
            target_symbols_data.append(coin)
    
    logger.info(f"éæ¿¾å¾Œå‰©é¤˜ {len(target_symbols_data)} å€‹ BingX å¹£ç¨®ï¼ˆå°‡è™•ç†å‰ {MAX_SYMBOLS} å€‹ï¼‰")
    
    # è™•ç†åˆç´„å¹£ç¨®ï¼ˆé™åˆ¶æ•¸é‡é¿å…è¶…æ™‚ï¼‰
    target_symbols = target_symbols_data[:MAX_SYMBOLS] if len(target_symbols_data) > MAX_SYMBOLS else target_symbols_data
    
    long_open = []
    long_close = []
    short_open = []
    short_close = []
    
    processed_count = 0
    oi_success_count = 0
    oi_fail_count = 0
    
    # ä¸¦è¡Œè™•ç†é…ç½®ï¼ˆBingXå¹£ç¨®è¼ƒå°‘ï¼Œå¯ä»¥é©ç•¶å¢åŠ ä¸¦ç™¼æ•¸ï¼‰
    MAX_WORKERS = 20  # åŒæ™‚è™•ç†20å€‹è«‹æ±‚ï¼ˆBingXå¹£ç¨®è¼ƒå°‘ï¼Œå¯ä»¥æ›´å¿«ï¼‰
    
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = time.time()
    MAX_EXECUTION_TIME = 25 * 60  # 25 åˆ†é˜ï¼ˆç•™ 5 åˆ†é˜ç·©è¡ï¼‰
    
    # ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œè™•ç†ï¼ˆä½¿ç”¨åŸæœ¬çš„é‚è¼¯ï¼Œå‚³å…¥ coin å­—å…¸ï¼‰
    results = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™ï¼ˆå‚³å…¥ coin å­—å…¸ï¼Œä½¿ç”¨åŸæœ¬çš„é‚è¼¯ï¼‰
        future_to_coin = {executor.submit(process_single_symbol, coin): coin for coin in target_symbols}
        
        # è™•ç†å®Œæˆçš„ä»»å‹™
        completed = 0
        for future in as_completed(future_to_coin):
            # æª¢æŸ¥è¶…æ™‚
            elapsed_time = time.time() - start_time
            if elapsed_time > MAX_EXECUTION_TIME:
                logger.warning(f"åŸ·è¡Œæ™‚é–“å·²è¶…é {MAX_EXECUTION_TIME/60:.1f} åˆ†é˜ï¼Œæå‰çµæŸè™•ç†")
                # å–æ¶ˆæœªå®Œæˆçš„ä»»å‹™
                for f in future_to_coin:
                    f.cancel()
                break
            
            completed += 1
            result = future.result()
            
            if result is None:
                continue
            
            processed_count += 1
            
            # é€²åº¦æ—¥èªŒï¼ˆæ¯100å€‹ï¼‰
            if completed % 100 == 0:
                elapsed_min = elapsed_time / 60
                logger.info(f"è™•ç†é€²åº¦: {completed}/{len(target_symbols)} å€‹å¹£ç¨® ({completed*100//len(target_symbols)}%) | å·²ç”¨æ™‚: {elapsed_min:.1f} åˆ†é˜")
            
            # è™•ç†çµæœ
            status = result.get('status')
            if status == 'oi_failed':
                oi_fail_count += 1
            elif status == 'success':
                oi_success_count += 1
                category = result.get('category')
                symbol = result.get('symbol')
                price_change = result.get('priceChange15m')
                oi_change = result.get('oiChange15m')
                
                item = {'symbol': symbol, 'priceChange15m': price_change, 'oiChange15m': oi_change}
                
                if category == 'long_open':
                    long_open.append(item)
                elif category == 'long_close':
                    long_close.append(item)
                elif category == 'short_open':
                    short_open.append(item)
                elif category == 'short_close':
                    short_close.append(item)
    
    total_time = time.time() - start_time
    logger.info(f"è™•ç†çµ±è¨ˆ: ç¸½å…± {processed_count} å€‹å¹£ç¨®, OI æˆåŠŸ {oi_success_count} å€‹, OI å¤±æ•— {oi_fail_count} å€‹ | ç¸½ç”¨æ™‚: {total_time/60:.1f} åˆ†é˜")
    logger.info(f"åˆ†é¡çµæœ: å¤šæ–¹é–‹å€‰ {len(long_open)}, å¤šæ–¹å¹³å€‰ {len(long_close)}, ç©ºæ–¹é–‹å€‰ {len(short_open)}, ç©ºæ–¹å¹³å€‰ {len(short_close)}")
    
    # æ’åºèˆ‡å–å‰ 3 å
    long_open.sort(key=lambda x: x['oiChange15m'], reverse=True)      # OI å¢åŠ è¶Šå¤šè¶Šå¥½
    long_close.sort(key=lambda x: x['oiChange15m'])                   # OI æ¸›å°‘è¶Šå¤šè¶Šå¥½ï¼ˆè¶Šè² è¶Šå¥½ï¼‰
    short_open.sort(key=lambda x: x['oiChange15m'], reverse=True)     # OI å¢åŠ è¶Šå¤šè¶Šå¥½
    short_close.sort(key=lambda x: x['oiChange15m'])                  # OI æ¸›å°‘è¶Šå¤šè¶Šå¥½ï¼ˆè¶Šè² è¶Šå¥½ï¼‰
    
    top_long_open = long_open[:3]
    top_long_close = long_close[:3]
    top_short_open = short_open[:3]
    top_short_close = short_close[:3]
    
    # ç¢ºä¿æ¯æ¬¡éƒ½æœƒæ¨æ’­ï¼ˆå³ä½¿æ²’æœ‰ç•°å¸¸ï¼Œä¹Ÿè¦æ¨æ’­å ±å‘Šï¼‰
    msg = build_report_message(top_long_open, top_long_close, top_short_open, top_short_close, processed_count, oi_success_count)
    send_telegram_message(msg, TG_THREAD_IDS['position_change'], parse_mode="Markdown")
    
    logger.info("æŒå€‰è®ŠåŒ–ç¯©é¸åŸ·è¡Œå®Œæˆä¸¦å·²æ¨æ’­")


# ==================== 4. é‡è¦ç¶“æ¿Ÿæ•¸æ“šæ¨æ’­ ====================

SENT_DATA_FILE = DATA_DIR / "sent_economic_data_ids.json"


def fetch_economic_data() -> List[Dict]:
    """å¾ CoinGlass API æŠ“å–ç¶“æ¿Ÿæ•¸æ“š"""
    url = "https://open-api-v4.coinglass.com/api/calendar/economic-data"
    params = {"language": "zh"}
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "Accept": "application/json"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        result = response.json()
        
        if result.get('code') in ['0', 0, 200, '200']:
            data_list = result.get('data', [])
            # æ¨™è¨˜æ•¸æ“šä¾†æº
            for item in data_list:
                item['_source'] = 'economic_data'
            return data_list
        else:
            logger.error(f"Economic Data API è¿”å›éŒ¯èª¤: {result.get('msg')} (éŒ¯èª¤ç¢¼: {result.get('code')})")
            return []
    except Exception as e:
        logger.error(f"ç²å–ç¶“æ¿Ÿæ•¸æ“šå¤±æ•—: {str(e)}")
        return []


def fetch_financial_events() -> List[Dict]:
    """å¾ CoinGlass API æŠ“å–è²¡ç¶“äº‹ä»¶"""
    url = "https://open-api-v4.coinglass.com/api/calendar/financial-events"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "Accept": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        result = response.json()
        
        if result.get('code') in ['0', 0, 200, '200']:
            data_list = result.get('data', [])
            # æ¨™è¨˜æ•¸æ“šä¾†æº
            for item in data_list:
                item['_source'] = 'financial_events'
            return data_list
        else:
            logger.warning(f"Financial Events API è¿”å›éŒ¯èª¤: {result.get('msg')} (éŒ¯èª¤ç¢¼: {result.get('code')})")
            return []
    except Exception as e:
        logger.warning(f"ç²å–è²¡ç¶“äº‹ä»¶å¤±æ•—: {str(e)}")
        return []


def fetch_central_bank_activities() -> List[Dict]:
    """å¾ CoinGlass API æŠ“å–å¤®è¡Œæ´»å‹•"""
    url = "https://open-api-v4.coinglass.com/api/calendar/central-bank-activities"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "Accept": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        result = response.json()
        
        if result.get('code') in ['0', 0, 200, '200']:
            data_list = result.get('data', [])
            # æ¨™è¨˜æ•¸æ“šä¾†æº
            for item in data_list:
                item['_source'] = 'central_bank'
            return data_list
        else:
            logger.warning(f"Central Bank API è¿”å›éŒ¯èª¤: {result.get('msg')} (éŒ¯èª¤ç¢¼: {result.get('code')})")
            return []
    except Exception as e:
        logger.warning(f"ç²å–å¤®è¡Œæ´»å‹•å¤±æ•—: {str(e)}")
        return []


def parse_publish_time(item: Dict) -> Optional[datetime]:
    """è§£æç™¼å¸ƒæ™‚é–“ï¼ˆè¿”å› UTC datetimeï¼Œå¾ŒçºŒæœƒè½‰æ›ç‚ºå°ç£æ™‚é–“ï¼‰"""
    publish_timestamp = item.get('publish_timestamp') or item.get('publish_time') or item.get('time')
    if not publish_timestamp:
        return None
    
    try:
        if isinstance(publish_timestamp, (int, float)):
            if publish_timestamp > 1e12:  # æ¯«ç§’æ™‚é–“æˆ³
                dt = datetime.fromtimestamp(publish_timestamp / 1000, tz=timezone.utc)
            else:  # ç§’æ™‚é–“æˆ³
                dt = datetime.fromtimestamp(publish_timestamp, tz=timezone.utc)
            return dt
        else:
            # å˜—è©¦ ISO æ ¼å¼
            time_str = str(publish_timestamp).replace('Z', '+00:00')
            dt = datetime.fromisoformat(time_str)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
    except Exception as e:
        logger.debug(f"æ™‚é–“è§£æå¤±æ•—: {publish_timestamp}, éŒ¯èª¤: {str(e)}")
        return None


def filter_important_data(data_array: List[Dict], min_importance: int = 2) -> List[Dict]:
    """éæ¿¾é‡è¦ç¶“æ¿Ÿæ•¸æ“šï¼ˆå¯æŒ‡å®šæœ€ä½é‡è¦æ€§ï¼‰"""
    now = get_taipei_time()
    one_week_later = now + timedelta(days=7)
    two_hours_ago = now - timedelta(hours=2)  # å…è¨±å·²ç™¼å¸ƒ2å°æ™‚å…§çš„æ•¸æ“š
    
    filtered = []
    for item in data_array:
        importance = item.get('importance_level') or item.get('importance') or 0
        
        # è§£æç™¼å¸ƒæ™‚é–“
        publish_time = parse_publish_time(item)
        if not publish_time:
            continue
        
        # æª¢æŸ¥æ˜¯å¦å·²ç™¼å¸ƒï¼ˆæœ‰å¯¦éš›ç™¼å¸ƒå€¼ï¼‰
        is_published = item.get('published_value') not in [None, '']
        
        # æ™‚é–“ç¯„åœï¼šéå»2å°æ™‚åˆ°æœªä¾†7å¤©
        time_valid = two_hours_ago <= publish_time <= one_week_later
        
        # æ ¹æ“šæœ€ä½é‡è¦æ€§éæ¿¾
        if importance >= min_importance and time_valid:
            filtered.append(item)
    
    return filtered


def filter_today_events(data_array: List[Dict], min_importance: int = 4) -> List[Dict]:
    """éæ¿¾ä»Šæ—¥äº‹ä»¶ï¼ˆç”¨æ–¼æ—©ä¸Š8é»é å‘Šï¼‰"""
    now = get_taipei_time()
    today_start = datetime(now.year, now.month, now.day, 0, 0, 0, tzinfo=TAIPEI_TZ)
    today_end = datetime(now.year, now.month, now.day, 23, 59, 59, tzinfo=TAIPEI_TZ)
    
    filtered = []
    for item in data_array:
        importance = item.get('importance_level') or item.get('importance') or 0
        
        # è§£æç™¼å¸ƒæ™‚é–“
        publish_time = parse_publish_time(item)
        if not publish_time:
            continue
        
        # åªå–ä»Šæ—¥ä¸”æœªç™¼å¸ƒçš„äº‹ä»¶
        is_published = item.get('published_value') not in [None, '']
        is_today = today_start <= publish_time <= today_end
        
        if importance >= min_importance and is_today and not is_published:
            filtered.append(item)
    
    return filtered


def generate_data_id(item: Dict) -> str:
    """ç”Ÿæˆå”¯ä¸€çš„æ•¸æ“š IDï¼ˆç”¨æ–¼å»é‡ï¼‰"""
    # å„ªå…ˆä½¿ç”¨ API æä¾›çš„å”¯ä¸€ ID
    if item.get('id'):
        return str(item['id'])
    if item.get('calendar_id'):
        return str(item['calendar_id'])
    
    # å¦‚æœæ²’æœ‰å”¯ä¸€ IDï¼Œä½¿ç”¨çµ„åˆéµï¼ˆä¾†æº + åç¨± + æ™‚é–“æˆ³ï¼‰
    source = item.get('_source', 'unknown')
    name = item.get('calendar_name') or item.get('name') or item.get('title') or 'unknown'
    timestamp = item.get('publish_timestamp') or item.get('publish_time') or item.get('time') or '0'
    
    return f"{source}_{name}_{timestamp}"


def get_unsent_data(data_array: List[Dict]) -> List[Dict]:
    """ç²å–å°šæœªæ¨é€çš„æ•¸æ“šï¼ˆæ”¹é€²ç‰ˆï¼šè€ƒæ…®ç™¼å¸ƒæ™‚é–“å’Œå¯¦éš›å€¼ï¼‰"""
    sent_ids = load_json_file(SENT_DATA_FILE, [])
    unsent = []
    now = get_taipei_time()
    
    for item in data_array:
        data_id = generate_data_id(item)
        
        # æª¢æŸ¥æ˜¯å¦åœ¨å·²æ¨é€åˆ—è¡¨ä¸­
        if data_id in sent_ids:
            continue
        
        # é¡å¤–æª¢æŸ¥ï¼šå¦‚æœæ•¸æ“šå·²ç™¼å¸ƒè¶…é 2 å°æ™‚ï¼Œä¸”å·²æœ‰å¯¦éš›å€¼ï¼Œå‰‡è·³é
        # é€™å¯ä»¥é˜²æ­¢åœ¨ GitHub Actions ç’°å¢ƒä¸­é‡è¤‡æ¨é€
        publish_time = parse_publish_time(item)
        if publish_time:
            time_diff = (now - publish_time).total_seconds()
            published_value = item.get('published_value') or item.get('actual')
            
            # å¦‚æœå·²ç™¼å¸ƒè¶…é 2 å°æ™‚ä¸”æœ‰å¯¦éš›å€¼ï¼Œè¦–ç‚ºå·²è™•ç†éï¼ˆé¿å…é‡è¤‡ï¼‰
            if time_diff > 7200 and published_value:  # 2å°æ™‚ = 7200ç§’
                logger.debug(f"è·³éå·²ç™¼å¸ƒè¶…é2å°æ™‚çš„æ•¸æ“š: {data_id}")
                # æ¨™è¨˜ç‚ºå·²æ¨é€ï¼Œé¿å…ä¸‹æ¬¡å†æª¢æŸ¥
                mark_as_sent(data_id)
                continue
        
        unsent.append(item)
    
    return unsent


def mark_as_sent(data_id: str):
    """æ¨™è¨˜æ•¸æ“šç‚ºå·²æ¨é€"""
    sent_ids = load_json_file(SENT_DATA_FILE, [])
    if data_id not in sent_ids:
        sent_ids.append(data_id)
        # åªä¿ç•™æœ€è¿‘ 1000 æ¢è¨˜éŒ„
        if len(sent_ids) > 1000:
            sent_ids = sent_ids[-1000:]
        save_json_file(SENT_DATA_FILE, sent_ids)


def get_time_status(publish_time: datetime) -> tuple:
    """è¨ˆç®—æ™‚é–“ç‹€æ…‹ï¼Œè¿”å› (ç‹€æ…‹æ–‡å­—, æ˜¯å¦å·²ç™¼å¸ƒ, æ™‚é–“å·®ç§’æ•¸)"""
    # ç¢ºä¿å…©å€‹æ™‚é–“éƒ½åœ¨åŒä¸€æ™‚å€ï¼ˆå°ç£æ™‚é–“ï¼‰
    now = get_taipei_time()
    publish_time_taipei = get_taipei_time(publish_time)
    diff_seconds = (publish_time_taipei - now).total_seconds()
    
    is_past = diff_seconds < 0
    abs_diff = abs(diff_seconds)
    
    if is_past:
        # å·²ç™¼å¸ƒæ™‚é–“
        if abs_diff < 3600:  # 1å°æ™‚å…§
            minutes = int(abs_diff // 60)
            return (f"å·²ç™¼å¸ƒ {minutes} åˆ†é˜å‰", True, diff_seconds)
        elif abs_diff < 86400:  # 24å°æ™‚å…§
            hours = int(abs_diff // 3600)
            return (f"å·²ç™¼å¸ƒ {hours} å°æ™‚å‰", True, diff_seconds)
        else:
            days = int(abs_diff // 86400)
            return (f"å·²ç™¼å¸ƒ {days} å¤©å‰", True, diff_seconds)
    else:
        # æœªç™¼å¸ƒæ™‚é–“
        if abs_diff < 3600:  # 1å°æ™‚å…§
            minutes = int(abs_diff // 60)
            return (f"{minutes} åˆ†é˜å¾Œç™¼å¸ƒ", False, diff_seconds)
        elif abs_diff < 86400:  # 24å°æ™‚å…§
            hours = int(abs_diff // 3600)
            minutes = int((abs_diff % 3600) // 60)
            if minutes > 0:
                return (f"{hours} å°æ™‚ {minutes} åˆ†é˜å¾Œ", False, diff_seconds)
            else:
                return (f"{hours} å°æ™‚å¾Œ", False, diff_seconds)
        else:
            days = int(abs_diff // 86400)
            hours = int((abs_diff % 86400) // 3600)
            if hours > 0:
                return (f"{days} å¤© {hours} å°æ™‚å¾Œ", False, diff_seconds)
            else:
                return (f"{days} å¤©å¾Œ", False, diff_seconds)


def get_country_flag(country_name: str) -> str:
    """ç²å–åœ‹å®¶æ——å¹Ÿ emoji"""
    flag_map = {
        'ç¾åœ‹': 'ğŸ‡ºğŸ‡¸', 'ç¾åˆ©å …': 'ğŸ‡ºğŸ‡¸', 'US': 'ğŸ‡ºğŸ‡¸', 'United States': 'ğŸ‡ºğŸ‡¸', 'USA': 'ğŸ‡ºğŸ‡¸',
        'ä¸­åœ‹': 'ğŸ‡¨ğŸ‡³', 'ä¸­è¯äººæ°‘å…±å’Œåœ‹': 'ğŸ‡¨ğŸ‡³', 'CN': 'ğŸ‡¨ğŸ‡³', 'China': 'ğŸ‡¨ğŸ‡³',
        'æ­å…ƒå€': 'ğŸ‡ªğŸ‡º', 'æ­ç›Ÿ': 'ğŸ‡ªğŸ‡º', 'EU': 'ğŸ‡ªğŸ‡º', 'Eurozone': 'ğŸ‡ªğŸ‡º', 'Euro Area': 'ğŸ‡ªğŸ‡º',
        'è‹±åœ‹': 'ğŸ‡¬ğŸ‡§', 'å¤§ä¸åˆ—é¡›': 'ğŸ‡¬ğŸ‡§', 'UK': 'ğŸ‡¬ğŸ‡§', 'United Kingdom': 'ğŸ‡¬ğŸ‡§', 'GB': 'ğŸ‡¬ğŸ‡§',
        'æ—¥æœ¬': 'ğŸ‡¯ğŸ‡µ', 'JP': 'ğŸ‡¯ğŸ‡µ', 'Japan': 'ğŸ‡¯ğŸ‡µ',
        'å°ç£': 'ğŸ‡¹ğŸ‡¼', 'è‡ºç£': 'ğŸ‡¹ğŸ‡¼', 'TW': 'ğŸ‡¹ğŸ‡¼', 'Taiwan': 'ğŸ‡¹ğŸ‡¼',
    }
    
    if country_name in flag_map:
        return flag_map[country_name]
    
    for key, flag in flag_map.items():
        if key in country_name or country_name in key:
            return flag
    
    return 'ğŸŒ'


def get_effect_text(effect: str) -> str:
    """ç²å–å¸‚å ´å½±éŸ¿çš„ä¸­æ–‡æè¿°"""
    effect_map = {
        'Minor Impact': 'è¼•å¾®å½±éŸ¿',
        'Moderate Impact': 'ä¸­ç­‰å½±éŸ¿',
        'High Impact': 'é‡å¤§å½±éŸ¿',
        'Major Impact': 'æ¥µå¤§å½±éŸ¿',
        'åˆ©å¤š': 'åå‘åˆ©å¤š', 'Bullish': 'åå‘åˆ©å¤š',
        'åˆ©ç©º': 'åå‘åˆ©ç©º', 'Bearish': 'åå‘åˆ©ç©º',
        'ä¸­æ€§': 'ä¸­æ€§å½±éŸ¿', 'Neutral': 'ä¸­æ€§å½±éŸ¿'
    }
    
    for key, value in effect_map.items():
        if key in effect or effect in key:
            return value
    
    return effect or 'å¾…è§€å¯Ÿ'


def get_effect_emoji(effect: str) -> str:
    """ç²å–å¸‚å ´å½±éŸ¿ emoji"""
    effect_map = {
        'åˆ©å¤š': 'ğŸ“ˆ', 'Bullish': 'ğŸ“ˆ',
        'åˆ©ç©º': 'ğŸ“‰', 'Bearish': 'ğŸ“‰',
        'ä¸­æ€§': 'â¡ï¸', 'Neutral': 'â¡ï¸'
    }
    return effect_map.get(effect, 'ğŸ“Š')


def get_category_info(data: Dict) -> tuple:
    """ç²å–æ•¸æ“šé¡åˆ¥è³‡è¨Šï¼Œè¿”å› (é¡åˆ¥åç¨±, é¡åˆ¥emoji)"""
    source = data.get('_source', 'economic_data')
    category_map = {
        'economic_data': ('ç¶“æ¿Ÿæ•¸æ“š', 'ğŸ“Š'),
        'financial_events': ('è²¡ç¶“äº‹ä»¶', 'ğŸ’¼'),
        'central_bank': ('å¤®è¡Œæ´»å‹•', 'ğŸ¦')
    }
    return category_map.get(source, ('ç¶“æ¿Ÿäº‹ä»¶', 'ğŸ“ˆ'))


def format_economic_data_message(data: Dict) -> str:
    """æ ¼å¼åŒ–ç¶“æ¿Ÿæ•¸æ“šè¨Šæ¯ï¼ˆå…¨æ–°è¨­è¨ˆï¼‰"""
    publish_time = parse_publish_time(data)
    if not publish_time:
        publish_time = get_taipei_time()
    
    time_str = format_datetime(publish_time)
    time_status, is_published, _ = get_time_status(publish_time)
    
    # é‡è¦æ€§
    importance_level = data.get('importance_level') or data.get('importance') or 0
    if importance_level >= 3:
        importance_emoji = 'ğŸ”´'
        importance_text = 'æ¥µé«˜'
        importance_badge = 'âš ï¸ æ¥µé«˜é‡è¦æ€§'
    elif importance_level >= 2:
        importance_emoji = 'ğŸŸ¡'
        importance_text = 'é«˜'
        importance_badge = 'âš¡ é«˜é‡è¦æ€§'
    else:
        importance_emoji = 'ğŸŸ¢'
        importance_text = 'ä¸­'
        importance_badge = 'ğŸ“Œ ä¸­é‡è¦æ€§'
    
    # é¡åˆ¥è³‡è¨Š
    category_name, category_emoji = get_category_info(data)
    
    # åœ‹å®¶è³‡è¨Š
    country_flag = get_country_flag(data.get('country_name') or data.get('country') or '')
    country_name = data.get('country_name') or data.get('country') or 'æœªçŸ¥åœ°å€'
    
    # äº‹ä»¶åç¨±
    event_name = data.get('calendar_name') or data.get('name') or data.get('title') or 'ç¶“æ¿ŸæŒ‡æ¨™'
    
    # å¸‚å ´å½±éŸ¿
    effect_emoji = get_effect_emoji(data.get('data_effect') or data.get('effect') or '')
    effect_text = get_effect_text(data.get('data_effect') or data.get('effect') or '')
    
    # é æ¸¬å€¼èˆ‡å‰å€¼
    forecast_value = data.get('forecast_value') or data.get('forecast')
    previous_value = data.get('previous_value') or data.get('previous')
    published_value = data.get('published_value') or data.get('actual')
    
    # æ§‹å»ºè¨Šæ¯
    lines = []
    
    # æ¨™é¡Œå€åŸŸ
    lines.append(f"{category_emoji} *ã€{category_name}æ¨æ’­ã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    
    # äº‹ä»¶æ¨™é¡Œ
    lines.append(f"{importance_emoji} *{event_name}*")
    lines.append(f"{country_flag} {country_name}")
    lines.append("")
    
    # æ™‚é–“è³‡è¨Š
    lines.append("ğŸ• *ç™¼å¸ƒæ™‚é–“*")
    if is_published:
        lines.append(f"âœ… {time_str}")
        lines.append(f"â° {time_status}")
    else:
        lines.append(f"ğŸ“… {time_str}")
        lines.append(f"â³ {time_status}")
    lines.append("")
    
    # æ•¸æ“šå°æ¯”ï¼ˆå¦‚æœå·²ç™¼å¸ƒï¼Œé¡¯ç¤ºå¯¦éš›å€¼ï¼›æœªç™¼å¸ƒé¡¯ç¤ºé æ¸¬å€¼ï¼‰
    has_data = False
    if published_value:
        lines.append("ğŸ“ˆ *å¯¦éš›ç™¼å¸ƒå€¼*")
        lines.append(f"`{published_value}`")
        has_data = True
        if forecast_value:
            lines.append(f"é æ¸¬å€¼ï¼š`{forecast_value}`")
        if previous_value:
            lines.append(f"å‰å€¼ï¼š`{previous_value}`")
    elif forecast_value or previous_value:
        lines.append("ğŸ“Š *å¸‚å ´é æœŸ*")
        if forecast_value:
            lines.append(f"é æ¸¬å€¼ï¼š`{forecast_value}`")
        if previous_value:
            lines.append(f"å‰å€¼ï¼š`{previous_value}`")
        has_data = True
    
    if has_data:
        lines.append("")
    
    # é‡è¦æ€§èˆ‡å½±éŸ¿
    lines.append(f"{importance_badge}")
    if effect_text and effect_text != 'å¾…è§€å¯Ÿ':
        lines.append(f"{effect_emoji} å¸‚å ´å½±éŸ¿ï¼š{effect_text}")
    lines.append("")
    
    # è£œå……èªªæ˜
    remark = data.get('remark') or data.get('note') or data.get('description')
    if remark:
        lines.append(f"ğŸ’¡ *èˆ¹é•·è§£è®€*")
        # é™åˆ¶èªªæ˜é•·åº¦
        if len(remark) > 200:
            remark = remark[:200] + "..."
        lines.append(f"{remark}")
        lines.append("")
    
    # åº•éƒ¨è³‡è¨Š
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"ğŸ¤– å€å¡Šéˆèˆ¹é•·ï½œ{format_datetime(get_taipei_time())}")
    
    return "\n".join(lines)


def format_today_preview_message(events: List[Dict]) -> str:
    """æ ¼å¼åŒ–ä»Šæ—¥é å‘Šè¨Šæ¯ï¼ˆæ”¹é€²ç‰ˆï¼šå–æ¶ˆæ˜Ÿç´šï¼Œæ”¹ç‚ºé«˜é‡è¦æ€§å’Œæ¥µé«˜é‡è¦æ€§ï¼‰"""
    now = get_taipei_time()
    time_str = format_datetime(now)
    
    lines = []
    lines.append("ğŸ“… *ã€ä»Šæ—¥é‡è¦ç¶“æ¿Ÿæ•¸æ“šé å‘Šã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    
    # åˆ†çµ„ï¼šæ¥µé«˜é‡è¦æ€§ï¼ˆ>= 3ï¼‰å’Œé«˜é‡è¦æ€§ï¼ˆ>= 2 ä¸” < 3ï¼‰
    very_high = [e for e in events if (e.get('importance_level') or e.get('importance') or 0) >= 3]
    high = [e for e in events if 2 <= (e.get('importance_level') or e.get('importance') or 0) < 3]
    
    # æŒ‰æ™‚é–“æ’åºï¼ˆä½¿ç”¨æœªä¾†æ™‚é–“ä½œç‚º fallbackï¼‰
    future_time = datetime(2099, 12, 31, 23, 59, 59, tzinfo=TAIPEI_TZ)
    very_high.sort(key=lambda x: parse_publish_time(x) or future_time)
    high.sort(key=lambda x: parse_publish_time(x) or future_time)
    
    if very_high:
        lines.append("ğŸ”´ *æ¥µé«˜é‡è¦æ€§ï¼ˆå°‡æº–æ™‚æ¨æ’­ï¼‰*ï¼š")
        lines.append("")
        for event in very_high:
            publish_time = parse_publish_time(event)
            if publish_time:
                # è½‰æ›ç‚ºå°ç£æ™‚é–“ä¸¦æ ¼å¼åŒ–
                publish_time_taipei = get_taipei_time(publish_time)
                time_display = publish_time_taipei.strftime("%H:%M")
                event_name = event.get('calendar_name') or event.get('name') or event.get('title') or 'ç¶“æ¿ŸæŒ‡æ¨™'
                country_flag = get_country_flag(event.get('country_name') or event.get('country') or '')
                lines.append(f"  â€¢ {time_display} | {country_flag} {event_name}")
        lines.append("")
    
    if high:
        lines.append("ğŸŸ¡ *é«˜é‡è¦æ€§ï¼ˆåƒ…åˆ—å‡ºæ¸…å–®ï¼‰*ï¼š")
        lines.append("")
        for event in high:
            publish_time = parse_publish_time(event)
            if publish_time:
                # è½‰æ›ç‚ºå°ç£æ™‚é–“ä¸¦æ ¼å¼åŒ–
                publish_time_taipei = get_taipei_time(publish_time)
                time_display = publish_time_taipei.strftime("%H:%M")
                event_name = event.get('calendar_name') or event.get('name') or event.get('title') or 'ç¶“æ¿ŸæŒ‡æ¨™'
                country_flag = get_country_flag(event.get('country_name') or event.get('country') or '')
                lines.append(f"  â€¢ {time_display} | {country_flag} {event_name}")
        lines.append("")
    
    if not very_high and not high:
        lines.append("ä»Šæ—¥ç„¡é‡è¦ç¶“æ¿Ÿæ•¸æ“šäº‹ä»¶")
        lines.append("")
    
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"â° é å‘Šæ™‚é–“ï¼š{time_str}")
    
    return "\n".join(lines)


def send_today_preview():
    """æ—©ä¸Š8é»ç™¼é€ä»Šæ—¥é å‘Šï¼ˆåˆ—å‡ºé«˜é‡è¦æ€§ä»¥ä¸Šçš„äº‹ä»¶ï¼‰"""
    try:
        all_data = []
        
        # æŠ“å–æ‰€æœ‰æ•¸æ“š
        logger.info("æ­£åœ¨æŠ“å–ç¶“æ¿Ÿæ•¸æ“šï¼ˆé å‘Šæ¨¡å¼ï¼‰...")
        economic_data = fetch_economic_data()
        all_data.extend(economic_data)
        
        financial_events = fetch_financial_events()
        all_data.extend(financial_events)
        
        central_bank = fetch_central_bank_activities()
        all_data.extend(central_bank)
        
        if not all_data:
            logger.info("æ²’æœ‰ç²å–åˆ°ä»»ä½•æ•¸æ“š")
            return
        
        # éæ¿¾ä»Šæ—¥é«˜é‡è¦æ€§ä»¥ä¸Šçš„äº‹ä»¶ï¼ˆ>= 2ï¼‰
        today_events = filter_today_events(all_data, min_importance=2)
        logger.info(f"ä»Šæ—¥é«˜é‡è¦æ€§ä»¥ä¸Šäº‹ä»¶: {len(today_events)} æ¢")
        
        if not today_events:
            logger.info("ä»Šæ—¥ç„¡é‡è¦äº‹ä»¶")
            return
        
        # ç™¼é€é å‘Š
        message = format_today_preview_message(today_events)
        send_telegram_message(message, TG_THREAD_IDS['economic_data'], parse_mode="Markdown")
        logger.info("ä»Šæ—¥é å‘Šç™¼é€å®Œæˆ")
        
    except Exception as e:
        logger.error(f"ç™¼é€ä»Šæ—¥é å‘ŠéŒ¯èª¤: {str(e)}")


def fetch_and_push_economic_data():
    """ä¸»å‡½æ•¸ï¼šæŠ“å–ä¸¦æ¨é€ç¶“æ¿Ÿæ•¸æ“šï¼ˆåªæ¨æ’­æ¥µé«˜é‡è¦æ€§äº‹ä»¶ï¼Œåœ¨äº‹ä»¶ç™¼ç”Ÿæ™‚ï¼‰"""
    try:
        all_data = []
        
        # 1. æŠ“å–ç¶“æ¿Ÿæ•¸æ“š
        logger.info("æ­£åœ¨æŠ“å–ç¶“æ¿Ÿæ•¸æ“š...")
        economic_data = fetch_economic_data()
        all_data.extend(economic_data)
        logger.info(f"ç¶“æ¿Ÿæ•¸æ“šï¼š{len(economic_data)} æ¢")
        
        # 2. æŠ“å–è²¡ç¶“äº‹ä»¶
        logger.info("æ­£åœ¨æŠ“å–è²¡ç¶“äº‹ä»¶...")
        financial_events = fetch_financial_events()
        all_data.extend(financial_events)
        logger.info(f"è²¡ç¶“äº‹ä»¶ï¼š{len(financial_events)} æ¢")
        
        # 3. æŠ“å–å¤®è¡Œæ´»å‹•
        logger.info("æ­£åœ¨æŠ“å–å¤®è¡Œæ´»å‹•...")
        central_bank = fetch_central_bank_activities()
        all_data.extend(central_bank)
        logger.info(f"å¤®è¡Œæ´»å‹•ï¼š{len(central_bank)} æ¢")
        
        if not all_data:
            logger.info("æ²’æœ‰ç²å–åˆ°ä»»ä½•æ•¸æ“š")
            return
        
        logger.info(f"ç¸½å…±ç²å– {len(all_data)} æ¢æ•¸æ“šï¼ˆç¶“æ¿Ÿæ•¸æ“š: {len(economic_data)}, è²¡ç¶“äº‹ä»¶: {len(financial_events)}, å¤®è¡Œæ´»å‹•: {len(central_bank)}ï¼‰")
        
        # åªéæ¿¾æ¥µé«˜é‡è¦æ€§æ•¸æ“šï¼ˆ>= 3ï¼‰ï¼Œé«˜é‡è¦æ€§ï¼ˆ>= 2 ä¸” < 3ï¼‰ä¸æ¨æ’­
        important_data = filter_important_data(all_data, min_importance=3)
        logger.info(f"éæ¿¾å¾Œçš„æ¥µé«˜é‡è¦æ€§æ•¸æ“š: {len(important_data)} æ¢")
        
        if not important_data:
            logger.info("æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ¥µé«˜é‡è¦æ€§æ•¸æ“š")
            return
        
        # æŒ‰ç™¼å¸ƒæ™‚é–“æ’åºï¼ˆå„ªå…ˆæ¨é€å³å°‡ç™¼å¸ƒçš„ï¼‰
        future_time = datetime(2099, 12, 31, 23, 59, 59, tzinfo=TAIPEI_TZ)
        important_data.sort(key=lambda x: parse_publish_time(x) or future_time)
        
        # æª¢æŸ¥å“ªäº›å°šæœªæ¨é€
        new_data = get_unsent_data(important_data)
        logger.info(f"å°šæœªæ¨é€çš„æ¥µé«˜é‡è¦æ€§æ•¸æ“š: {len(new_data)} æ¢")
        
        if not new_data:
            logger.info("æ‰€æœ‰æ¥µé«˜é‡è¦æ€§æ•¸æ“šå‡å·²æ¨é€é")
            return
        
        # æ‰¹é‡æ¨é€ï¼ˆé¿å…éæ–¼é »ç¹ï¼‰
        success_count = 0
        for idx, data in enumerate(new_data):
            try:
                message = format_economic_data_message(data)
                send_telegram_message(message, TG_THREAD_IDS['economic_data'], parse_mode="Markdown")
                
                data_id = generate_data_id(data)
                mark_as_sent(data_id)
                success_count += 1
                
                # æ¯æ¢è¨Šæ¯é–“éš” 1 ç§’ï¼Œé¿å…è§¸ç™¼é€Ÿç‡é™åˆ¶
                if idx < len(new_data) - 1:
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"æ¨é€å–®æ¢æ•¸æ“šå¤±æ•—: {str(e)}")
        
        logger.info(f"æˆåŠŸæ¨é€ {success_count}/{len(new_data)} æ¢æ¥µé«˜é‡è¦æ€§ç¶“æ¿Ÿæ•¸æ“š")
        
    except Exception as e:
        logger.error(f"ç¶“æ¿Ÿæ•¸æ“šæ¨æ’­åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        send_telegram_message(
            f"âš ï¸ *ç¶“æ¿Ÿæ•¸æ“šæŠ“å–éŒ¯èª¤*\n\néŒ¯èª¤è¨Šæ¯ï¼š{str(e)}\n\nè«‹æª¢æŸ¥ API é‡‘é‘°æˆ–ç¶²è·¯é€£ç·šã€‚", 
            TG_THREAD_IDS['economic_data']
        )


# ==================== 5. æ–°èå¿«è¨Šæ¨ç‰¹ä¸­æ–‡æ¨æ’­ ====================

LAST_NEWS_TIME_FILE = DATA_DIR / "last_news_time.json"
COINGLASS_ARTICLE_IDS_FILE = DATA_DIR / "coinglass_article_ids.json"
COINGLASS_NEWSFLASH_IDS_FILE = DATA_DIR / "coinglass_newsflash_ids.json"


def fetch_tree_news():
    """æŠ“å– Tree of Alpha æ–°è"""
    url = "https://news.treeofalpha.com/api/news"
    params = {"limit": 10}
    headers = {"Authorization": TREE_API_KEY}
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        news_list = response.json()
        
        # å–å¾—å‰ä¸€æ¬¡ç™¼é€çš„æœ€æ™šæ™‚é–“ï¼Œé¿å…é‡è¤‡
        last_time = load_json_file(LAST_NEWS_TIME_FILE, 0)
        newest_time = last_time
        
        # ç”±èˆŠåˆ°æ–°æ’åˆ—ç™¼é€
        for news in reversed(news_list):
            if news.get('time', 0) > last_time:
                process_and_send(news, "Tree of Alpha")
                if news.get('time', 0) > newest_time:
                    newest_time = news.get('time', 0)
        
        # æ›´æ–°æ™‚é–“ç´€éŒ„
        save_json_file(LAST_NEWS_TIME_FILE, newest_time)
        
    except Exception as e:
        logger.warning(f"Tree of Alpha æ–°èæŠ“å–å¤±æ•—: {str(e)}")


def fetch_coinglass_articles():
    """æŠ“å– CoinGlass æ–°è"""
    if not CG_API_KEY:
        logger.warning("è«‹å…ˆè¨­å®š CoinGlass API é‡‘é‘°")
        return
    
    url = "https://open-api-v4.coinglass.com/api/article/list"
    headers = {
        "accept": "application/json",
        "CG-API-KEY": CG_API_KEY
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        result = response.json()
        
        if result.get('code') != '0':
            error_msg = result.get('msg', '')
            # å¦‚æœæ˜¯é€Ÿç‡é™åˆ¶éŒ¯èª¤ï¼Œåªè¨˜éŒ„è­¦å‘Šï¼Œä¸å ±éŒ¯
            if 'Too Many Requests' in error_msg or '429' in str(result.get('code')):
                logger.warning(f"CoinGlass æ–°è API é€Ÿç‡é™åˆ¶ï¼Œç¨å¾Œå†è©¦: {error_msg}")
            else:
                logger.warning(f"CoinGlass æ–°è API éŒ¯èª¤: {result}")
            return
        
        article_list = result.get('data', [])
        
        # å–å¾—å·²ç™¼é€çš„æ–°è ID åˆ—è¡¨
        sent_ids = load_json_file(COINGLASS_ARTICLE_IDS_FILE, [])
        new_sent_ids = sent_ids.copy()
        
        # è™•ç†æ–°èåˆ—è¡¨ï¼ˆç”±èˆŠåˆ°æ–°ï¼‰
        for article in reversed(article_list):
            article_id = article.get('id') or article.get('articleId') or article.get('url')
            
            if article_id and article_id not in sent_ids:
                process_and_send_coinglass(article, "article")
                new_sent_ids.append(article_id)
                
                # åªä¿ç•™æœ€è¿‘ 1000 æ¢ IDï¼Œé¿å…å„²å­˜éå¤š
                if len(new_sent_ids) > 1000:
                    new_sent_ids = new_sent_ids[-1000:]
        
        # æ›´æ–°å·²ç™¼é€ ID åˆ—è¡¨
        save_json_file(COINGLASS_ARTICLE_IDS_FILE, new_sent_ids)
        
    except Exception as e:
        logger.warning(f"CoinGlass æ–°èæŠ“å–å¤±æ•—: {str(e)}")


def fetch_coinglass_newsflash():
    """æŠ“å– CoinGlass å¿«è¨Š"""
    if not CG_API_KEY:
        logger.warning("è«‹å…ˆè¨­å®š CoinGlass API é‡‘é‘°")
        return
    
    url = "https://open-api-v4.coinglass.com/api/newsflash/list"
    headers = {
        "accept": "application/json",
        "CG-API-KEY": CG_API_KEY
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        # æª¢æŸ¥ HTTP ç‹€æ…‹ç¢¼
        if response.status_code != 200:
            logger.warning(f"CoinGlass å¿«è¨Š API HTTP éŒ¯èª¤: {response.status_code} - {response.text[:200]}")
            return
        
        result = response.json()
        
        if result.get('code') != '0':
            error_msg = result.get('msg', '')
            # å¦‚æœæ˜¯é€Ÿç‡é™åˆ¶éŒ¯èª¤ï¼Œåªè¨˜éŒ„è­¦å‘Šï¼Œä¸å ±éŒ¯
            if 'Too Many Requests' in error_msg or '429' in str(result.get('code')):
                logger.warning(f"CoinGlass å¿«è¨Š API é€Ÿç‡é™åˆ¶ï¼Œç¨å¾Œå†è©¦: {error_msg}")
            else:
                logger.warning(f"CoinGlass å¿«è¨Š API éŒ¯èª¤: {result}")
            return
        
        newsflash_list = result.get('data', [])
        
        # å–å¾—å·²ç™¼é€çš„å¿«è¨Š ID åˆ—è¡¨
        sent_ids = load_json_file(COINGLASS_NEWSFLASH_IDS_FILE, [])
        new_sent_ids = sent_ids.copy()
        
        # è™•ç†å¿«è¨Šåˆ—è¡¨ï¼ˆç”±èˆŠåˆ°æ–°ï¼‰
        for newsflash in reversed(newsflash_list):
            newsflash_id = newsflash.get('id') or newsflash.get('newsflashId') or newsflash.get('url')
            
            if newsflash_id and newsflash_id not in sent_ids:
                process_and_send_coinglass(newsflash, "newsflash")
                new_sent_ids.append(newsflash_id)
                
                # åªä¿ç•™æœ€è¿‘ 1000 æ¢ IDï¼Œé¿å…å„²å­˜éå¤š
                if len(new_sent_ids) > 1000:
                    new_sent_ids = new_sent_ids[-1000:]
        
        # æ›´æ–°å·²ç™¼é€ ID åˆ—è¡¨
        save_json_file(COINGLASS_NEWSFLASH_IDS_FILE, new_sent_ids)
        
    except Exception as e:
        logger.warning(f"CoinGlass å¿«è¨ŠæŠ“å–å¤±æ•—: {str(e)}")


def process_and_send(news: Dict, source: str):
    """ç¿»è­¯ä¸¦ç™¼é€ Tree of Alpha æ–°èåˆ° Telegram"""
    translated_title = translate_text(news.get('title', ''))
    
    message = "ğŸ“° *ã€å…¨çƒå¹£åœˆå³æ™‚å¿«è¨Šã€‘*\n\n"
    message += f"ğŸ”” *{translated_title}*\n\n"
    message += f"ğŸ“„ åŸæ–‡ï¼š{news.get('title', '')}\n"
    message += f"ğŸ” ä¾†æºï¼š{news.get('source', '')}\n"
    message += f"ğŸ”— [é»æ“ŠæŸ¥çœ‹åŸæ–‡]({news.get('url', 'https://tree.news')})"
    
    send_telegram_message(message, TG_THREAD_IDS['news'])


def process_and_send_coinglass(item: Dict, type_str: str):
    """ç¿»è­¯ä¸¦ç™¼é€ CoinGlass æ–°è/å¿«è¨Šåˆ° Telegram"""
    is_newsflash = type_str == "newsflash"
    emoji = "âš¡" if is_newsflash else "ğŸ“°"
    type_name = "å¿«è¨Š" if is_newsflash else "æ–°è"
    
    translated_title = translate_text(item.get('title') or item.get('headline') or "")
    translated_content = translate_text(item.get('content') or item.get('description') or "")
    
    message = f"{emoji} *ã€CoinGlass {type_name}ã€‘*\n\n"
    
    if translated_title:
        message += f"ğŸ”” *{translated_title}*\n\n"
    
    if translated_content:
        if len(translated_content) > 500:
            translated_content = translated_content[:500] + "..."
        message += f"{translated_content}\n\n"
    
    time_val = item.get('time') or item.get('timestamp') or item.get('publishTime')
    if time_val:
        if isinstance(time_val, (int, float)):
            if time_val > 1e12:
                date = datetime.fromtimestamp(time_val / 1000, tz=timezone.utc)
            else:
                date = datetime.fromtimestamp(time_val, tz=timezone.utc)
        else:
            date = get_taipei_time()
        # è½‰æ›ç‚ºå°ç£æ™‚é–“
        date_taipei = get_taipei_time(date)
        message += f"ğŸ• æ™‚é–“ï¼š{date_taipei.strftime('%Y-%m-%d %H:%M:%S')}\n"
    
    if item.get('source'):
        message += f"ğŸ” ä¾†æºï¼š{item.get('source')}\n"
    
    if item.get('url') or item.get('link'):
        message += f"ğŸ”— [é»æ“ŠæŸ¥çœ‹åŸæ–‡]({item.get('url') or item.get('link')})"
    
    send_telegram_message(message, TG_THREAD_IDS['news'])


def fetch_all_news():
    """æ•´åˆåŸ·è¡Œå‡½æ•¸ï¼šæŠ“å–æ‰€æœ‰æ–°èä¸¦æ¿ƒç¸®æˆä¸€å€‹ç°¡çŸ­è¨Šæ¯ï¼ˆæ¯4å°æ™‚æ¨æ’­ä¸€æ¬¡ï¼‰"""
    all_news_items = []
    
    # æŠ“å– Tree of Alpha æ–°è
    try:
        url = "https://news.treeofalpha.com/api/news"
        params = {"limit": 5}  # åªå–æœ€æ–°5æ¢
        headers = {"Authorization": TREE_API_KEY}
        response = requests.get(url, params=params, headers=headers, timeout=10)
        news_list = response.json()
        for news in news_list[:5]:  # åªå–å‰5æ¢
            title = translate_text(news.get('title', ''))
            if title:
                all_news_items.append({
                    'title': title,
                    'source': 'Tree of Alpha',
                    'url': news.get('url', '')
                })
    except Exception as e:
        logger.warning(f"Tree of Alpha æ–°èæŠ“å–å¤±æ•—: {str(e)}")
    
    # æŠ“å– CoinGlass æ–°èï¼ˆåªå–æœ€æ–°3æ¢ï¼‰
    if CG_API_KEY:
        try:
            url = "https://open-api-v4.coinglass.com/api/article/list"
            headers = {
                "accept": "application/json",
                "CG-API-KEY": CG_API_KEY
            }
            response = requests.get(url, headers=headers, timeout=10)
            result = response.json()
            if result.get('code') == '0':
                article_list = result.get('data', [])[:3]  # åªå–å‰3æ¢
                for article in article_list:
                    title = translate_text(article.get('title') or article.get('headline') or "")
                    if title:
                        all_news_items.append({
                            'title': title,
                            'source': 'CoinGlass',
                            'url': article.get('url') or article.get('link') or ''
                        })
        except Exception as e:
            logger.warning(f"CoinGlass æ–°èæŠ“å–å¤±æ•—: {str(e)}")
    
    # å¦‚æœæ²’æœ‰æ–°èï¼Œä¸æ¨æ’­
    if not all_news_items:
        logger.info("æœ¬æ¬¡ç›£æ§ç„¡æ–°æ–°èï¼Œè·³éæ¨æ’­")
        return
    
    # æ¿ƒç¸®æˆä¸€å€‹ç°¡çŸ­è¨Šæ¯
    now = get_taipei_time()
    time_str = format_datetime(now)
    
    lines = []
    lines.append("ğŸ“° *ã€å…¨çƒå¹£åœˆå³æ™‚å¿«è¨Šã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    
    # åªé¡¯ç¤ºæ¨™é¡Œï¼Œç°¡çŸ­æ ¼å¼
    for idx, item in enumerate(all_news_items[:8], 1):  # æœ€å¤š8æ¢
        lines.append(f"{idx}. {item['title']}")
        if item.get('url'):
            lines.append(f"   ğŸ”— [æŸ¥çœ‹è©³æƒ…]({item['url']})")
        lines.append("")
    
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"â° æ›´æ–°æ™‚é–“ï¼š{time_str}")
    
    message = "\n".join(lines)
    send_telegram_message(message, TG_THREAD_IDS['news'], parse_mode="Markdown")
    logger.info(f"æ–°èå¿«è¨Šæ¨æ’­å®Œæˆï¼Œå…± {len(all_news_items)} æ¢æ–°è")


# ==================== 6. è³‡é‡‘è²»ç‡ ====================

def fetch_funding_fortune_list():
    """æŠ“å–è³‡é‡‘è²»ç‡æ’è¡Œæ¦œ"""
    url = "https://open-api-v4.coinglass.com/api/futures/funding-rate/exchange-list"
    headers = {
        "accept": "application/json",
        "CG-API-KEY": CG_API_KEY
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        logger.info(f"API å›æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
        
        result = response.json()
        if result.get('code') not in ['0', 0]:
            logger.error(f"API å›æ‡‰éŒ¯èª¤: {result}")
            return
        
        data_list = result.get('data', [])
        if not isinstance(data_list, list):
            logger.error("API æ•¸æ“šæ ¼å¼éŒ¯èª¤")
            return
        
        binance_funding_rates = []
        for coin_data in data_list:
            symbol = coin_data.get('symbol')
            
            # å„ªå…ˆè™•ç† USDT æ°¸çºŒåˆç´„
            stablecoin_list = coin_data.get('stablecoin_margin_list', [])
            for item in stablecoin_list:
                if item.get('exchange') == 'Binance' and item.get('funding_rate') is not None:
                    binance_funding_rates.append({
                        'symbol': symbol,
                        'exchange': item.get('exchange'),
                        'fundingRate': float(item.get('funding_rate', 0)),
                        'marginType': 'USDTæ°¸çºŒ',
                        'fundingRateInterval': item.get('funding_rate_interval', 8)
                    })
            
            # å¦‚æœ USDT æ°¸çºŒæ²’æœ‰å¹£å®‰çš„æ•¸æ“šï¼Œå†æª¢æŸ¥å¹£æœ¬ä½æ°¸çºŒ
            token_list = coin_data.get('token_margin_list', [])
            for item in token_list:
                if item.get('exchange') == 'Binance' and item.get('funding_rate') is not None:
                    has_usdt = any(r['symbol'] == symbol and r['marginType'] == 'USDTæ°¸çºŒ' 
                                   for r in binance_funding_rates)
                    if not has_usdt:
                        binance_funding_rates.append({
                            'symbol': symbol,
                            'exchange': item.get('exchange'),
                            'fundingRate': float(item.get('funding_rate', 0)),
                            'marginType': 'å¹£æœ¬ä½æ°¸çºŒ',
                            'fundingRateInterval': item.get('funding_rate_interval', 8)
                        })
        
        logger.info(f"å¹£å®‰æ°¸çºŒåˆç´„æ•¸æ“šæ¢æ•¸: {len(binance_funding_rates)}")
        
        # æ ¹æ“šè²»ç‡çµ•å°å€¼æ’åºï¼Œå–å‰ 5 å
        sorted_data = sorted(
            [item for item in binance_funding_rates if item['fundingRate'] != 0],
            key=lambda x: abs(x['fundingRate']),
            reverse=True
        )[:5]
        
        if not sorted_data:
            logger.warning("æœªæ‰¾åˆ°å¹£å®‰æ°¸çºŒåˆç´„çš„æœ‰æ•ˆè³‡é‡‘è²»ç‡æ•¸æ“š")
            return
        
        # æ§‹å»ºè¨Šæ¯
        message = "ğŸ¦ *ã€Uæœ¬ä½è³‡é‡‘è²»ç‡æ’è¡Œæ¦œã€‘*\n"
        message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        message += "*ä»¥æŒå€‰ 10,000 USDT ç‚ºä¾‹ï¼Œæ¯ 4 å°æ™‚çµç®—ä¸€æ¬¡ï¼š*\n\n"
        
        for index, item in enumerate(sorted_data):
            symbol = item['symbol']
            rate = item['fundingRate']
            
            rate_percent = f"{abs(rate):.6f}"
            rate_display = f"+{rate_percent}%" if rate >= 0 else f"-{rate_percent}%"
            
            rate_for_calculation = abs(rate) / 100
            single_pay = f"{10000 * 0.4 * rate_for_calculation:.2f}"
            
            message += f"{index + 1}. ğŸ’° *{symbol}USDT æ°¸çºŒ*\n"
            message += f"   ğŸ“Š è³‡é‡‘è²»ç‡ï¼š`{rate_display}`\n"
            message += f"   ğŸ’µ å–®æ¬¡é ˜å–ï¼š`${single_pay}` USDT\n"
            message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        
        message += "\nğŸ’¡ *å¥—åˆ©ç­–ç•¥*ï¼š\n"
        message += "*æ­£è²»ç‡ï¼ˆ+ï¼‰*ï¼šåšç©ºæ°¸çºŒ + æŒæœ‰ç¾è²¨ï¼Œæ¯ 4 å°æ™‚é ˜å–è³‡é‡‘è²»ç‡ã€‚\n"
        message += "*è² è²»ç‡ï¼ˆ-ï¼‰*ï¼šåšå¤šæ°¸çºŒ + è³£å‡ºç¾è²¨ï¼Œä½†éœ€æ³¨æ„è»‹ç©ºé¢¨éšªã€‚\n\n"
        message += "ğŸ“Š æ•¸æ“šä¾†æºï¼š[å¹£å®‰Uæœ¬ä½](https://www.binance.com/zh-TC/futures/funding-history/perpetual/real-time-funding-rate)\n"
        now_taipei = get_taipei_time()
        message += f"â° æ›´æ–°æ™‚é–“ï¼š{now_taipei.strftime('%Y-%m-%d %H:%M:%S')}"
        
        send_telegram_message(message, TG_THREAD_IDS['funding_rate'])
        
    except Exception as e:
        logger.error(f"è³‡è²»æ¦œåŸ·è¡Œå¤±æ•—: {str(e)}")


# ==================== 7. é•·ç·šæŒ‡æ¨™ï¼šç‰›ç†Šå°èˆªå„€ ====================

def _coinglass_get(path: str, params: Optional[Dict] = None) -> Optional[Dict]:
    """é€šç”¨çš„ CoinGlass GET è«‹æ±‚å·¥å…·"""
    if not CG_API_KEY:
        logger.error("CG_API_KEY æœªè¨­å®šï¼Œç„¡æ³•å‘¼å« CoinGlass API")
        return None
    url = f"{CG_API_BASE}{path}"
    headers = {
        "accept": "application/json",
        "CG-API-KEY": CG_API_KEY,
    }
    try:
        resp = requests.get(url, headers=headers, params=params or {}, timeout=10)
        if resp.status_code != 200:
            logger.error(f"CoinGlass API HTTP éŒ¯èª¤ {path}: {resp.status_code} - {resp.text[:200]}")
            return None
        data = resp.json()
        # å¤šæ•¸ CoinGlass ä»‹é¢ code ç‚º '0' ä»£è¡¨æˆåŠŸ
        code = data.get("code", 0)
        if code not in [0, "0", 200, "200"]:
            logger.error(f"CoinGlass API è¿”å›éŒ¯èª¤ {path}: {data}")
            return None
        return data
    except Exception as e:
        logger.error(f"CoinGlass API è«‹æ±‚å¤±æ•— {path}: {str(e)}")
        return None


def _get_latest_from_data(result: Dict) -> Optional[Dict]:
    """å¾ CoinGlass å›æ‡‰ä¸­å–å‡ºæœ€æ–°ä¸€ç­† dataï¼Œç¢ºä¿è¿”å› dict"""
    if not result:
        return None
    data = result.get("data", result)
    if isinstance(data, list):
        if not data:
            return None
        # å–æœ€å¾Œä¸€å€‹å…ƒç´ ï¼Œä½†ç¢ºä¿å®ƒæ˜¯ dict
        last_item = data[-1]
        if isinstance(last_item, dict):
            return last_item
        # å¦‚æœæœ€å¾Œä¸€å€‹å…ƒç´ ä¸æ˜¯ dictï¼Œå˜—è©¦å¾€å‰æ‰¾
        for item in reversed(data):
            if isinstance(item, dict):
                return item
        logger.warning(f"åˆ—è¡¨ä¸­æ²’æœ‰æ‰¾åˆ° dict é¡å‹çš„è³‡æ–™: {data}")
        return None
    if isinstance(data, dict):
        return data
    logger.warning(f"æœªçŸ¥çš„è³‡æ–™æ ¼å¼: {type(data)} - {data}")
    return None


def fetch_ahr999_index() -> Optional[float]:
    """å–å¾—æ¯”ç‰¹å¹£ Ahr999 æŒ‡æ¨™æ•¸å€¼"""
    result = _coinglass_get("/api/index/ahr999")
    point = _get_latest_from_data(result) if result else None
    if not point:
        return None
    # ç¢ºä¿ point æ˜¯ dictï¼Œä¸æ˜¯ list
    if not isinstance(point, dict):
        logger.warning(f"Ahr999 è³‡æ–™æ ¼å¼éŒ¯èª¤ï¼Œé æœŸ dict ä½†å¾—åˆ° {type(point)}: {point}")
        return None
    # å˜—è©¦å¤šå€‹å¸¸è¦‹æ¬„ä½åç¨±ï¼ˆåŒ…å«å¯¦éš› API å›å‚³çš„ ahr999_valueï¼‰
    for key in ("ahr999_value", "ahr999", "ahr999_index", "ahrIndex", "ahr_value"):
        val = point.get(key)
        if val is not None:
            try:
                return float(val)
            except (TypeError, ValueError):
                continue
    logger.warning(f"Ahr999 çµæ§‹æœªçŸ¥ï¼ŒåŸå§‹è³‡æ–™: {point}")
    return None


def get_rainbow_stage(price: Optional[float], levels: Optional[List[float]]) -> str:
    """
    æ ¹æ“šç•¶å‰åƒ¹æ ¼èˆ‡å½©è™¹åœ–åƒ¹æ ¼é–¾å€¼ï¼Œå›å‚³æ–‡å­—æè¿°ã€‚
    levels: ç”±ä½åˆ°é«˜çš„åƒ¹æ ¼é–¾å€¼åˆ—è¡¨ï¼ˆé€šå¸¸ 9 å€‹ï¼‰ã€‚
    """
    if price is None or not levels or len(levels) < 3:
        return "è³‡æ–™ä¸è¶³ï¼Œæš«ç„¡æ³•åˆ¤æ–·"

    # ç¢ºä¿å‡å†ªæ’åº
    levels = sorted(levels)

    # åš´é‡ä½ä¼°
    if price < levels[0]:
        return "åŸºæœ¬ä¸Šæ˜¯ç«ç†±å¤§ç‰¹åƒ¹ï¼ˆæ¥µåº¦ä½ä¼°å€ï¼‰"

    # åš´é‡é«˜ä¼°
    if price > levels[-1]:
        return "æœ€å¤§æ³¡æ²«å€ï¼Œå»ºè­°åˆ†æ‰¹é€ƒé ‚ã€é™ä½æ§“æ¡¿"

    # è½åœ¨å€é–“ä¸­ï¼Œæ‰¾åˆ°å°æ‡‰å€æ®µ
    idx = 0
    for i in range(len(levels) - 1):
        if levels[i] <= price < levels[i + 1]:
            idx = i
            break

    # ä¾ç…§æ‰€åœ¨å€æ®µç²—åˆ†ç‚ºã€Œä½ä½ / ä¸­ä½ / é«˜ä½ã€
    n = len(levels) - 1  # æœ‰ n å€‹å€é–“
    low_border = n // 3
    high_border = (2 * n) // 3

    if idx <= low_border:
        return "åƒ¹æ ¼ä½æ–¼å½©è™¹åœ–ä½ä½å€ï¼Œé©åˆé•·ç·šç´¯ç©/åˆ†æ‰¹åŠ å€‰"
    elif idx <= high_border:
        return "åƒ¹æ ¼ä½æ–¼å½©è™¹åœ–ä¸­é–“å€ï¼Œå±¬æ–¼åˆç†å€é–“ï¼Œåå‘æŒæœ‰/è§€æœ›"
    else:
        return "åƒ¹æ ¼ä½æ–¼å½©è™¹åœ–é«˜ä½å€ï¼Œå¸‚å ´å FOMO/æ³¡æ²«ï¼Œéœ€è¬¹æ…æ§ç®¡é¢¨éšª"


def fetch_rainbow_zone() -> Optional[str]:
    """å–å¾—æ¯”ç‰¹å¹£å½©è™¹åœ–ç•¶å‰å€é–“æè¿°ï¼ˆè½‰æˆå°ç™½å‹å–„æ–‡å­—ï¼‰"""
    result = _coinglass_get("/api/index/bitcoin/rainbow-chart")
    if not result:
        return None

    # å˜—è©¦å¾å›æ‡‰ä¸­å–å¾—ç•¶å‰ BTC åƒ¹æ ¼
    price = None
    for key in ("current_price", "btc_price", "price"):
        val = result.get(key)
        if isinstance(val, (int, float)):
            price = float(val)
            break

    data = result.get("data") or result.get("list")
    levels: Optional[List[float]] = None

    if isinstance(data, list) and data:
        last_row = data[-1]
        # å…¸å‹çµæ§‹ï¼šä¸€åˆ—ç‚º [v1, v2, ..., vN, timestamp] æˆ– [level1..level9]
        if isinstance(last_row, list) and len(last_row) >= 4:
            # å˜—è©¦è¦–æœ€å¾Œä¸€å€‹å…ƒç´ ç‚ºæ™‚é–“æˆ³ï¼Œå…¶é¤˜ç‚ºåƒ¹æ ¼é–¾å€¼
            numeric_parts = [x for x in last_row if isinstance(x, (int, float))]
            if len(numeric_parts) >= 4:
                # è‹¥å°šæœªå–å¾—åƒ¹æ ¼ï¼Œä½¿ç”¨æœ€å¤§å€¼ç•¶å‰åƒ¹æ ¼ä½œç‚ºè¿‘ä¼¼
                if price is None:
                    price = max(numeric_parts)
                # å–é™¤ç•¶å‰åƒ¹æ ¼å¤–è¼ƒå°çš„é‚£äº›ä½œç‚ºã€Œå±¤ç´šã€ï¼Œé¿å…æŠŠæ¥µç«¯æœ€å¤§å€¼ç•¶ä½œå€é–“
                # é€™è£¡ç°¡åŒ–ç‚ºå»æ‰æ•¸åˆ—ä¸­çš„æœ€å¤§å€¼ï¼Œå…¶é¤˜è¦–ç‚ºå½©è™¹å±¤ç´š
                max_val = max(numeric_parts)
                levels = [v for v in numeric_parts if v != max_val] or numeric_parts

    return get_rainbow_stage(price, levels)


def fetch_pi_cycle_signal() -> bool:
    """å–å¾— Pi å¾ªç’°é ‚éƒ¨æŒ‡æ¨™æ˜¯å¦è§¸ç™¼ï¼ˆå‡ç·šäº¤å‰ï¼‰"""
    result = _coinglass_get("/api/index/pi-cycle-indicator")
    point = _get_latest_from_data(result) if result else None
    if not point:
        return False
    # ç¢ºä¿ point æ˜¯ dict
    if not isinstance(point, dict):
        logger.warning(f"Pi å¾ªç’°æŒ‡æ¨™è³‡æ–™æ ¼å¼éŒ¯èª¤ï¼Œé æœŸ dict ä½†å¾—åˆ° {type(point)}: {point}")
        return False

    # 1) ç›´æ¥çš„å¸ƒæ—æ¬„ä½
    for key in ("isCross", "cross", "signal", "topSignal", "top_signal"):
        val = point.get(key)
        if isinstance(val, bool):
            return val
        if isinstance(val, (int, float)) and val in (0, 1):
            return bool(val)
        if isinstance(val, str):
            low = val.lower()
            if low in ("true", "yes", "y", "1", "cross", "top", "sell"):
                return True

    # 2) å¦‚æœæœ‰å…©æ¢å‡ç·šæ•¸å€¼ï¼Œå¯ä»¥ç²—ç•¥åˆ¤æ–·æ˜¯å¦å‰›äº¤å‰
    # ä½ çš„æ—¥èªŒé¡¯ç¤ºçµæ§‹ç‚º: {'ma_110': ..., 'ma_350_mu_2': ..., 'price': ..., 'timestamp': ...}
    short_ma = (
        point.get("short_ma")
        or point.get("shortMA")
        or point.get("fast_ma")
        or point.get("ma_110")
    )
    long_ma = (
        point.get("long_ma")
        or point.get("longMA")
        or point.get("slow_ma")
        or point.get("ma_350_mu_2")
    )
    if short_ma is not None and long_ma is not None:
        try:
            short_ma = float(short_ma)
            long_ma = float(long_ma)
            # åªè¦çŸ­å‡ç·šé«˜æ–¼é•·å‡ç·šï¼Œè¦–ç‚ºæœ‰é ‚éƒ¨é¢¨éšª
            return short_ma >= long_ma
        except (TypeError, ValueError):
            pass

    logger.warning(f"Pi å¾ªç’°æŒ‡æ¨™çµæ§‹æœªçŸ¥ï¼ŒåŸå§‹è³‡æ–™: {point}")
    return False


def fetch_latest_fear_greed() -> Optional[int]:
    """å–å¾—æœ€æ–°ä¸€ç­†ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸"""
    result = _coinglass_get("/api/index/fear-greed-history")
    point = _get_latest_from_data(result) if result else None
    if not point:
        return None

    # 1) æ–°ç‰ˆçµæ§‹ï¼š{'data_list': [ ... æ•´æ•¸åˆ—è¡¨ ... ]}
    if isinstance(point, dict) and "data_list" in point:
        data_list = point.get("data_list")
        if isinstance(data_list, list) and data_list:
            try:
                return int(float(data_list[-1]))
            except (TypeError, ValueError):
                logger.warning(f"ç„¡æ³•è§£æææ‡¼èˆ‡è²ªå©ª data_list æœ€å¾Œä¸€ç­†æ•¸å€¼: {data_list[-1]}")
                return None

    # 2) å‚³çµ±çµæ§‹ï¼šæ¯ç­†æ˜¯ä¸€å€‹ dictï¼Œå« value / score ç­‰æ¬„ä½
    if isinstance(point, dict):
        for key in ("value", "fear_greed", "score", "index"):
            val = point.get(key)
            if val is not None:
                try:
                    return int(float(val))
                except (TypeError, ValueError):
                    continue

    logger.warning(f"ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸çµæ§‹æœªçŸ¥ï¼ŒåŸå§‹è³‡æ–™: {point}")
    return None


def _classify_fear_greed(value: Optional[int]) -> str:
    if value is None:
        return "æœªçŸ¥"
    if value <= 20:
        return "æ¥µåº¦ææ‡¼"
    if value <= 40:
        return "ææ‡¼"
    if value < 60:
        return "ä¸­æ€§"
    if value <= 80:
        return "è²ªå©ª"
    return "æ¥µåº¦è²ªå©ª"


def _describe_fear_greed(value: Optional[int]) -> str:
    """å°‡ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸è½‰æˆæ›´æœ‰ç•«é¢çš„æè¿°æ–‡å­—"""
    if value is None:
        return "æŒ‡æ¨™æš«ç¼ºï¼Œè«‹å…ˆè§€å¯Ÿ Ahr999 èˆ‡åƒ¹æ ¼ä½ç½®ã€‚"
    if value < 25:
        return "ğŸ˜± å¤§å®¶éƒ½åœ¨é€ƒå‘½ï¼Œæƒ…ç·’æ¥µåº¦ææ‡¼ï¼Œå¾€å¾€æ˜¯é•·ç·šæŠ•è³‡äººæ…¢æ…¢æ’¿ä¾¿å®œçš„å€åŸŸã€‚"
    if 45 <= value <= 55:
        return "ğŸ˜ å¸‚å ´æƒ…ç·’æ¥è¿‘ä¸­æ€§ï¼Œé©åˆæŒ‰å…µä¸å‹•ã€ç…§åŸæœ¬ç¯€å¥ç´€å¾‹æ“ä½œå³å¯ã€‚"
    if value > 75:
        return "ğŸ”¥ å¸‚å ´æ¥µåº¦è²ªå©ªï¼Œè³‡é‡‘æƒ…ç·’ç˜‹ç‹‚ï¼Œè«‹ç¹«å¥½å®‰å…¨å¸¶ä¸¦éš¨æ™‚æº–å‚™æ¸›å€‰ã€‚"
    return "æƒ…ç·’å°šæœªåˆ°æ¥µç«¯å€é–“ï¼Œå»ºè­°æ­é… Ahr999 èˆ‡å½©è™¹åœ–ä¸€èµ·ç¶œåˆåˆ¤æ–·ã€‚"


def _interpret_rainbow_zone(zone: Optional[str]) -> str:
    """æŠŠå½©è™¹åœ–çš„è‹±æ–‡å€é–“ç¿»æˆå°ç™½å‹å–„æè¿°"""
    if not zone:
        return "è³‡æ–™ä¸è¶³ï¼Œæš«ç„¡æ³•åˆ¤æ–·"
    z = zone.lower()
    if any(k in z for k in ["buy", "cheap", "accumulate", "bargain", "btfd"]):
        return f"{zone}ï¼ˆé‚„åœ¨åŠ å€‰å€ï¼Œé•·ç·šåä¾¿å®œï¼‰"
    if any(k in z for k in ["hodl", "hold"]):
        return f"{zone}ï¼ˆé•·ç·šæŒæœ‰å€ï¼Œè€å¿ƒæŠ±ç·Šï¼‰"
    if any(k in z for k in ["fomo", "sell", "bubble", "maximum", "overvalued"]):
        return f"{zone}ï¼ˆåæ³¡æ²«/é«˜ä¼°å€ï¼Œé©åˆæ¸›å€‰é¢¨éšªæ§ç®¡ï¼‰"
    return zone


def build_long_term_message() -> Optional[str]:
    """æŠ“å–ä¸¦åˆ†æé•·ç·šæŒ‡æ¨™ï¼Œçµ„æˆ Telegram Markdown æ¨æ’­å…§å®¹"""
    ahr = fetch_ahr999_index()
    rainbow_zone = fetch_rainbow_zone()
    pi_trigger = fetch_pi_cycle_signal()
    fg = fetch_latest_fear_greed()

    if ahr is None and fg is None and not rainbow_zone:
        logger.error("é•·ç·šæŒ‡æ¨™è³‡æ–™çš†å–å¾—å¤±æ•—ï¼Œæ”¾æ£„æ¨æ’­")
        return None

    # Ahr999 å€é–“åˆ¤æ–·
    ahr_status = "æœªçŸ¥"
    ahr_state = "è³‡æ–™ä¸è¶³"
    if ahr is not None:
        if ahr < 0.45:
            ahr_status = "ç‰¹åƒ¹æŠ„åº•æœŸ"
            ahr_state = "æŠ„åº•ä¸­"
        elif ahr <= 1.2:
            ahr_status = "å®šæŠ•å€"
            ahr_state = "å®šæŠ•ä¸­"
        else:
            ahr_status = "é«˜ä¼°å€"
            ahr_state = "è¬¹æ…è§€æœ›"

    # ææ‡¼è²ªå©ª
    fg_mood = _classify_fear_greed(fg)

    # å½©è™¹åœ–ä¸­æ–‡èªªæ˜
    rainbow_desc = _interpret_rainbow_zone(rainbow_zone)

    # æ³¡æ²«é¢¨éšªåˆ¤æ–·ï¼šææ‡¼è²ªå©ª > 80 ä¸” Pi è§¸ç™¼
    bubble_risk = bool(fg is not None and fg > 80 and pi_trigger)

    # é¢¨éšªæç¤º / èˆ¹é•·å»ºè­°
    risk_text = "è³‡æ–™ä¸è¶³ï¼Œæš«ç„¡æ³•è©•ä¼°é¢¨éšªã€‚"
    advice_text = "è«‹å…ˆç¢ºèªæŒ‡æ¨™è³‡æ–™æ˜¯å¦æ­£å¸¸å–å¾—ï¼Œå†åšæ±ºç­–ã€‚"

    if ahr is not None:
        if ahr < 0.45:
            risk_text = "ç›®å‰é•·ç·šé¢¨éšªåä½ï¼Œå±¬æ–¼ã€Œç‰¹åƒ¹æŠ„åº•æœŸã€ï¼Œä½†ä»éœ€åˆ†æ‰¹å¸ƒå±€ã€åš´å®ˆé¢¨éšªã€‚"
            advice_text = "é€™è£¡å±¬æ–¼é•·ç·šé»ƒé‡‘å€é–“ï¼Œå¯ä»¥è€ƒæ…®åˆ†æ‰¹é€¢ä½ä½ˆå±€ï¼Œæ¯”ç‰¹å¹£ç‚ºä¸»ã€å±±å¯¨ç‚ºè¼”ã€‚"
        elif ahr <= 1.2:
            risk_text = "ç›®å‰ä¼°å€¼åˆç†åä¾¿å®œï¼Œã€Œé©åˆå®šæŠ•ã€å€é–“ï¼Œé¢¨éšªèˆ‡å ±é…¬ç›¸å°å‡è¡¡ã€‚"
            advice_text = "å»ºè­°å•Ÿå‹•/ç¶­æŒå›ºå®šé€±æœŸå®šæŠ•ç­–ç•¥ï¼Œä¸ç‚ºçŸ­æœŸæ³¢å‹•æƒ…ç·’åŒ–ã€‚"
        else:
            risk_text = "ç›®å‰ä¼°å€¼åè²´ï¼Œå±¬æ–¼é«˜ä¼°å€ï¼Œè‹¥å†ç–ŠåŠ æƒ…ç·’éç†±ï¼Œéœ€è¬¹æ…é¢å°å›æ’¤é¢¨éšªã€‚"
            advice_text = "ä¸å»ºè­°é‡å€‰è¿½é«˜ï¼Œå¯è€ƒæ…®åªå°é¡è©¦å–®ï¼Œæˆ–ç­‰å¾…æ›´å‹å–„çš„ä¼°å€¼å†é€²å ´ã€‚"

    # ç–ŠåŠ æƒ…ç·’èˆ‡ Pi é ‚éƒ¨ä¿¡è™Ÿèª¿æ•´å»ºè­°
    if fg is not None:
        if fg <= 20:
            risk_text += " å¦å¤–ï¼Œå¸‚å ´è™•æ–¼ã€Œæ¥µåº¦ææ‡¼ã€ï¼ŒçŸ­ç·šå¯èƒ½é‚„æœ‰æ®ºåƒ¹ï¼Œä½†é•·ç·šé€šå¸¸æ˜¯æ©Ÿæœƒå¤§æ–¼é¢¨éšªã€‚"
        elif fg >= 80:
            risk_text += " åŒæ™‚ï¼Œå¸‚å ´è™•æ–¼ã€Œæ¥µåº¦è²ªå©ªã€ï¼Œè³‡é‡‘æƒ…ç·’éç†±ï¼Œè¿½é«˜é¢¨éšªæ¥µå¤§ã€‚"

    if bubble_risk:
        risk_text = "âš ï¸ å¸‚å ´é€²å…¥ã€Œæ³¡æ²«é¢¨éšªæœŸã€ï¼šæƒ…ç·’æ¥µåº¦è²ªå©ªä¸” Pi å¾ªç’°é ‚éƒ¨æŒ‡æ¨™è§¸ç™¼ï¼Œéœ€åš´é˜²å¤§å¹…å›èª¿ã€‚"
        advice_text = "å»ºè­°é€æ­¥æ¸›å€‰ã€é–å®šç²åˆ©ï¼Œé¿å…é«˜æ§“æ¡¿è¿½é«˜ï¼›ä¿ç•™ç¾é‡‘èˆ‡ç©©å®šå¹£ï¼Œç­‰å¾…æ›´å¥½çš„é¢¨éšªå›å ±å€é–“ã€‚"
    elif pi_trigger:
        risk_text += " å¦å¤–ï¼ŒPi å¾ªç’°é ‚éƒ¨æŒ‡æ¨™å·²è§¸ç™¼ï¼Œæ­·å²ä¸Šå¸¸å°æ‡‰ä¸­é•·æœŸé«˜ä½å€ã€‚"
        advice_text = "å¯ä»¥è€ƒæ…®èª¿é™æ•´é«”å€‰ä½ï¼Œå°‡é«˜é¢¨éšªå±±å¯¨å¹£é€æ­¥æ›å›ä¸»æµæˆ–ç©©å®šå¹£ã€‚"

    now_str = format_datetime(get_taipei_time())

    msg_lines = []
    msg_lines.append("ğŸ“Š *ã€ç‰›ç†Šå°èˆªå„€ã€‘*")
    msg_lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    msg_lines.append("")

    # å¸‚å ´æƒ…ç·’ï¼ˆç™½è©±ï¼‰
    if fg is not None:
        msg_lines.append(f"ğŸŒ¡ï¸ *å¸‚å ´æƒ…ç·’*ï¼š{fg_mood}ï¼ˆ{fg}åˆ†ï¼‰")
    else:
        msg_lines.append("ğŸŒ¡ï¸ *å¸‚å ´æƒ…ç·’*ï¼šè³‡æ–™æš«ç¼º")

    # Ahr999ï¼ˆç™½è©±ï¼‰
    if ahr is not None:
        msg_lines.append(f"ğŸ’° *Ahr999*ï¼š{ahr_status}")
    else:
        msg_lines.append("ğŸ’° *Ahr999*ï¼šè³‡æ–™æš«ç¼º")

    # å½©è™¹åœ–ï¼ˆç™½è©±ï¼‰
    msg_lines.append(f"ğŸŒˆ *å½©è™¹åœ–*ï¼š{rainbow_desc}")

    # ä»Šå¤©æ“ä½œæ–¹å‘å»ºè­°ï¼ˆæ–°å¢ï¼‰
    msg_lines.append("")
    msg_lines.append("ğŸ¯ *ä»Šå¤©æ“ä½œæ–¹å‘å»ºè­°*ï¼š")
    
    # æ ¹æ“šæŒ‡æ¨™ç¶œåˆåˆ¤æ–·æ“ä½œæ–¹å‘
    if ahr is not None and fg is not None:
        if ahr < 0.45 and fg < 30:
            msg_lines.append("âœ… å»ºè­°ï¼šåˆ†æ‰¹åšå¤šï¼Œé©åˆæŠ„åº•")
        elif ahr < 1.2 and fg < 60:
            msg_lines.append("âœ… å»ºè­°ï¼šå¯ä»¥è€ƒæ…®åšå¤šï¼Œä½†éœ€è¬¹æ…")
        elif ahr > 1.2 and fg > 70:
            msg_lines.append("âš ï¸ å»ºè­°ï¼šè¬¹æ…åšç©ºï¼Œæ³¨æ„é¢¨éšª")
        elif pi_trigger and fg > 75:
            msg_lines.append("âš ï¸ å»ºè­°ï¼šæ¸›å€‰è§€æœ›ï¼Œç­‰å¾…å›èª¿")
        else:
            msg_lines.append("â¡ï¸ å»ºè­°ï¼šä¿æŒè§€æœ›ï¼Œç­‰å¾…æ˜ç¢ºä¿¡è™Ÿ")
    elif ahr is not None:
        if ahr < 0.45:
            msg_lines.append("âœ… å»ºè­°ï¼šå¯ä»¥è€ƒæ…®åšå¤š")
        elif ahr > 1.2:
            msg_lines.append("âš ï¸ å»ºè­°ï¼šè¬¹æ…åšç©º")
        else:
            msg_lines.append("â¡ï¸ å»ºè­°ï¼šä¿æŒè§€æœ›")
    else:
        msg_lines.append("â¡ï¸ å»ºè­°ï¼šè³‡æ–™ä¸è¶³ï¼Œä¿æŒè§€æœ›")

    # ç°¡åŒ–çš„é¢¨éšªæç¤º
    msg_lines.append("")
    msg_lines.append(f"ğŸš¨ *é¢¨éšªæç¤º*ï¼š{risk_text}")

    # ç°¡åŒ–çš„èˆ¹é•·å»ºè­°
    msg_lines.append("")
    msg_lines.append(f"ğŸ’¡ *æ“ä½œå»ºè­°*ï¼š{advice_text}")
    msg_lines.append("")
    msg_lines.append(f"â° æ›´æ–°æ™‚é–“ï¼š{now_str}")

    return "\n".join(msg_lines)


def run_long_term_monitor(interval_hours: int = 4):
    """24 å°æ™‚å¸¸é§ï¼Œæ¯ interval_hours å°æ™‚æŠ“å–ä¸¦æ¨æ’­ä¸€æ¬¡"""
    logger.info(f"å•Ÿå‹•é•·ç·šæŒ‡æ¨™ç›£æ§ï¼Œæ¯ {interval_hours} å°æ™‚æ›´æ–°ä¸€æ¬¡...")
    interval_sec = max(1, int(interval_hours * 3600))
    while True:
        try:
            message = build_long_term_message()
            if message:
                thread_id = TG_THREAD_IDS.get("long_term_index", 0)
                send_telegram_message(message, thread_id, parse_mode="Markdown")
            else:
                logger.warning("æœ¬è¼ªé•·ç·šæŒ‡æ¨™åˆ†æå¤±æ•—ï¼Œæœªç™¼é€æ¨æ’­")
        except Exception as e:
            logger.error(f"é•·ç·šæŒ‡æ¨™ç›£æ§åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        # ä¼‘æ¯ interval
        time.sleep(interval_sec)


def run_long_term_once():
    """åªåŸ·è¡Œä¸€æ¬¡é•·ç·šæŒ‡æ¨™åˆ†æèˆ‡æ¨æ’­ï¼ˆé©åˆæ’ç¨‹è§¸ç™¼ï¼‰"""
    logger.info("åŸ·è¡Œå–®æ¬¡é•·ç·šæŒ‡æ¨™æ¨æ’­...")
    message = build_long_term_message()
    if not message:
        logger.warning("æœ¬æ¬¡é•·ç·šæŒ‡æ¨™åˆ†æå¤±æ•—ï¼Œæœªç™¼é€æ¨æ’­")
        return
    thread_id = TG_THREAD_IDS.get("long_term_index", 248)
    send_telegram_message(message, thread_id, parse_mode="Markdown")


# ==================== 8. æµå‹•æ€§çµå–é›·é”ï¼ˆæ¥µç«¯æ¸…ç®—ç›£æ§ï¼‰ ====================

LIQ_SYMBOLS = [
    "BTC", "ETH", "SOL",  # åªåµæ¸¬é€™ä¸‰å€‹ä¸»æµå¹£ç¨®
]
LIQ_EXCHANGE_LIST = "Binance"
LIQ_REQUEST_DELAY = 1.2  # ç§’


def get_liquidation_threshold(symbol: str, time_window: str = "1h") -> tuple:
    """æ ¹æ“šå¹£ç¨®å›å‚³æ¥µç«¯çˆ†å€‰é–€æª»ï¼ˆUSDï¼‰
    è¿”å› (1hé˜ˆå€¼, 24hé˜ˆå€¼) çš„å…ƒçµ„
    æ³¨æ„ï¼š1å°æ™‚é–€æª»å·²å¤§å¹…é™ä½ï¼Œä»¥ä¾¿æ•æ‰æ›´å¤šæ¥µç«¯çˆ†å€‰äº‹ä»¶
    """
    if symbol in ("BTC", "ETH"):
        return (100_000.0, 15_000_000.0)  # 1h: 10è¬ï¼ˆå¤§å¹…é™ä½ï¼‰, 24h: 1500è¬
    if symbol in ("SOL", "XRP", "DOGE"):
        return (50_000.0, 5_000_000.0)  # 1h: 5è¬ï¼ˆå¤§å¹…é™ä½ï¼‰, 24h: 500è¬
    return (30_000.0, 3_000_000.0)  # 1h: 3è¬ï¼ˆå¤§å¹…é™ä½ï¼‰, 24h: 300è¬


def fetch_liquidation_data(symbol: str) -> Optional[List[Dict]]:
    """å¾ CoinGlass æŠ“å–å–®ä¸€å¹£ç¨®çš„æ¸…ç®—å½™ç¸½æ­·å²ï¼ˆæ”¹é€²ç‰ˆï¼šæ·»åŠ èª¿è©¦ä¿¡æ¯ï¼‰"""
    if not CG_API_KEY:
        logger.error("CG_API_KEY æœªè¨­å®šï¼Œç„¡æ³•å‘¼å«æ¸…ç®— API")
        return None

    url = f"{CG_API_BASE}/api/futures/liquidation/aggregated-history"
    params = {
        "symbol": symbol,
        "interval": "1h",
        "exchange_list": LIQ_EXCHANGE_LIST,
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json",
    }

    try:
        resp = requests.get(url, params=params, headers=headers, timeout=10)
        if resp.status_code != 200:
            logger.warning(f"{symbol} æ¸…ç®— API è«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {resp.status_code}")
            return None

        data = resp.json()
        if not (data.get("success") is True or data.get("code") in (0, "0")):
            logger.warning(
                f"{symbol} æ¸…ç®— API è¿”å›å¤±æ•— - code: {data.get('code')}, msg: {data.get('msg')}"
            )
            return None

        data_array = data.get("data") or data.get("list") or []
        if not isinstance(data_array, list):
            logger.warning(f"{symbol} æ¸…ç®—æ•¸æ“šæ ¼å¼ç•°å¸¸: {type(data_array)}")
            return None
        
        # èª¿è©¦ï¼šæª¢æŸ¥æ•¸æ“šçµæ§‹ï¼ˆåªå°å‰å¹¾å€‹å¹£ç¨®ï¼‰
        if symbol in ["BTC", "ETH", "SOL"] and data_array:
            sample = data_array[-1] if data_array else {}
            logger.debug(f"{symbol} APIè¿”å› - æ•¸æ“šç­†æ•¸: {len(data_array)}, æœ€æ–°ä¸€ç­†æ™‚é–“æˆ³: {sample.get('time')}, æ¬„ä½: {list(sample.keys())[:8]}")
        
        return data_array
    except Exception as e:
        logger.error(f"ç²å– {symbol} æ¸…ç®—æ•¸æ“šæ™‚ç™¼ç”Ÿç•°å¸¸: {str(e)}")
        return None


def process_liquidation_data(symbol: str, data_array: List[Dict]) -> Optional[Dict]:
    """è™•ç†æ¸…ç®—æ•¸æ“šï¼Œåˆ¤æ–·æ˜¯å¦é”åˆ°æ¥µç«¯çˆ†å€‰é–€æª»ï¼Œè¿”å›äº‹ä»¶æè¿°ï¼ˆæ”¹é€²ç‰ˆï¼šä¿®å¾©æ™‚é–“æˆ³è™•ç†ï¼‰"""
    try:
        if not data_array:
            logger.debug(f"{symbol} æ¸…ç®—æ•¸æ“šç‚ºç©º")
            return None

        now_ms = int(time.time() * 1000)
        twenty_four_hours_ago = now_ms - 24 * 60 * 60 * 1000
        one_hour_ago = now_ms - 60 * 60 * 1000

        buy_vol_usd_24h = 0.0
        sell_vol_usd_24h = 0.0
        buy_vol_usd_1h = 0.0
        sell_vol_usd_1h = 0.0

        # èª¿è©¦ï¼šæª¢æŸ¥æ•¸æ“šçµæ§‹ï¼ˆåªå°å‰å¹¾å€‹å¹£ç¨®ï¼‰
        if symbol in ["BTC", "ETH", "SOL"] and data_array:
            sample_item = data_array[-1] if data_array else {}
            logger.debug(f"{symbol} æ•¸æ“šæ¨£æœ¬ - æ™‚é–“æˆ³: {sample_item.get('time')}, æ¬„ä½: {list(sample_item.keys())[:5]}")

        # å¾å¾Œå¾€å‰éæ­·ï¼Œç´¯åŠ æœ€è¿‘ 24 å°æ™‚èˆ‡ 1 å°æ™‚çš„æ¸…ç®—
        items_in_24h = 0
        items_in_1h = 0
        
        for item in reversed(data_array):
            try:
                item_time_raw = item.get("time") or item.get("timestamp") or 0
                
                # è™•ç†æ™‚é–“æˆ³ï¼šå¯èƒ½æ˜¯æ¯«ç§’æˆ–ç§’
                if isinstance(item_time_raw, str):
                    item_time = int(float(item_time_raw))
                else:
                    item_time = int(item_time_raw)
                
                # å¦‚æœæ™‚é–“æˆ³çœ‹èµ·ä¾†æ˜¯ç§’ï¼ˆå°æ–¼ 1e12ï¼‰ï¼Œè½‰æ›ç‚ºæ¯«ç§’
                if item_time < 1e12:
                    item_time = item_time * 1000
                
            except (TypeError, ValueError) as e:
                logger.debug(f"{symbol} æ™‚é–“æˆ³è§£æå¤±æ•—: {item_time_raw}, éŒ¯èª¤: {str(e)}")
                continue

            long_liq = float(item.get("aggregated_long_liquidation_usd") or item.get("long_liquidation_usd") or item.get("long") or 0)
            short_liq = float(item.get("aggregated_short_liquidation_usd") or item.get("short_liquidation_usd") or item.get("short") or 0)

            if item_time >= twenty_four_hours_ago:
                items_in_24h += 1
                buy_vol_usd_24h += long_liq
                sell_vol_usd_24h += short_liq

                if item_time >= one_hour_ago:
                    items_in_1h += 1
                    buy_vol_usd_1h += long_liq
                    sell_vol_usd_1h += short_liq
            else:
                break

        # èª¿è©¦æ—¥èªŒï¼ˆåªå°å‰å¹¾å€‹å¹£ç¨®æˆ–ç•¶æ•¸æ“šç•°å¸¸æ™‚ï¼‰
        if symbol in ["BTC", "ETH", "SOL"] or (items_in_1h == 0 and items_in_24h > 0):
            logger.debug(f"{symbol} æ™‚é–“ç¯„åœçµ±è¨ˆ - 24hå…§: {items_in_24h} ç­†, 1hå…§: {items_in_1h} ç­†, ç¸½æ•¸æ“š: {len(data_array)} ç­†")

        # å¦‚æœ 24h æ²’æ•¸æ“šï¼Œç”¨æœ€æ–°ä¸€ç­†é ‚ä¸Šï¼ˆå‚™ç”¨é‚è¼¯ï¼‰
        if buy_vol_usd_24h == 0 and sell_vol_usd_24h == 0 and data_array:
            latest = data_array[-1]
            buy_vol_usd_24h = float(latest.get("aggregated_long_liquidation_usd") or latest.get("long_liquidation_usd") or latest.get("long") or 0)
            sell_vol_usd_24h = float(latest.get("aggregated_short_liquidation_usd") or latest.get("short_liquidation_usd") or latest.get("short") or 0)
            buy_vol_usd_1h = buy_vol_usd_24h
            sell_vol_usd_1h = sell_vol_usd_24h

            logger.debug(f"{symbol} æœªæ‰¾åˆ° 24 å°æ™‚å…§æ•¸æ“šï¼Œæ”¹ç”¨æœ€æ–°ä¸€ç­†æ¸…ç®—è³‡æ–™")

        total_vol_usd_24h = buy_vol_usd_24h + sell_vol_usd_24h
        total_vol_usd_1h = buy_vol_usd_1h + sell_vol_usd_1h
        threshold_1h, threshold_24h = get_liquidation_threshold(symbol)

        # è¨˜éŒ„å¯¦éš›æ¸…ç®—æ•¸æ“šä¾›èª¿è©¦
        logger.info(
            f"{symbol} æ¸…ç®—çµ±è¨ˆ - 1h: ${total_vol_usd_1h/10000:.2f}è¬ (é–€æª»: ${threshold_1h/10000:.2f}è¬), "
            f"24h: ${total_vol_usd_24h/10000:.2f}è¬ (é–€æª»: ${threshold_24h/10000:.2f}è¬)"
        )

        # åªæª¢æŸ¥1å°æ™‚é–€æª»ï¼šåªæœ‰éå»1å°æ™‚é”åˆ°é–€æª»æ™‚æ‰æ¨æ’­
        triggered_by_1h = total_vol_usd_1h >= threshold_1h
        
        if not triggered_by_1h:
            logger.debug(
                f"{symbol} æœªé”1å°æ™‚é–€æª» - 1h: {total_vol_usd_1h/10000:.2f}è¬ < {threshold_1h/10000:.2f}è¬"
            )
            return None

        # åˆ¤æ–·ä¸»å°æ¸…ç®—æ–¹å‘ï¼ˆåªç”¨1å°æ™‚æ•¸æ“šï¼‰
        is_long_dom = buy_vol_usd_1h > sell_vol_usd_1h
        dominant_side = "å¤šå–®" if is_long_dom else "ç©ºå–®"
        dominant_amount_1h = buy_vol_usd_1h if is_long_dom else sell_vol_usd_1h

        logger.info(
            f"{symbol} âš ï¸ è§¸ç™¼è­¦å ± (1å°æ™‚æ¥µç«¯çˆ†å€‰) - éå»1h: ${(buy_vol_usd_1h + sell_vol_usd_1h)/10000:.2f}è¬"
        )

        return {
            "symbol": symbol,
            "dominantSide": dominant_side,
            "dominantAmount1h": dominant_amount_1h,
            "totalVolUsd1h": total_vol_usd_1h,
            "buyVolUsd1h": buy_vol_usd_1h,
            "sellVolUsd1h": sell_vol_usd_1h,
        }
    except Exception as e:
        logger.error(f"è™•ç† {symbol} æ¸…ç®—æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None


# ç§»é™¤ generate_liq_symbol_analysis å‡½æ•¸ï¼ˆä¸å†éœ€è¦è¨ºæ–·æ–‡å­—ï¼‰


def format_liquidity_consolidated_message(events: List[Dict]) -> str:
    """å°‡å¤šå€‹æ¸…ç®—äº‹ä»¶æ•´ç†æˆä¸€å‰‡ Telegram æ¨æ’­æ–‡å­—ï¼ˆåªé¡¯ç¤ºéå»1å°æ™‚æ•¸æ“šï¼Œç™½è©±+æ“ä½œå»ºè­°ï¼‰"""
    now = get_taipei_time()
    time_str = now.strftime("%Y-%m-%d %H:%M:%S")

    lines: List[str] = []
    lines.append("ğŸ¯ *ã€æ¸…ç®—çˆ†å€‰é›·é”ã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"ğŸ“Š æœ¬æ¬¡ç›£æ§å…±æœ‰ *{len(events)}* å€‹å¹£ç¨®é”åˆ°æ¥µç«¯çˆ†å€‰é–€æª»\n")

    # ä¾1å°æ™‚ç¸½é‡æ’åº
    events_sorted = sorted(events, key=lambda e: e.get("totalVolUsd1h", 0), reverse=True)

    for ev in events_sorted:
        total_1h = ev.get("totalVolUsd1h", 0.0) / 10_000
        amount_1h = ev["dominantAmount1h"] / 10_000
        dominant_side = ev['dominantSide']

        lines.append(f"ğŸ¥Š *ã€{ev['symbol']}ã€‘*")
        lines.append(f"âš ï¸ éå»1å°æ™‚å…§ç´„æœ‰ *${amount_1h:.2f} è¬* ç¾å…ƒçš„ *{dominant_side}* è¢«å¼·åˆ¶å¹³å€‰ã€‚\n")
        
        # æ“ä½œå»ºè­°ï¼ˆç™½è©±ï¼‰
        if dominant_side == "å¤šå–®":
            lines.append("ğŸ’¡ *æ“ä½œå»ºè­°*ï¼šå¤§é‡å¤šå–®è¢«çˆ†å€‰ï¼Œä»£è¡¨åƒ¹æ ¼ä¸‹è·Œå£“åŠ›å¤§ã€‚")
            lines.append("   â€¢ å¦‚æœåƒ¹æ ¼é‚„åœ¨è·Œï¼Œå¯ä»¥è€ƒæ…®ã€Œæ‘¸é ­ã€åšç©ºï¼Œä½†è¦è¨­å¥½æ­¢æ")
            lines.append("   â€¢ å¦‚æœåƒ¹æ ¼å·²ç¶“è·Œå¾ˆå¤šï¼Œå¯ä»¥è€ƒæ…®ã€Œæ‘¸åº•ã€åšå¤šï¼Œä½†è¦åˆ†æ‰¹é€²å ´")
        else:  # ç©ºå–®
            lines.append("ğŸ’¡ *æ“ä½œå»ºè­°*ï¼šå¤§é‡ç©ºå–®è¢«çˆ†å€‰ï¼Œä»£è¡¨åƒ¹æ ¼ä¸Šæ¼²å‹•èƒ½å¼·ã€‚")
            lines.append("   â€¢ å¦‚æœåƒ¹æ ¼é‚„åœ¨æ¼²ï¼Œå¯ä»¥è€ƒæ…®ã€Œæ‘¸é ­ã€åšç©ºï¼Œä½†è¦è¨­å¥½æ­¢æ")
            lines.append("   â€¢ å¦‚æœåƒ¹æ ¼å·²ç¶“æ¼²å¾ˆå¤šï¼Œå¯ä»¥è€ƒæ…®ã€Œæ‘¸åº•ã€åšå¤šï¼Œä½†è¦åˆ†æ‰¹é€²å ´")
        lines.append("")

    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"â° æ›´æ–°æ™‚é–“ï¼š{time_str}")

    return "\n".join(lines)


def run_liquidity_radar_once():
    """ä¸»æµç¨‹ï¼šæµå‹•æ€§çµå–é›·é”ï¼ˆåŸ·è¡Œä¸€æ¬¡ï¼Œé©åˆæ’ç¨‹æˆ– HTTP è§¸ç™¼ï¼‰"""
    logger.info(f"é–‹å§‹åŸ·è¡Œæµå‹•æ€§çµå–é›·é”ï¼Œå…± {len(LIQ_SYMBOLS)} å€‹å¹£ç¨®...")

    events: List[Dict] = []

    for idx, symbol in enumerate(LIQ_SYMBOLS):
        try:
            data_array = fetch_liquidation_data(symbol)
            if data_array is None:
                continue
            event = process_liquidation_data(symbol, data_array)
            if event:
                events.append(event)
            # æ§åˆ¶è«‹æ±‚ç¯€å¥ï¼Œé¿å…è§¸ç™¼é »ç‡é™åˆ¶
            if idx < len(LIQ_SYMBOLS) - 1:
                time.sleep(LIQ_REQUEST_DELAY)
        except Exception as e:
            logger.error(f"è™•ç† {symbol} æµå‹•æ€§æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    if not events:
        logger.info("æœ¬æ¬¡ç›£æ§ç„¡å¹£ç¨®é”åˆ°æ¥µç«¯çˆ†å€‰é–€æª»")
        return

    msg = format_liquidity_consolidated_message(events)
    thread_id = TG_THREAD_IDS.get("liquidity_radar", 3)
    send_telegram_message(msg, thread_id, parse_mode="Markdown")

    logger.info(f"æµå‹•æ€§çµå–é›·é”å®Œæˆï¼Œæ¨é€ {len(events)} å€‹å¹£ç¨®çš„æ¥µç«¯çˆ†å€‰äº‹ä»¶")


# ==================== 9. å±±å¯¨çˆ†ç™¼é›·é”ï¼ˆAltcoin Season + RSI + Buy Ratioï¼‰ ====================

def _coinglass_simple_get(path: str, params: Optional[Dict] = None) -> Optional[Dict]:
    """ç°¡åŒ–ç‰ˆ GETï¼Œä¸»è¦çµ¦ Altseason / RSI é€™é¡å–®æ¬¡æŸ¥è©¢ç”¨"""
    if not CG_API_KEY:
        logger.error("CG_API_KEY æœªè¨­å®šï¼Œç„¡æ³•å‘¼å« CoinGlass API")
        return None
    url = f"{CG_API_BASE}{path}"
    headers = {
        "accept": "application/json",
        "CG-API-KEY": CG_API_KEY,
    }
    try:
        resp = requests.get(url, headers=headers, params=params or {}, timeout=10)
        if resp.status_code != 200:
            logger.error(f"CoinGlass API HTTP éŒ¯èª¤ {path}: {resp.status_code} - {resp.text[:200]}")
            return None
        data = resp.json()
        if data.get("code") not in (0, "0", 200, "200", None) and not data.get("success", True):
            logger.error(f"CoinGlass API è¿”å›éŒ¯èª¤ {path}: {data}")
            return None
        return data
    except Exception as e:
        logger.error(f"CoinGlass API è«‹æ±‚å¤±æ•— {path}: {str(e)}")
        return None


def fetch_altseason_index() -> Optional[float]:
    """å–å¾—å±±å¯¨å­£æŒ‡æ•¸ (0-100)"""
    data = _coinglass_simple_get("/api/index/altcoin-season")
    if not data:
        logger.warning("Altseason API å›å‚³ç‚ºç©º")
        return None

    # è¨˜éŒ„åŸå§‹æ•¸æ“šçµæ§‹ä»¥ä¾¿èª¿è©¦
    logger.debug(f"Altseason API åŸå§‹å›å‚³: {json.dumps(data, ensure_ascii=False)[:500]}")

    # å˜—è©¦å¤šç¨®å¯èƒ½çš„æ•¸æ“šçµæ§‹
    val = None
    
    # 1) å¦‚æœ data æ˜¯ dict
    if isinstance(data.get("data"), dict):
        inner = data["data"]
        # å˜—è©¦æ›´å¤šå¯èƒ½çš„æ¬„ä½åç¨±
        for key in ("value", "index", "altcoinSeasonIndex", "altcoin_season_index", 
                    "seasonIndex", "season_index", "altcoinIndex", "altcoin_index",
                    "score", "ratio", "percentage"):
            if inner.get(key) is not None:
                val = inner.get(key)
                logger.debug(f"å¾ data[dict] ä¸­æ‰¾åˆ°æ¬„ä½ {key}: {val}")
                break
    
    # 2) å¦‚æœ data æ˜¯ list
    elif isinstance(data.get("data"), list) and data["data"]:
        # å–æœ€å¾Œä¸€ç­†ï¼ˆæœ€æ–°çš„ï¼‰
        inner = data["data"][-1]
        if isinstance(inner, dict):
            for key in ("value", "index", "altcoinSeasonIndex", "altcoin_season_index",
                        "seasonIndex", "season_index", "altcoinIndex", "altcoin_index",
                        "score", "ratio", "percentage"):
                if inner.get(key) is not None:
                    val = inner.get(key)
                    logger.debug(f"å¾ data[list][-1] ä¸­æ‰¾åˆ°æ¬„ä½ {key}: {val}")
                    break
    
    # 3) ç›´æ¥åœ¨é ‚å±¤æ‰¾
    if val is None:
        for key in ("value", "index", "altcoinSeasonIndex", "altcoin_season_index",
                    "seasonIndex", "season_index", "altcoinIndex", "altcoin_index",
                    "score", "ratio", "percentage"):
            if data.get(key) is not None:
                val = data.get(key)
                logger.debug(f"å¾é ‚å±¤æ‰¾åˆ°æ¬„ä½ {key}: {val}")
                break
    
    # 4) å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œå˜—è©¦éæ­·æ‰€æœ‰æ•¸å€¼æ¬„ä½
    if val is None:
        def find_numeric_value(obj, depth=0):
            if depth > 3:  # é¿å…éè¿´å¤ªæ·±
                return None
            if isinstance(obj, (int, float)):
                if 0 <= obj <= 100:  # å±±å¯¨å­£æŒ‡æ•¸æ‡‰è©²åœ¨ 0-100 ä¹‹é–“
                    return obj
            elif isinstance(obj, dict):
                for v in obj.values():
                    result = find_numeric_value(v, depth + 1)
                    if result is not None:
                        return result
            elif isinstance(obj, list):
                for item in obj:
                    result = find_numeric_value(item, depth + 1)
                    if result is not None:
                        return result
            return None
        
        val = find_numeric_value(data)
        if val is not None:
            logger.debug(f"é€éæ·±åº¦æœå°‹æ‰¾åˆ°æ•¸å€¼: {val}")

    # è½‰æ›ç‚º float
    if val is not None:
        try:
            result = float(val)
            # é©—è­‰ç¯„åœ
            if 0 <= result <= 100:
                logger.info(f"æˆåŠŸå–å¾— Altseason æŒ‡æ•¸: {result}")
                return result
            else:
                logger.warning(f"Altseason æŒ‡æ•¸è¶…å‡ºç¯„åœ (0-100): {result}")
        except (TypeError, ValueError) as e:
            logger.warning(f"Altseason æŒ‡æ•¸è½‰æ›å¤±æ•—: {val} - {str(e)}")
    
    logger.warning(f"ç„¡æ³•å¾ Altseason API å›å‚³ä¸­æå–æŒ‡æ•¸ï¼ŒåŸå§‹æ•¸æ“š: {json.dumps(data, ensure_ascii=False)[:500]}")
    return None


def describe_altseason(index_val: Optional[float]) -> str:
    if index_val is None:
        return "è³‡æ–™æš«ç¼ºï¼Œæš«æ™‚ç„¡æ³•æ˜ç¢ºåˆ¤æ–·æ˜¯å±±å¯¨å­£é‚„æ˜¯æ¯”ç‰¹å¹£å­£ã€‚"
    if index_val > 75:
        return "ğŸŒ‹ å±±å¯¨å­£ç‹‚æ­¡ï¼šè³‡é‡‘å¤§å¹…æµå‘å±±å¯¨å¹£ï¼Œæ³¢å‹•èˆ‡é¢¨éšªåŒæ­¥æ”¾å¤§ï¼Œå°å¹£æš´æ¼²æš´è·Œæ©Ÿç‡æ¥µé«˜ã€‚"
    if index_val < 25:
        return "ğŸ›¡ æ¯”ç‰¹å¹£å­£ï¼šè³‡é‡‘ä¸»è¦åœç¹ BTC ç­‰ä¸»æµè³‡ç”¢ï¼Œå±±å¯¨æ™®æ¼²å¯èƒ½é‚„éœ€è¦è€å¿ƒç­‰å¾…ã€‚"
    return "âš– è³‡é‡‘åœ¨æ¯”ç‰¹å¹£èˆ‡å±±å¯¨ä¹‹é–“ç›¸å°å‡è¡¡ï¼Œé ˜é ­ç¾Šå€‹åˆ¥è¡¨ç¾æ›´é‡è¦ã€‚"


def fetch_rsi_list() -> List[Dict]:
    """å–å¾— RSI åˆ—è¡¨ä¸¦è½‰æˆæ¨™æº–åŒ–çš„ dict listï¼Œä¸ä¾è³´ pandas"""
    data = _coinglass_simple_get("/api/futures/rsi/list")
    if not data:
        return []

    raw = data.get("data") or data.get("list") or []
    if not isinstance(raw, list) or not raw:
        logger.warning("RSI åˆ—è¡¨ç‚ºç©ºæˆ–æ ¼å¼ç•°å¸¸")
        return []

    # æ¨™æº–åŒ–æ¬„ä½åç¨±
    result = []
    for item in raw:
        if not isinstance(item, dict):
            continue
        
        # æ‰¾ symbol æ¬„ä½
        symbol = None
        for key in ["symbol", "pair", "coin", "symbolName"]:
            if key in item:
                symbol = str(item[key])
                break
        if not symbol:
            continue

        # æ‰¾ RSI æ¬„ä½
        rsi_1h = None
        rsi_4h = None
        for key, val in item.items():
            kl = key.lower()
            if "rsi" in kl:
                if "1h" in kl or "h1" in kl:
                    try:
                        rsi_1h = float(val) if val is not None else None
                    except (TypeError, ValueError):
                        pass
                elif "4h" in kl or "h4" in kl:
                    try:
                        rsi_4h = float(val) if val is not None else None
                    except (TypeError, ValueError):
                        pass

        # æ‰¾æˆäº¤é‡æ¬„ä½
        volume = None
        for key, val in item.items():
            kl = key.lower()
            if "volume" in kl or "turnover" in kl or "amount" in kl:
                try:
                    volume = float(val) if val is not None else None
                except (TypeError, ValueError):
                    pass
                if volume is not None:
                    break

        result.append({
            "symbol": symbol,
            "rsi_1h": rsi_1h,
            "rsi_4h": rsi_4h,
            "volume": volume
        })

    return result


def fetch_buy_ratio(symbol: str) -> Optional[float]:
    """
    è¿‘ä¼¼è¨ˆç®—æŸå¹£ç¨®çš„ Buy Ratioï¼ˆç”±èšåˆæ›å–®æ·±åº¦è¿‘ä¼¼ï¼Œbids / (bids + asks)ï¼‰
    ä½¿ç”¨ /api/futures/orderbook/aggregated-ask-bids-history
    """
    data = _coinglass_simple_get(
        "/api/futures/orderbook/aggregated-ask-bids-history",
        params={"exchange_list": "Binance", "symbol": symbol, "interval": "h1"},
    )
    if not data:
        return None

    arr = data.get("data") or data.get("list") or []
    if not isinstance(arr, list) or not arr:
        return None

    last = arr[-1]
    if isinstance(last, dict):
        # å˜—è©¦å¤šç¨®æ¬„ä½åç¨±
        bid_keys = [k for k in last.keys() if "bid" in k.lower()]
        ask_keys = [k for k in last.keys() if "ask" in k.lower()]
        bid_val = float(last.get(bid_keys[0]) or 0) if bid_keys else 0.0
        ask_val = float(last.get(ask_keys[0]) or 0) if ask_keys else 0.0
    elif isinstance(last, list):
        # å‡è¨­çµæ§‹ [bids, asks, time] æˆ– [asks, bids, time]ï¼Œå„˜é‡å®¹éŒ¯
        numeric = [x for x in last if isinstance(x, (int, float))]
        if len(numeric) >= 2:
            # å‡è¨­ç¬¬ä¸€å€‹æ˜¯ bidsï¼Œç¬¬äºŒå€‹æ˜¯ asks
            bid_val, ask_val = float(numeric[0]), float(numeric[1])
        else:
            return None
    else:
        return None

    total = bid_val + ask_val
    if total <= 0:
        return None
    return bid_val / total * 100.0  # è½‰æˆç™¾åˆ†æ¯”


def fetch_price_history(symbol: str, interval: str = "1h") -> Optional[List[Dict]]:
    """ç²å–åƒ¹æ ¼æ­·å²æ•¸æ“šï¼ˆOHLCï¼‰
    æ³¨æ„ï¼šæ ¹æ“š CoinGlass API v4 æ–‡æª”ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ç‰¹å®šçš„åƒ¹æ ¼æ­·å²ç«¯é»
    é€™è£¡å˜—è©¦å¤šç¨®æ–¹æ³•ç²å–åƒ¹æ ¼æ•¸æ“š
    """
    # æ–¹æ³•1ï¼šå˜—è©¦ä½¿ç”¨åƒ¹æ ¼æ­·å²ç«¯é»ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    # æ ¹æ“šç”¨æˆ¶æä¾›çš„ API æ–‡æª”ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ä¸åŒçš„ç«¯é»
    # æš«æ™‚ä½¿ç”¨ OI history ç«¯é»ï¼Œå› ç‚ºå®ƒå¯èƒ½åŒ…å«åƒ¹æ ¼ä¿¡æ¯
    
    url = f"{CG_API_BASE}/api/futures/open-interest/history"
    params = {
        "exchange": "Binance",
        "symbol": symbol,
        "interval": interval
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        logger.debug(f"å˜—è©¦ç²å–åƒ¹æ ¼æ­·å² {symbol}ï¼Œä½¿ç”¨ OI history ç«¯é»")
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data.get('code') in ['0', 0, 200, '200']:
                data_list = data.get('data', [])
                if isinstance(data_list, list) and len(data_list) > 0:
                    # æª¢æŸ¥æ•¸æ“šçµæ§‹ï¼Œçœ‹æ˜¯å¦æœ‰åƒ¹æ ¼å­—æ®µ
                    sample = data_list[0]
                    logger.debug(f"åƒ¹æ ¼æ­·å²æ•¸æ“šæ¨£æœ¬ {symbol}: {list(sample.keys())[:10]}")
                    # OI æ•¸æ“šå¯èƒ½åŒ…å« markPrice æˆ–å…¶ä»–åƒ¹æ ¼å­—æ®µ
                    if any(key in sample for key in ['price', 'close', 'markPrice', 'mark_price', 'open', 'high', 'low']):
                        logger.debug(f"å¾ OI ç«¯é»ç²å–åˆ°åƒ¹æ ¼æ•¸æ“š {symbol}: {len(data_list)} æ¢")
                        return data_list
                    else:
                        logger.debug(f"OI ç«¯é»æ•¸æ“š {symbol} ä¸åŒ…å«åƒ¹æ ¼å­—æ®µï¼Œå¯ç”¨å­—æ®µ: {list(sample.keys())}")
        
        # å¦‚æœ OI ç«¯é»æ²’æœ‰åƒ¹æ ¼ï¼Œè¿”å› Noneï¼ˆéœ€è¦å…¶ä»–æ–¹æ³•ç²å–åƒ¹æ ¼ï¼‰
        logger.debug(f"ç„¡æ³•å¾ OI ç«¯é»ç²å–åƒ¹æ ¼æ•¸æ“š for {symbol}")
        return None
    except Exception as e:
        logger.debug(f"ç²å–åƒ¹æ ¼æ­·å²å¤±æ•— {symbol}: {str(e)}")
        return None


def fetch_aggregated_cvd_history(symbol: str, interval: str = "1h") -> Optional[List[Dict]]:
    """ç²å–èšåˆç´¯è¨ˆæˆäº¤é‡å·®å€¼ï¼ˆCVDï¼‰æ­·å²æ•¸æ“š"""
    url = "https://open-api-v4.coinglass.com/api/futures/aggregated-cvd/history"
    params = {
        "exchange_list": "Binance",
        "symbol": symbol,
        "interval": interval
    }
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        logger.debug(f"å˜—è©¦ç²å– CVD æ­·å² {symbol}")
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.debug(f"èšåˆ CVD API è¿”å›ç‹€æ…‹ç¢¼: {response.status_code} for {symbol}")
            return None
        
        data = response.json()
        if data.get('code') not in ['0', 0, 200, '200']:
            error_msg = data.get('msg') or data.get('message') or 'æœªçŸ¥éŒ¯èª¤'
            logger.debug(f"èšåˆ CVD API è¿”å›éŒ¯èª¤: {error_msg} (code: {data.get('code')}) for {symbol}")
            return None
        
        data_list = data.get('data', [])
        if isinstance(data_list, list) and len(data_list) > 0:
            logger.debug(f"æˆåŠŸç²å– CVD æ­·å² {symbol}: {len(data_list)} æ¢")
            # è¼¸å‡ºæ•¸æ“šæ¨£æœ¬ä»¥ä¾¿èª¿è©¦
            if len(data_list) > 0:
                sample = data_list[0]
                logger.debug(f"CVD æ•¸æ“šæ¨£æœ¬ {symbol}: å­—æ®µ {list(sample.keys())[:10]}")
            return data_list
        else:
            logger.debug(f"èšåˆ CVD API è¿”å›ç©ºæ•¸æ“š for {symbol}")
            return None
    except Exception as e:
        logger.debug(f"ç²å–èšåˆ CVD æ­·å²å¤±æ•— {symbol}: {str(e)}")
        import traceback
        logger.debug(traceback.format_exc())
        return None


def detect_cvd_divergence(symbol: str) -> Optional[str]:
    """æª¢æ¸¬ CVD èƒŒé›¢ï¼ˆçœ‹æ¼²/çœ‹è·Œï¼‰
    è¿”å›: 'bullish' (çœ‹æ¼²èƒŒé›¢), 'bearish' (çœ‹è·ŒèƒŒé›¢), None (ç„¡èƒŒé›¢)
    """
    try:
        # ç²å–æœ€è¿‘ 4 å°æ™‚çš„åƒ¹æ ¼æ­·å²ï¼ˆéœ€è¦è‡³å°‘ 5 å€‹æ•¸æ“šé»ä¾†æ¯”è¼ƒï¼‰
        price_data = fetch_price_history(symbol + "USDT", "1h")
        if not price_data or len(price_data) < 5:
            logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: åƒ¹æ ¼æ•¸æ“šä¸è¶³ï¼ˆ{len(price_data) if price_data else 0} å€‹æ•¸æ“šé»ï¼‰")
            return None
        
        # ç²å–æœ€è¿‘ 4 å°æ™‚çš„ CVD æ­·å²
        base_symbol = symbol.replace("USDT", "")
        cvd_data = fetch_aggregated_cvd_history(base_symbol, "1h")
        if not cvd_data or len(cvd_data) < 5:
            logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: CVD æ•¸æ“šä¸è¶³ï¼ˆ{len(cvd_data) if cvd_data else 0} å€‹æ•¸æ“šé»ï¼‰")
            return None
        
        logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: åƒ¹æ ¼æ•¸æ“š {len(price_data)} æ¢, CVD æ•¸æ“š {len(cvd_data)} æ¢")
        
        # æŒ‰æ™‚é–“æˆ³æ’åºï¼ˆè™•ç† None å€¼ï¼‰
        def get_sort_key(item):
            time_val = item.get('time') or item.get('timestamp')
            if time_val is not None:
                return time_val
            return 0
        
        price_sorted = sorted(price_data, key=get_sort_key)
        cvd_sorted = sorted(cvd_data, key=get_sort_key)
        
        # å–æœ€è¿‘ 5 å€‹æ•¸æ“šé»ï¼ˆç•¶å‰ + å‰ 4 å€‹ï¼‰
        recent_prices = price_sorted[-5:] if len(price_sorted) >= 5 else price_sorted
        recent_cvds = cvd_sorted[-5:] if len(cvd_sorted) >= 5 else cvd_sorted
        
        logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: å–æœ€è¿‘ {len(recent_prices)} å€‹åƒ¹æ ¼æ•¸æ“šé», {len(recent_cvds)} å€‹ CVD æ•¸æ“šé»")
        
        # æå–åƒ¹æ ¼é«˜é»å’Œä½é»ï¼ˆå˜—è©¦å¤šç¨®å­—æ®µåç¨±ï¼‰
        price_highs = []
        price_lows = []
        for item in recent_prices:
            # å˜—è©¦å¤šç¨®å¯èƒ½çš„åƒ¹æ ¼å­—æ®µï¼ˆå„ªå…ˆä½¿ç”¨ OHLC æ•¸æ“šï¼‰
            high = (item.get('high') or item.get('markPrice') or item.get('mark_price') or 
                   item.get('close') or item.get('price') or item.get('value'))
            low = (item.get('low') or item.get('markPrice') or item.get('mark_price') or 
                  item.get('close') or item.get('price') or item.get('value'))
            
            # å¦‚æœæ²’æœ‰ high/lowï¼Œä½¿ç”¨ close ä½œç‚ºå‚™ç”¨
            if not high or not low:
                close_price = item.get('close') or item.get('markPrice') or item.get('mark_price') or item.get('price')
                if close_price:
                    high = close_price
                    low = close_price
            
            if high and low:
                try:
                    price_highs.append(float(high))
                    price_lows.append(float(low))
                except (ValueError, TypeError):
                    continue
        
        # æå– CVD å€¼ï¼ˆå˜—è©¦å¤šç¨®å­—æ®µåç¨±ï¼‰
        cvd_values = []
        for item in recent_cvds:
            # å˜—è©¦å¤šç¨®å¯èƒ½çš„ CVD å­—æ®µ
            cvd = (item.get('cvd') or item.get('value') or 
                  item.get('close') or item.get('cvdValue') or
                  item.get('cumulativeVolumeDelta') or item.get('volumeDelta'))
            if cvd is not None:
                try:
                    cvd_values.append(float(cvd))
                except (ValueError, TypeError) as e:
                    logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: CVD è½‰æ›å¤±æ•— {cvd}: {str(e)}")
                    continue
        
        logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: æå–åˆ° {len(cvd_values)} å€‹ CVD å€¼")
        
        # å¦‚æœæ•¸æ“šé»ä¸è¶³ï¼Œå˜—è©¦ä½¿ç”¨æ›´å°‘çš„æ•¸æ“šé»ï¼ˆè‡³å°‘éœ€è¦ 2 å€‹é»ä¾†æ¯”è¼ƒï¼‰
        min_points = 2  # é™ä½è¦æ±‚ï¼Œè‡³å°‘éœ€è¦ 2 å€‹é»ä¾†æ¯”è¼ƒ
        
        if len(price_highs) < min_points or len(price_lows) < min_points or len(cvd_values) < min_points:
            logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: æ•¸æ“šé»ä¸è¶³ (åƒ¹æ ¼é«˜é»: {len(price_highs)}, åƒ¹æ ¼ä½é»: {len(price_lows)}, CVD: {len(cvd_values)})")
            # è¼¸å‡ºæ¨£æœ¬æ•¸æ“šä»¥ä¾¿èª¿è©¦
            if recent_prices:
                logger.debug(f"åƒ¹æ ¼æ•¸æ“šæ¨£æœ¬: {recent_prices[0]}")
            if recent_cvds:
                logger.debug(f"CVD æ•¸æ“šæ¨£æœ¬: {recent_cvds[0]}")
            return None
        
        # å¦‚æœæ•¸æ“šé»ä¸è¶³ 5 å€‹ï¼Œä½¿ç”¨ç¾æœ‰çš„æ•¸æ“šé»
        if len(price_highs) < 5:
            logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: åƒ¹æ ¼æ•¸æ“šé»ä¸è¶³ 5 å€‹ï¼Œä½¿ç”¨ {len(price_highs)} å€‹é»")
        if len(cvd_values) < 5:
            logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: CVD æ•¸æ“šé»ä¸è¶³ 5 å€‹ï¼Œä½¿ç”¨ {len(cvd_values)} å€‹é»")
        
        # ç•¶å‰å€¼ï¼ˆæœ€å¾Œä¸€å€‹ï¼‰
        current_price_high = price_highs[-1]
        current_price_low = price_lows[-1]
        current_cvd = cvd_values[-1]
        
        # å‰ N-1 å€‹æ•¸æ“šé»çš„æœ€é«˜/æœ€ä½ï¼ˆå¦‚æœåªæœ‰ 2 å€‹é»ï¼Œå°±æ¯”è¼ƒç¬¬ä¸€å€‹å’Œæœ€å¾Œä¸€å€‹ï¼‰
        if len(price_highs) >= 2:
            previous_price_high = max(price_highs[:-1])
            previous_price_low = min(price_lows[:-1])
        else:
            previous_price_high = price_highs[0] if len(price_highs) > 0 else current_price_high
            previous_price_low = price_lows[0] if len(price_lows) > 0 else current_price_low
        
        if len(cvd_values) >= 2:
            previous_cvd_max = max(cvd_values[:-1])
            previous_cvd_min = min(cvd_values[:-1])
        else:
            previous_cvd_max = cvd_values[0] if len(cvd_values) > 0 else current_cvd
            previous_cvd_min = cvd_values[0] if len(cvd_values) > 0 else current_cvd
        
        logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: ç•¶å‰åƒ¹æ ¼é«˜/ä½: {current_price_high}/{current_price_low}, ä¹‹å‰æœ€é«˜/æœ€ä½: {previous_price_high}/{previous_price_low}")
        logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: ç•¶å‰ CVD: {current_cvd}, ä¹‹å‰æœ€å¤§/æœ€å°: {previous_cvd_max}/{previous_cvd_min}")
        
        # çœ‹è·ŒèƒŒé›¢ï¼šåƒ¹æ ¼å‰µé«˜ä½† CVD ä¸‹é™
        if current_price_high > previous_price_high and current_cvd < previous_cvd_max:
            logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: âœ… æª¢æ¸¬åˆ°çœ‹è·ŒèƒŒé›¢ (åƒ¹æ ¼: {current_price_high:.2f} > {previous_price_high:.2f}, CVD: {current_cvd:.2f} < {previous_cvd_max:.2f})")
            return 'bearish'
        
        # çœ‹æ¼²èƒŒé›¢ï¼šåƒ¹æ ¼å‰µä½ä½† CVD ä¸Šå‡
        if current_price_low < previous_price_low and current_cvd > previous_cvd_min:
            logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: âœ… æª¢æ¸¬åˆ°çœ‹æ¼²èƒŒé›¢ (åƒ¹æ ¼: {current_price_low:.2f} < {previous_price_low:.2f}, CVD: {current_cvd:.2f} > {previous_cvd_min:.2f})")
            return 'bullish'
        
        logger.debug(f"CVD èƒŒé›¢æª¢æ¸¬ {symbol}: ç„¡èƒŒé›¢ (åƒ¹æ ¼é«˜: {current_price_high:.2f}/{previous_price_high:.2f}, åƒ¹æ ¼ä½: {current_price_low:.2f}/{previous_price_low:.2f}, CVD: {current_cvd:.2f}/{previous_cvd_max:.2f}/{previous_cvd_min:.2f})")
        return None
    except Exception as e:
        logger.warning(f"CVD èƒŒé›¢æª¢æ¸¬å¤±æ•— {symbol}: {str(e)}")
        import traceback
        logger.debug(traceback.format_exc())
        return None


def build_altseason_message() -> Optional[str]:
    """çµ„åˆå±±å¯¨çˆ†ç™¼é›·é”è¨Šæ¯ï¼ˆä¸ä¾è³´ pandasï¼ŒåŠ å…¥ CVD èƒŒé›¢åˆ¤æ–·ï¼‰"""
    index_val = fetch_altseason_index()
    rsi_list = fetch_rsi_list()
    if not rsi_list:
        logger.error("ç„¡æ³•å–å¾— RSI åˆ—è¡¨ï¼Œæ”¾æ£„æ¨æ’­")
        return None

    # åªçœ‹æˆäº¤é¡å‰ 50 å¤§ï¼Œé¿å…åƒåœ¾å¹£
    rsi_with_vol = [r for r in rsi_list if r.get("volume") is not None]
    if rsi_with_vol:
        rsi_with_vol.sort(key=lambda x: x.get("volume") or 0, reverse=True)
        rsi_list = rsi_with_vol[:50] + [r for r in rsi_list if r.get("volume") is None]

    # æ¨™æº–åŒ– RSIï¼šå„ªå…ˆä½¿ç”¨ 4hï¼Œæ²’æœ‰æ‰ç”¨ 1h
    for item in rsi_list:
        rsi_base = item.get("rsi_4h")
        if rsi_base is None:
            rsi_base = item.get("rsi_1h")
        item["rsi_base"] = rsi_base

    # éæ¿¾æ‰æ²’æœ‰ RSI çš„é …ç›®
    rsi_list = [r for r in rsi_list if r.get("rsi_base") is not None]

    # å¼·å‹¢çªç ´ï¼šRSI >= 70
    strong_list = [r for r in rsi_list if r.get("rsi_base", 0) >= 70]
    # è¶…è³£åå½ˆï¼šRSI <= 30
    oversold_list = [r for r in rsi_list if r.get("rsi_base", 100) <= 30]

    # åŠ å…¥ Buy Ratio éæ¿¾
    def attach_buy_ratio(items: List[Dict]) -> List[Dict]:
        result = []
        for item in items:
            sym = item.get("symbol", "")
            base = sym.replace("USDT", "")
            ratio = fetch_buy_ratio(base)
            if ratio is None:
                ratio = fetch_buy_ratio(sym)
            item["buy_ratio"] = ratio
            if ratio is not None:
                result.append(item)
            time.sleep(0.8)
        return result

    # å¼·å‹¢çªç ´ï¼šè²·å…¥æ¯” >= 55%
    if strong_list:
        strong_list = attach_buy_ratio(strong_list)
        strong_list = [r for r in strong_list if r.get("buy_ratio", 0) >= 55.0]
        strong_list.sort(key=lambda x: (x.get("rsi_base", 0), x.get("buy_ratio", 0)), reverse=True)
        strong_list = strong_list[:5]

    # è¶…è³£åå½ˆï¼šè²·å…¥æ¯” >= 52%
    if oversold_list:
        oversold_list = attach_buy_ratio(oversold_list)
        oversold_list = [r for r in oversold_list if r.get("buy_ratio", 0) >= 52.0]
        oversold_list.sort(key=lambda x: (x.get("rsi_base", 100), -x.get("buy_ratio", 0)))
        oversold_list = oversold_list[:5]

    now_str = format_datetime(get_taipei_time())

    lines: List[str] = []
    lines.append("ğŸ›°ï¸ *ã€å€å¡Šéˆèˆ¹é•· - å±±å¯¨çˆ†ç™¼é›·é”ã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

    # å±±å¯¨å­£æŒ‡æ•¸
    if index_val is not None:
        season = "å±±å¯¨å­£" if index_val > 50 else "æ¯”ç‰¹å¹£å­£"
        lines.append(f"ğŸ“… *ç•¶å‰é€±æœŸ*ï¼š{season}")
        lines.append(f"ğŸ“ˆ *å±±å¯¨å­£æŒ‡æ•¸*ï¼š{index_val:.2f}ï¼ˆ0-100ï¼‰")
    else:
        lines.append("ğŸ“… *ç•¶å‰é€±æœŸ*ï¼šè³‡æ–™æš«ç¼º")
        lines.append("ğŸ“ˆ *å±±å¯¨å­£æŒ‡æ•¸*ï¼šæš«ç„¡æ³•å–å¾—")

    lines.append("")
    lines.append(describe_altseason(index_val))
    lines.append("")

    # å¼·å‹¢çªç ´å€ï¼ˆåŠ å…¥ CVD èƒŒé›¢åˆ¤æ–·ï¼‰
    lines.append("ğŸ”¥ *æ½›åŠ›é ˜é ­ç¾Šï¼ˆå¼·å‹¢çªç ´ï¼‰*ï¼š")
    if not strong_list:
        lines.append("ç›®å‰æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢çªç ´å±±å¯¨å¹£ã€‚")
    else:
        for idx, item in enumerate(strong_list, 1):
            s = str(item.get("symbol", ""))
            rsi_v = float(item.get("rsi_base", 0))
            br = float(item.get("buy_ratio", 0))
            
            # æª¢æ¸¬ CVD èƒŒé›¢
            base_symbol = s.replace("USDT", "")
            try:
                divergence = detect_cvd_divergence(base_symbol)
                logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {base_symbol}: {divergence}")
            except Exception as e:
                logger.warning(f"CVD èƒŒé›¢æª¢æ¸¬å¤±æ•— {base_symbol}: {str(e)}")
                divergence = None
            
            divergence_text = ""
            if divergence == 'bearish':
                divergence_text = " âš ï¸ çœ‹è·ŒèƒŒé›¢"
            elif divergence == 'bullish':
                divergence_text = " ğŸš€ çœ‹æ¼²èƒŒé›¢"
            
            lines.append(f"{idx}. `{s}` - RSI: *{rsi_v:.1f}* ï½œ è²·å…¥æ¯”: *{br:.1f}%*{divergence_text}")
            
            # é¿å…è«‹æ±‚éæ–¼é »ç¹
            if idx < len(strong_list):
                time.sleep(0.5)
    lines.append("")
    
    # è¶…è³£åå½ˆå€ï¼ˆåŠ å…¥ CVD èƒŒé›¢åˆ¤æ–·ï¼‰
    lines.append("ğŸ’ *è¶…è³£åå½ˆæ©Ÿæœƒï¼ˆæŠ„åº•åƒè€ƒï¼‰*ï¼š")
    if not oversold_list:
        lines.append("ç›®å‰æ²’æœ‰æ˜é¡¯çš„è¶…è³£åå½ˆå€™é¸ã€‚")
    else:
        for idx, item in enumerate(oversold_list, 1):
            s = str(item.get("symbol", ""))
            rsi_v = float(item.get("rsi_base", 0))
            br = float(item.get("buy_ratio", 0))
            
            # æª¢æ¸¬ CVD èƒŒé›¢
            base_symbol = s.replace("USDT", "")
            try:
                divergence = detect_cvd_divergence(base_symbol)
                logger.info(f"CVD èƒŒé›¢æª¢æ¸¬ {base_symbol}: {divergence}")
            except Exception as e:
                logger.warning(f"CVD èƒŒé›¢æª¢æ¸¬å¤±æ•— {base_symbol}: {str(e)}")
                divergence = None
            
            divergence_text = ""
            if divergence == 'bearish':
                divergence_text = " âš ï¸ çœ‹è·ŒèƒŒé›¢"
            elif divergence == 'bullish':
                divergence_text = " ğŸš€ çœ‹æ¼²èƒŒé›¢"
            
            lines.append(f"{idx}. `{s}` - RSI: *{rsi_v:.1f}* ï½œ è²·å…¥æ¯”: *{br:.1f}%*{divergence_text}")
            
            # é¿å…è«‹æ±‚éæ–¼é »ç¹
            if idx < len(oversold_list):
                time.sleep(0.5)
    lines.append("")

    # æç¤ºï¼ˆåŠ å…¥ CVD èƒŒé›¢èªªæ˜ï¼‰
    lines.append("ğŸ’¡ *èˆ¹é•·æç¤º*ï¼š")
    if index_val is not None and index_val > 60:
        lines.append("å±±å¯¨å­£æŒ‡æ•¸æ­£åœ¨æŠ¬å‡ï¼Œè³‡é‡‘é–‹å§‹åŠ é€Ÿæµå‘å°å¹£ï¼Œå»ºè­°é‡é»é—œæ³¨é ˜é ­ç¾ŠäºŒæ¸¬èˆ‡æ”¾é‡çªç ´ã€‚")
    elif index_val is not None and index_val < 40:
        lines.append("ç›®å‰ä»åå‘æ¯”ç‰¹å¹£å­£ï¼Œå±±å¯¨æ³¢å‹•ç›¸å°å—é™ï¼Œå»ºè­°ä»¥ä¸»æµå¹£èˆ‡ç¾è²¨ç‚ºä¸»ï¼Œè€å¿ƒç­‰å¾…è³‡é‡‘è¼ªå‹•ã€‚")
    else:
        lines.append("è³‡é‡‘å°šæœªæ˜é¡¯åå‘ä»»ä½•ä¸€æ–¹ï¼Œé¸æ“‡å±±å¯¨æ™‚æ›´è¦æ­é…æˆäº¤é‡èˆ‡è²·å…¥æ¯”ç‡ï¼Œé¿å…è¿½åœ¨å‡çªç ´ä¸Šã€‚")
    
    lines.append("")
    lines.append("ğŸ“Š *CVD èƒŒé›¢èªªæ˜*ï¼š")
    lines.append("â€¢ âš ï¸ çœ‹è·ŒèƒŒé›¢ï¼šåƒ¹æ ¼å‰µé«˜ä½† CVD ä¸‹é™ï¼ˆå¤§æˆ¶æ´¾ç™¼ï¼‰ï¼Œå‡çªç ´é¢¨éšªé«˜ï¼Œä¸å»ºè­°è¿½é«˜")
    lines.append("â€¢ ğŸš€ çœ‹æ¼²èƒŒé›¢ï¼šåƒ¹æ ¼å‰µä½ä½† CVD ä¸Šå‡ï¼ˆå¤§æˆ¶å¸ç±Œï¼‰ï¼Œåº•éƒ¨åè½‰å‹ç‡é«˜ï¼Œå¯é—œæ³¨")

    lines.append("")
    lines.append(f"â° æ›´æ–°æ™‚é–“ï¼š{now_str}")

    return "\n".join(lines)


def run_altseason_radar_once():
    """æ¯å°æ™‚åŸ·è¡Œä¸€æ¬¡çš„å±±å¯¨çˆ†ç™¼é›·é”ä¸»æµç¨‹"""
    logger.info("é–‹å§‹åŸ·è¡Œå±±å¯¨çˆ†ç™¼é›·é”...")
    msg = build_altseason_message()
    if not msg:
        logger.warning("æœ¬æ¬¡å±±å¯¨çˆ†ç™¼é›·é”æœªèƒ½ç”¢ç”Ÿæœ‰æ•ˆè¨Šæ¯")
        return
    thread_id = TG_THREAD_IDS.get("altseason_radar", 0)
    if not thread_id:
        logger.warning("æœªè¨­å®š TG_THREAD_ALTSEASON_RADARï¼Œå°‡ç™¼é€åˆ°é è¨­èŠå¤©è€Œéç‰¹å®šè©±é¡Œ")
    send_telegram_message(msg, thread_id or int(CHAT_ID or 0), parse_mode="Markdown")
    logger.info("å±±å¯¨çˆ†ç™¼é›·é”æ¨æ’­å®Œæˆ")


# ==================== 10. Hyperliquid è°æ˜éŒ¢ç›£æ§ ====================

HYPERLIQUID_SENT_ALERTS_FILE = DATA_DIR / "hyperliquid_sent_alerts.json"
WHALE_ALERT_THRESHOLD = 200_000  # $20è¬ USDï¼ˆæ”¾å¯¬é–€æª»ï¼Œæ•æ‰æ›´å¤šå¤§é¡äº¤æ˜“ï¼‰
SMART_MONEY_PNL_MIN = 50_000  # $50k USDï¼ˆæ”¾å¯¬ï¼‰
MONEY_PRINTER_PNL_MIN = 500_000  # $50è¬ USDï¼ˆæ”¾å¯¬ï¼‰


def fetch_hyperliquid_whale_alert() -> List[Dict]:
    """ç²å– Hyperliquid é¯¨é­šæé†’ï¼ˆå¤§é¡äº¤æ˜“ï¼Œæ”¹é€²ç‰ˆï¼šé™ä½é–€æª»ä¸¦æ·»åŠ èª¿è©¦ï¼‰"""
    url = f"{CG_API_BASE}/api/hyperliquid/whale-alert"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.error(f"Hyperliquid Whale Alert API éŒ¯èª¤: {response.status_code}")
            return []
        
        result = response.json()
        if result.get('code') not in ['0', 0, 200, '200']:
            logger.error(f"Hyperliquid Whale Alert API è¿”å›éŒ¯èª¤: {result}")
            return []
        
        data_list = result.get('data', [])
        if not isinstance(data_list, list):
            logger.warning(f"Hyperliquid Whale Alert æ•¸æ“šæ ¼å¼ç•°å¸¸: {type(data_list)}")
            return []
        
        # èª¿è©¦ï¼šè¨˜éŒ„åŸå§‹æ•¸æ“š
        logger.info(f"Hyperliquid Whale Alert åŸå§‹æ•¸æ“š: {len(data_list)} æ¢")
        if data_list:
            sample = data_list[0]
            logger.info(f"æ•¸æ“šæ¨£æœ¬æ¬„ä½: {list(sample.keys())}")
            logger.info(f"æ•¸æ“šæ¨£æœ¬å®Œæ•´å…§å®¹: {json.dumps(sample, ensure_ascii=False, indent=2)}")
        
        # ç¯©é¸åç›®åƒ¹å€¼ >= é–€æª»çš„æé†’ï¼ˆé–€æª»å·²é™ä½ï¼‰
        filtered_alerts = []
        value_stats = []  # è¨˜éŒ„æ‰€æœ‰æ•¸å€¼ç”¨æ–¼èª¿è©¦
        
        for idx, alert in enumerate(data_list):
            # å˜—è©¦å¤šç¨®å¯èƒ½çš„æ¬„ä½åç¨±ï¼ˆæ“´å±•æ›´å¤šå¯èƒ½æ€§ï¼‰
            value = None
            value_key = None
            
            # æŒ‰å„ªå…ˆé †åºå˜—è©¦å„ç¨®å­—æ®µåç¨±ï¼ˆå„ªå…ˆä½¿ç”¨ position_value_usdï¼Œé€™æ˜¯æ­£ç¢ºçš„USDåƒ¹å€¼ï¼‰
            possible_keys = [
                'position_value_usd', 'positionValueUsd', 'position_value', 'positionValue',  # æœ€å„ªå…ˆï¼šæŒå€‰USDåƒ¹å€¼
                'notional_value', 'notionalValue', 'notional', 'notional_usd',
                'value', 'value_usd', 'usd_value', 'usdValue',
                'size_usd', 'sizeUSD', 'size',  # size å¯èƒ½æ˜¯æ•¸é‡ï¼Œä¸æ˜¯åƒ¹å€¼
                'amount', 'amount_usd', 'amountUSD',
                'volume', 'volume_usd', 'volumeUSD',
                'trade_value', 'tradeValue', 'trade_value_usd',
                'order_value', 'orderValue', 'order_value_usd',
                'total_value', 'totalValue', 'total_value_usd'
            ]
            
            for key in possible_keys:
                if key in alert and alert[key] is not None:
                    value = alert[key]
                    value_key = key
                    break
            
            # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œå˜—è©¦éæ­·æ‰€æœ‰æ•¸å€¼å­—æ®µï¼ˆæ’é™¤æ˜é¡¯ä¸æ˜¯åƒ¹å€¼çš„å­—æ®µï¼‰
            if value is None:
                excluded_keys = ['entry_price', 'liq_price', 'mark_price', 'leverage', 'position_size', 'create_time', 'update_time']
                for key, val in alert.items():
                    if key.lower() in excluded_keys:
                        continue  # è·³éæ˜é¡¯ä¸æ˜¯åƒ¹å€¼çš„å­—æ®µ
                    if isinstance(val, (int, float)) and val > 0:
                        # å¯èƒ½æ˜¯æ•¸å€¼å­—æ®µï¼Œä½†éœ€è¦åˆ¤æ–·æ˜¯å¦åˆç†ï¼ˆé€šå¸¸äº¤æ˜“é‡‘é¡ > 1000ï¼‰
                        if val >= 1000:
                            value = val
                            value_key = key
                            break
            
            if value is None:
                logger.warning(f"Alert #{idx} ç„¡æ³•æ‰¾åˆ°æ•¸å€¼å­—æ®µï¼Œæ‰€æœ‰å­—æ®µ: {list(alert.keys())}")
                continue
            
            try:
                # è™•ç†å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå¯èƒ½åŒ…å«é€—è™Ÿæˆ–å–®ä½ï¼‰
                if isinstance(value, str):
                    # ç§»é™¤é€—è™Ÿã€ç©ºæ ¼ã€$ç¬¦è™Ÿç­‰
                    value_clean = value.replace(',', '').replace('$', '').replace(' ', '').replace('USD', '').replace('usd', '')
                    value_float = float(value_clean)
                else:
                    value_float = float(value)
                
                # è¨˜éŒ„çµ±è¨ˆä¿¡æ¯ï¼ˆå‰10æ¢ï¼‰
                if idx < 10:
                    symbol = alert.get('symbol') or alert.get('coin') or alert.get('asset') or 'æœªçŸ¥'
                    value_stats.append({
                        'symbol': symbol,
                        'key': value_key,
                        'value': value_float,
                        'formatted': f"${value_float/10000:.2f}è¬"
                    })
                
                if value_float >= WHALE_ALERT_THRESHOLD:
                    filtered_alerts.append(alert)
                    symbol = alert.get('symbol') or alert.get('coin') or alert.get('asset') or 'æœªçŸ¥'
                    logger.info(f"âœ… ç¬¦åˆé–€æª»çš„ Alert: {symbol} - ${value_float/10000:.2f}è¬ (å­—æ®µ: {value_key})")
                else:
                    if idx < 5:  # åªè¨˜éŒ„å‰5æ¢æœªé”é–€æª»çš„
                        symbol = alert.get('symbol') or alert.get('coin') or alert.get('asset') or 'æœªçŸ¥'
                        logger.info(f"âŒ æœªé”é–€æª»: {symbol} - ${value_float/10000:.2f}è¬ < ${WHALE_ALERT_THRESHOLD/10000:.2f}è¬ (å­—æ®µ: {value_key})")
            except (TypeError, ValueError) as e:
                logger.warning(f"Alert #{idx} æ•¸å€¼è§£æå¤±æ•—: å­—æ®µ={value_key}, å€¼={value}, éŒ¯èª¤: {str(e)}")
                continue
        
        # è¼¸å‡ºçµ±è¨ˆä¿¡æ¯
        if value_stats:
            logger.info(f"å‰10æ¢æ•¸æ“šçš„æ•¸å€¼çµ±è¨ˆ:")
            for stat in value_stats:
                logger.info(f"  {stat['symbol']}: {stat['formatted']} (å­—æ®µ: {stat['key']})")
        
        logger.info(f"ç¬¦åˆé–€æª»çš„ Whale Alert: {len(filtered_alerts)} æ¢ï¼ˆé–€æª»: ${WHALE_ALERT_THRESHOLD/10000:.2f}è¬ï¼‰")
        return filtered_alerts
    except Exception as e:
        logger.error(f"ç²å– Hyperliquid Whale Alert å¤±æ•—: {str(e)}")
        return []


def fetch_hyperliquid_pnl_distribution() -> Optional[Dict]:
    """ç²å– Hyperliquid éŒ¢åŒ…ç›ˆè™§åˆ†ä½ˆ"""
    url = f"{CG_API_BASE}/api/hyperliquid/wallet/pnl-distribution"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.error(f"Hyperliquid PNL Distribution API éŒ¯èª¤: {response.status_code}")
            return None
        
        result = response.json()
        if result.get('code') not in ['0', 0, 200, '200']:
            logger.error(f"Hyperliquid PNL Distribution API è¿”å›éŒ¯èª¤: {result}")
            return None
        
        return result.get('data', result)
    except Exception as e:
        logger.error(f"ç²å– Hyperliquid PNL Distribution å¤±æ•—: {str(e)}")
        return None


def fetch_hyperliquid_whale_position() -> List[Dict]:
    """ç²å– Hyperliquid é¯¨é­šæŒå€‰ï¼ˆåƒ¹å€¼ > $100kï¼‰"""
    url = f"{CG_API_BASE}/api/hyperliquid/whale-position"
    headers = {
        "CG-API-KEY": CG_API_KEY,
        "accept": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            logger.error(f"Hyperliquid Whale Position API éŒ¯èª¤: {response.status_code}")
            return []
        
        result = response.json()
        if result.get('code') not in ['0', 0, 200, '200']:
            logger.error(f"Hyperliquid Whale Position API è¿”å›éŒ¯èª¤: {result}")
            return []
        
        data_list = result.get('data', [])
        if not isinstance(data_list, list):
            return []
        
        # è¨˜éŒ„ç¬¬ä¸€å€‹ä½ç½®çš„æ•¸æ“šçµæ§‹ä»¥ä¾¿èª¿è©¦ï¼ˆåªåœ¨æœ‰æ•¸æ“šæ™‚ï¼‰
        if data_list:
            first_item = data_list[0]
            logger.info(f"Hyperliquid Whale Position æ•¸æ“šçµæ§‹ç¤ºä¾‹ï¼ˆå‰ 3 å€‹æ¬„ä½ï¼‰: {list(first_item.keys())[:10]}")
            logger.info(f"å®Œæ•´æ•¸æ“šçµæ§‹: {json.dumps(first_item, ensure_ascii=False, indent=2)[:1000]}")
        
        # å˜—è©¦æå–æŒå€‰åƒ¹å€¼çš„å¤šç¨®å¯èƒ½æ¬„ä½
        def get_position_value(item: Dict) -> float:
            # å˜—è©¦ç›´æ¥çš„å€¼æ¬„ä½
            value = (
                item.get('position_value') or 
                item.get('positionValue') or 
                item.get('value') or 
                item.get('notional_value') or
                item.get('notionalValue') or
                item.get('size_usd') or
                item.get('sizeUSD') or
                item.get('usd_value') or
                item.get('usdValue') or
                0
            )
            
            # å¦‚æœç›´æ¥å€¼ä¸å­˜åœ¨ï¼Œå˜—è©¦ç”¨ size * price è¨ˆç®—
            if value == 0 or (isinstance(value, (int, float)) and value == 0):
                size = float(item.get('size') or item.get('position_size') or item.get('positionSize') or 0)
                price = float(item.get('price') or item.get('mark_price') or item.get('markPrice') or 0)
                if size > 0 and price > 0:
                    value = abs(size * price)
            
            try:
                return float(value)
            except (TypeError, ValueError):
                return 0.0
        
        # æ’åºä¸¦å–å‰ 5 åï¼ˆæŒ‰æŒå€‰åƒ¹å€¼ï¼‰
        sorted_positions = sorted(
            data_list,
            key=get_position_value,
            reverse=True
        )[:5]
        
        return sorted_positions
    except Exception as e:
        logger.error(f"ç²å– Hyperliquid Whale Position å¤±æ•—: {str(e)}")
        return []


def process_smart_money_pnl(pnl_data: Dict) -> Dict:
    """è™•ç†è°æ˜éŒ¢ PNL åˆ†ä½ˆæ•¸æ“š"""
    if not pnl_data or not isinstance(pnl_data, dict):
        return {}
    
    smart_money_info = {
        'money_printers': [],  # > $1M ç²åˆ©
        'smart_money': [],     # $100k - $1M ç²åˆ©
        'top_symbols': {}
    }
    
    # å˜—è©¦è§£æåˆ†å±¤æ•¸æ“š
    # å¯èƒ½çš„çµæ§‹ï¼šåˆ†å±¤åˆ—è¡¨æˆ–ç›´æ¥åŒ…å«æ•¸æ“š
    distribution_list = (
        pnl_data.get('distribution') or 
        pnl_data.get('data') or 
        pnl_data.get('list') or 
        []
    )
    
    if isinstance(distribution_list, list):
        for item in distribution_list:
            if not isinstance(item, dict):
                continue
            
            # ç²å– PNL ç¯„åœ
            pnl_min = float(item.get('pnl_min') or item.get('pnlMin') or item.get('min_pnl') or 0)
            pnl_max = float(item.get('pnl_max') or item.get('pnlMax') or item.get('max_pnl') or float('inf'))
            address_count = int(item.get('address_count') or item.get('addressCount') or item.get('count') or 0)
            
            # åˆ¤æ–·å±¤ç´š
            if pnl_min >= MONEY_PRINTER_PNL_MIN:
                smart_money_info['money_printers'].append({
                    'pnl_range': f"${pnl_min/1000:.0f}k - ${pnl_max/1000:.0f}k" if pnl_max < float('inf') else f"> ${pnl_min/1000:.0f}k",
                    'address_count': address_count
                })
            elif pnl_min >= SMART_MONEY_PNL_MIN and pnl_max <= MONEY_PRINTER_PNL_MIN:
                smart_money_info['smart_money'].append({
                    'pnl_range': f"${pnl_min/1000:.0f}k - ${pnl_max/1000:.0f}k",
                    'address_count': address_count
                })
    
    # å˜—è©¦ç²å–æŒå€‰åˆ†ä½ˆï¼ˆæŒ‰å¹£ç¨®ï¼‰
    position_dist = pnl_data.get('position_distribution') or pnl_data.get('top_symbols') or {}
    if isinstance(position_dist, dict):
        # æ’åºä¸¦å–å‰ 3 å€‹å¹£ç¨®
        sorted_symbols = sorted(
            position_dist.items(),
            key=lambda x: float(x[1].get('value') or x[1].get('total_value') or 0) if isinstance(x[1], dict) else float(x[1] or 0),
            reverse=True
        )[:3]
        
        for symbol, data in sorted_symbols:
            if isinstance(data, dict):
                bias = data.get('bias') or data.get('long_ratio') or 0
                smart_money_info['top_symbols'][symbol] = {
                    'bias': float(bias) * 100 if bias < 1 else float(bias)
                }
    
    return smart_money_info


def format_alert_message(alert: Dict) -> str:
    """æ ¼å¼åŒ–å–®å€‹ Whale Alert è¨Šæ¯"""
    symbol = alert.get('symbol') or alert.get('coin') or 'æœªçŸ¥'
    direction = alert.get('side') or alert.get('direction') or alert.get('type') or 'æœªçŸ¥'
    value = float(
        alert.get('notional_value') or 
        alert.get('notionalValue') or 
        alert.get('value') or 
        0
    )
    
    # åˆ¤æ–·æ–¹å‘ emoji
    direction_emoji = "ğŸŸ¢" if str(direction).lower() in ['long', 'buy', 'å¤š', 'long'] else "ğŸ”´"
    direction_text = "å¤§é¡é–‹å¤š" if str(direction).lower() in ['long', 'buy', 'å¤š', 'long'] else "å¤§é¡é–‹ç©º"
    
    return f"é …ç›®ï¼š`{symbol}`\næ–¹å‘ï¼š{direction_emoji} {direction_text}\nè¦æ¨¡ï¼š${value:,.0f} USD (åç›®åƒ¹å€¼)"


def format_whale_position_message(position: Dict, index: int) -> str:
    """æ ¼å¼åŒ–å–®å€‹é¯¨é­šæŒå€‰è¨Šæ¯"""
    address = position.get('address') or position.get('user') or position.get('user_address') or 'æœªçŸ¥'
    symbol = position.get('symbol') or position.get('coin') or position.get('asset') or 'æœªçŸ¥'
    side = position.get('side') or position.get('direction') or position.get('position_side') or 'æœªçŸ¥'
    
    # å˜—è©¦å¤šç¨®æ–¹å¼ç²å–æŒå€‰åƒ¹å€¼
    size = (
        position.get('position_value') or 
        position.get('positionValue') or 
        position.get('value') or 
        position.get('notional_value') or
        position.get('notionalValue') or
        position.get('size_usd') or
        position.get('sizeUSD') or
        position.get('usd_value') or
        position.get('usdValue') or
        0
    )
    
    # å¦‚æœç›´æ¥å€¼ä¸å­˜åœ¨ï¼Œå˜—è©¦ç”¨ size * price è¨ˆç®—
    try:
        size_float = float(size) if size else 0.0
    except (TypeError, ValueError):
        size_float = 0.0
    
    if size_float == 0:
        position_size = float(position.get('size') or position.get('position_size') or position.get('positionSize') or 0)
        price = float(position.get('price') or position.get('mark_price') or position.get('markPrice') or 0)
        if position_size > 0 and price > 0:
            size_float = abs(position_size * price)
    
    leverage = float(position.get('leverage') or position.get('leverage_ratio') or position.get('leverageRatio') or 1)
    
    # ç°¡åŒ–åœ°å€é¡¯ç¤ºï¼ˆåªé¡¯ç¤ºå¾Œ 4 ä½ï¼‰
    address_short = address[-4:] if len(address) > 4 else address
    
    # åˆ¤æ–·å¤šç©ºæ–¹å‘ï¼ˆç™½è©±æ–‡ä¸­æ–‡ï¼‰
    side_lower = str(side).lower()
    side_text = "åšå¤š" if side_lower in ['long', 'buy', 'å¤š', 'l'] else "åšç©º"
    
    # æ ¼å¼åŒ–é‡‘é¡é¡¯ç¤º
    if size_float >= 1_000_000:
        size_display = f"${size_float/1_000_000:.2f}M"
    elif size_float >= 1_000:
        size_display = f"${size_float/1_000:.2f}K"
    else:
        size_display = f"${size_float:.2f}"
    
    return f"{index}. åœ°å€ `...{address_short}` | å€‰ä½ï¼š{size_display} [{symbol} {side_text}] | æ§“æ¡¿ï¼š{leverage:.1f}x"


def build_hyperliquid_message() -> Optional[str]:
    """çµ„åˆ Hyperliquid è°æ˜éŒ¢ç›£æ§è¨Šæ¯ï¼ˆåƒ…åœ¨æœ‰æ–°çš„ Whale Alert æ™‚æ¨æ’­ï¼‰"""
    logger.info("é–‹å§‹æ§‹å»º Hyperliquid è°æ˜éŒ¢ç›£æ§è¨Šæ¯...")
    
    # 1. ç²å– Whale Alert
    alerts = fetch_hyperliquid_whale_alert()
    logger.info(f"ç²å–åˆ° {len(alerts)} å€‹ Whale Alert")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„ Alertï¼ˆé¿å…é‡è¤‡æ¨æ’­ï¼‰
    sent_alert_ids = load_json_file(HYPERLIQUID_SENT_ALERTS_FILE, [])
    new_alerts = []
    new_alert_ids = []
    
    for alert in alerts:
        # ç”Ÿæˆå”¯ä¸€ IDï¼ˆä½¿ç”¨æ™‚é–“æˆ³ + symbol + valueï¼‰
        alert_id = f"{alert.get('time') or alert.get('timestamp')}_{alert.get('symbol')}_{alert.get('notional_value') or alert.get('notionalValue')}"
        if alert_id not in sent_alert_ids:
            new_alerts.append(alert)
            new_alert_ids.append(alert_id)
    
    # âš ï¸ é‡è¦ï¼šåªåœ¨æœ‰æ–°çš„ Whale Alert æ™‚æ‰æ¨æ’­ï¼Œé¿å…æ´—é »
    if not new_alerts:
        logger.info("æœ¬æ¬¡ç›£æ§æœŸé–“ç„¡æ–°çš„å¤§é¡äº¤æ˜“æé†’ï¼ˆ> $1Mï¼‰ï¼Œè·³éæ¨æ’­")
        return None
    
    # 2. ç²å– PNL Distributionï¼ˆåƒ…ä½œç‚ºè£œå……è³‡è¨Šï¼‰
    pnl_data = fetch_hyperliquid_pnl_distribution()
    smart_money_info = process_smart_money_pnl(pnl_data) if pnl_data else {}
    
    # 3. ç²å– Whale Positionï¼ˆåƒ…ä½œç‚ºè£œå……è³‡è¨Šï¼‰
    whale_positions = fetch_hyperliquid_whale_position()
    logger.info(f"ç²å–åˆ° {len(whale_positions)} å€‹é¯¨é­šæŒå€‰")
    
    # æ§‹å»ºè¨Šæ¯ï¼ˆåƒ…åœ¨æœ‰æ–°çš„ Alert æ™‚æ‰æ§‹å»ºï¼‰
    lines = []
    lines.append("ğŸ³ *ã€å€å¡Šéˆèˆ¹é•· - Hyperliquid é¯¨é­šè¿½è¹¤ã€‘*")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    
    # Whale Alert éƒ¨åˆ†ï¼ˆä¸»è¦å…§å®¹ï¼ŒåŒ…å«é–‹å€‰æ™‚é–“ã€æ¨™çš„ã€æ–¹å‘ï¼‰
    lines.append("ğŸš¨ *å·¨é¯¨å³æ™‚é è­¦ (Whale Alert)*ï¼š")
    for alert in new_alerts[:5]:  # æœ€å¤šé¡¯ç¤º 5 å€‹
        symbol = alert.get('symbol') or alert.get('coin') or 'æœªçŸ¥'
        
        # ç²å–USDåƒ¹å€¼ï¼ˆå„ªå…ˆä½¿ç”¨ position_value_usdï¼‰
        value = float(
            alert.get('position_value_usd') or 
            alert.get('positionValueUsd') or 
            alert.get('position_value') or 
            alert.get('positionValue') or 
            alert.get('notional_value') or 
            alert.get('notionalValue') or 
            alert.get('value') or 
            0
        )
        
        # ç²å–é–‹å€‰æ™‚é–“ï¼ˆcreate_time æ˜¯æ¯«ç§’æ™‚é–“æˆ³ï¼‰
        alert_time = alert.get('create_time') or alert.get('time') or alert.get('timestamp') or alert.get('open_time')
        time_str = "æ™‚é–“æœªçŸ¥"
        if alert_time:
            try:
                if isinstance(alert_time, (int, float)):
                    # create_time æ˜¯æ¯«ç§’æ™‚é–“æˆ³ï¼ˆä¾‹å¦‚ 1768536078000ï¼‰
                    if alert_time > 1e12:
                        dt = datetime.fromtimestamp(alert_time / 1000, tz=timezone.utc)
                    else:
                        dt = datetime.fromtimestamp(alert_time, tz=timezone.utc)
                    # è½‰æ›ç‚ºå°ç£æ™‚é–“
                    dt_taipei = get_taipei_time(dt)
                    time_str = dt_taipei.strftime("%Y-%m-%d %H:%M")
                else:
                    time_str = str(alert_time)
            except Exception as e:
                logger.debug(f"æ™‚é–“è§£æå¤±æ•—: {alert_time}, éŒ¯èª¤: {str(e)}")
                time_str = "æ™‚é–“æœªçŸ¥"
        
        # åˆ¤æ–·æ–¹å‘ï¼ˆæ ¹æ“š position_size æ­£è² æˆ– position_actionï¼‰
        position_size = alert.get('position_size') or alert.get('positionSize') or 0
        position_action = alert.get('position_action') or alert.get('positionAction')
        side = alert.get('side') or alert.get('direction') or alert.get('type')
        
        # åˆ¤æ–·æ–¹å‘é‚è¼¯ï¼š
        # 1. å¦‚æœæœ‰ side/direction/type å­—æ®µï¼Œç›´æ¥ä½¿ç”¨
        # 2. å¦‚æœ position_size > 0ï¼Œå¯èƒ½æ˜¯åšå¤šï¼›< 0 å¯èƒ½æ˜¯åšç©º
        # 3. position_action: 1=é–‹å¤š, 2=é–‹ç©º, 3=å¹³å¤š, 4=å¹³ç©º
        if side:
            direction_text = "åšå¤š" if str(side).lower() in ['long', 'buy', 'å¤š', 'l', '1'] else "åšç©º"
        elif position_action is not None:
            # position_action: 1=é–‹å¤š, 2=é–‹ç©º
            if position_action == 1:
                direction_text = "åšå¤š"
            elif position_action == 2:
                direction_text = "åšç©º"
            else:
                direction_text = "æœªçŸ¥"
        elif isinstance(position_size, (int, float)):
            # æ ¹æ“š position_size æ­£è² åˆ¤æ–·ï¼ˆæ­£æ•¸å¯èƒ½æ˜¯åšå¤šï¼Œè² æ•¸å¯èƒ½æ˜¯åšç©ºï¼‰
            direction_text = "åšå¤š" if position_size > 0 else "åšç©º"
        else:
            direction_text = "æœªçŸ¥"
        
        direction_emoji = "ğŸŸ¢" if "åšå¤š" in direction_text else "ğŸ”´"
        
        # æ ¼å¼åŒ–åƒ¹å€¼é¡¯ç¤º
        if value >= 1_000_000:
            value_display = f"${value/1_000_000:.2f}M"
        elif value >= 1_000:
            value_display = f"${value/1_000:.2f}K"
        else:
            value_display = f"${value:,.0f}"
        
        lines.append(f"â° æ™‚é–“ï¼š{time_str}")
        lines.append(f"æ¨™çš„ï¼š`{symbol}`")
        lines.append(f"æ–¹å‘ï¼š{direction_emoji} {direction_text}")
        lines.append(f"è¦æ¨¡ï¼š{value_display} USD")
        lines.append("")
    
    # æ›´æ–°å·²ç™¼é€ ID åˆ—è¡¨
    sent_alert_ids.extend(new_alert_ids)
    # åªä¿ç•™æœ€è¿‘ 500 æ¢
    if len(sent_alert_ids) > 500:
        sent_alert_ids = sent_alert_ids[-500:]
    save_json_file(HYPERLIQUID_SENT_ALERTS_FILE, sent_alert_ids)
    
    # è°æ˜éŒ¢ PNL åˆ†ä½ˆéƒ¨åˆ†ï¼ˆè£œå……è³‡è¨Šï¼‰
    has_smart_money_data = (
        smart_money_info.get('money_printers') or 
        smart_money_info.get('smart_money') or 
        smart_money_info.get('top_symbols')
    )
    
    if has_smart_money_data:
        lines.append("ğŸ’° *è°æ˜éŒ¢ PNL åˆ†ä½ˆè§€å¯Ÿ*ï¼š")
        
        # é¡¯ç¤ºå±¤ç´šçµ±è¨ˆ
        if smart_money_info.get('money_printers'):
            printer_count = sum(mp.get('address_count', 0) for mp in smart_money_info['money_printers'])
            if printer_count > 0:
                lines.append(f"Money Printer (> $1M ç²åˆ©)ï¼š{printer_count} å€‹éŒ¢åŒ…")
        
        if smart_money_info.get('smart_money'):
            smart_count = sum(sm.get('address_count', 0) for sm in smart_money_info['smart_money'])
            if smart_count > 0:
                lines.append(f"Smart Money ($100k - $1M ç²åˆ©)ï¼š{smart_count} å€‹éŒ¢åŒ…")
        
        # é¡¯ç¤ºæŒå€‰é›†ä¸­åº¦
        top_symbols = smart_money_info.get('top_symbols', {})
        if top_symbols:
            symbol_list = []
            for symbol, info in list(top_symbols.items())[:3]:
                bias = info.get('bias', 0)
                symbol_list.append(f"`{symbol}`")
                if bias > 0:
                    lines.append(f"å…¶ä¸­ {symbol} çš„çœ‹æ¼²æƒ…ç·’ (Bias) é” {bias:.1f}%")
            
            if symbol_list:
                lines.append(f"ç›®å‰ç²åˆ© > $100k çš„éŒ¢åŒ…ï¼Œä¸»è¦æŒå€‰é›†ä¸­åœ¨ï¼š{', '.join(symbol_list)}")
        
        lines.append("")
    
    # èˆ¹é•·æç¤º
    if new_alerts:
        top_symbol = new_alerts[0].get('symbol', 'ç‰¹å®šæ¨™çš„')
        lines.append(f"ğŸ’¡ *èˆ¹é•·æç¤º*ï¼šè°æ˜éŒ¢æ­£åœ¨é—œæ³¨ {top_symbol}ï¼Œè«‹æ³¨æ„è©²å¹£ç¨®çš„æµå‹•æ€§è®ŠåŒ–ï¼")
        lines.append("")
    
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"â° æ›´æ–°æ™‚é–“ï¼š{format_datetime(get_taipei_time())}")
    
    return "\n".join(lines)


def run_hyperliquid_monitor_once():
    """åŸ·è¡Œä¸€æ¬¡ Hyperliquid è°æ˜éŒ¢ç›£æ§ï¼ˆé©åˆæ’ç¨‹è§¸ç™¼ï¼‰"""
    logger.info("é–‹å§‹åŸ·è¡Œ Hyperliquid è°æ˜éŒ¢ç›£æ§...")
    
    message = build_hyperliquid_message()
    if not message:
        logger.info("æœ¬æ¬¡ Hyperliquid ç›£æ§ç„¡æœ‰æ•ˆæ•¸æ“šï¼Œæœªç™¼é€æ¨æ’­")
        return
    
    thread_id = TG_THREAD_IDS.get("hyperliquid", 252)
    send_telegram_message(message, thread_id, parse_mode="Markdown")
    logger.info("Hyperliquid è°æ˜éŒ¢ç›£æ§æ¨æ’­å®Œæˆ")


# ==================== ä¸»ç¨‹åº ====================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        function_name = sys.argv[1]
        
        if function_name == "sector_ranking":
            fetch_sector_ranking()
        elif function_name == "buying_power_monitor":
            buying_power_monitor()
        elif function_name == "whale_position":
            # å‘å¾Œå…¼å®¹ï¼šèˆŠåç¨±ä»å¯ä½¿ç”¨
            logger.info("ä½¿ç”¨èˆŠå‡½æ•¸åç¨± whale_positionï¼Œå»ºè­°æ”¹ç”¨ buying_power_monitor")
            buying_power_monitor()
        elif function_name == "position_change":
            fetch_position_change()
        elif function_name == "economic_data":
            fetch_and_push_economic_data()
        elif function_name == "economic_data_preview":
            send_today_preview()
        elif function_name == "news":
            fetch_all_news()
        elif function_name == "funding_rate":
            fetch_funding_fortune_list()
        elif function_name == "long_term_index":
            run_long_term_monitor()
        elif function_name == "long_term_index_once":
            run_long_term_once()
        elif function_name == "liquidity_radar":
            run_liquidity_radar_once()
        elif function_name == "altseason_radar":
            run_altseason_radar_once()
        elif function_name == "hyperliquid":
            run_hyperliquid_monitor_once()
        else:
            print("å¯ç”¨çš„åŠŸèƒ½:")
            print("  sector_ranking   - ä¸»æµæ¿å¡Šæ’è¡Œæ¦œæ¨æ’­")
            print("  buying_power_monitor - è³¼è²·åŠ›ç›£æ§ï¼ˆç©©å®šå¹£å¸‚å€¼ + OI ç›£æ§ï¼‰")
            print("  whale_position       - å·²å»¢æ£„ï¼Œè«‹ä½¿ç”¨ buying_power_monitor")
            print("  position_change  - æŒå€‰è®ŠåŒ–ç¯©é¸")
            print("  economic_data    - é‡è¦ç¶“æ¿Ÿæ•¸æ“šæ¨æ’­")
            print("  news             - æ–°èå¿«è¨Šæ¨æ’­")
            print("  funding_rate     - è³‡é‡‘è²»ç‡æ’è¡Œæ¦œ")
            print("  long_term_index       - é•·ç·šç‰›ç†Šå°èˆªå„€ï¼ˆ24 å°æ™‚æ¯ 4 å°æ™‚æ›´æ–°ï¼‰")
            print("  long_term_index_once  - é•·ç·šç‰›ç†Šå°èˆªå„€ï¼ˆåªåŸ·è¡Œä¸€æ¬¡ï¼Œé©åˆæ’ç¨‹ï¼‰")
            print("  liquidity_radar       - æµå‹•æ€§çµå–é›·é”ï¼ˆæ¥µç«¯çˆ†å€‰å½™æ•´ï¼‰")
            print("  altseason_radar       - å±±å¯¨çˆ†ç™¼é›·é”ï¼ˆAltseason + RSI + Buy Ratioï¼‰")
            print("  hyperliquid           - Hyperliquid è°æ˜éŒ¢ç›£æ§")
    else:
        print("è«‹æŒ‡å®šè¦åŸ·è¡Œçš„åŠŸèƒ½ï¼Œä¾‹å¦‚: python jackbot.py sector_ranking")

